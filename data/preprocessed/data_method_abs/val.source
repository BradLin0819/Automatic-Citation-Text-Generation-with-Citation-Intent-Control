malaria is a major public health concern in northeast india with a preponderance of drug-resistant strains. until recently the partner drug for artemisinin combination therapy (act) was sulphadoxine pyrimethamine (sp). antifolate drug resistance has been associated with the mutations at dihydropteroate synthase (dhps) and dihydrofolatereductase (dhfr) genes. this study investigated antifolate drug resistance at the molecular level. a total of 249 fever cases from arunachal pradesh, ne india, were screened for malaria, and of these, 75 were found to be positive for plasmodium falciparum. samples were sequenced and analysed with the help of bioedit and clustalw. three novel point mutations were found in the dhps gene with 10 haplotypes along with the already reported mutations. a single haplotype having quadruple mutation was found in the dhfr gene. the study reports higher degree of antifolate drug resistance as evidenced by the presence of multiple point mutations in dhps and dhfr genes. the findings of this study strongly discourage the use sp as a partner drug in act. as chloroquine resistance spreads across africa, the dihydrofolate reductase (dhfr) inhibitors pyrimethamine and proguanil are being used as alternative first-line drugs for the treatment and prevention of plasmodium falciparum malaria. resistance to these drugs is conferred by point mutations in parasite dhfr. these point mutations can be detected by polymerase chain reaction (pcr) assays, but better methods for sample collection, dna extraction, and a diagnostic pcr are needed to make these assays useful in malaria-endemic areas. here we report methods for collecting fingerstick blood onto filter paper strips that are air-dried, then stored and transported at room temperature. cell lysis and dna extraction are accomplished by boiling in chelex-100. we also report a nested pcr technique that has improved sensitivity and specificity. these procedures readily detect mixed infections of parasites with both sensitive and resistant genotypes (confirmed by direct sequencing) and are reliable at parasite densities less than 250/mm3 in field surveys.
phase variation of genes in bacteria enables phenotypic alteration to modulate interactions within a host as conditions change. to promote commensalism in animals and disease in humans, campylobacter jejuni produces a flagellar organelle for motility. in addition to tight transcriptional regulation of flagellar genes, c. jejuni also controls flagellar biosynthesis by phase variation. in this study, an unusual phase‐variable mechanism controlling production of flgr, the response regulator of the flgsr two‐component system required for transcription of σ54‐dependent flagellar genes, is identified. phase variation of flgr production is due to loss or gain of a nucleotide in homopolymeric adenine or thymine tracts within flgr. this mechanism occurs during commensalism in poultry to alter the colonization capacity of c. jejuni, presumably by influencing the motility phenotype of the bacterium. these findings provide more understanding into the genetic and colonization strategies c. jejuni employs to achieve commensalism in a natural host. second, due to the richness of the c. jejuni genome in adenine or thymine residues and the apparent lack of the normal set of mismatch repair enzymes, the results from this study may suggest that the c. jejuni genome is more unstable and variable than previously realized. furthermore, phase variation of flagellar motility by targeting flgr may be a phenomenon specific to c. jejuni that is absent in other campylobacter species and contribute to reasons why c. jejuni is more frequently found as a commensal organism in poultry and as the cause of disease in humans. campylobacter jejuni is the leading cause of bacterial gastroenteritis in humans in developed countries throughout the world. this bacterium frequently promotes a commensal lifestyle in the gastrointestinal tracts of many animals including birds and consumption or handling of poultry meats is a prevalent source of c. jejuni for infection in humans. to understand how the bacterium promotes commensalism, we used signature‐tagged transposon mutagenesis and identified 29 mutants representing 22 different genes of c. jejuni strain 81–176 involved in colonization of the chick gastrointestinal tract. among the determinants identified were two adjacent genes, one encoding a methyl‐accepting chemotaxis protein (mcp), presumably required for proper chemotaxis to a specific environmental component, and another gene encoding a putative cytochrome c peroxidase that may function to reduce periplasmic hydrogen peroxide stress during in vivo growth. deletion of either gene resulted in attenuation for growth throughout the gastrointestinal tract. further examination of 10 other putative mcps or mcp‐domain containing proteins of c. jejuni revealed one other required for wild‐type levels of caecal colonization. this study represents one of the first genetic screens focusing on the bacterial requirements necessary for promoting commensalism in a vertebrate host.
vergence eye movements have traditionally been considered the product of a single neural control center and are usually studied by combining the movements of each eye into a single 'vergence' response. in the present experiment, disparity-driven eye movements were produced by symmetrical step stimuli, and the dynamic properties of each eye movement were analyzed separately. although the final positions of the two eyes were symmetrical, large dynamic asymmetries often occurred. the timing between the two eyes showed fair synchrony as they attained maximum velocity at approximately the same time. since the final static positions were symmetrical, asymmetries occurring during the initial dynamic component must necessarily be compensated by offsetting asymmetries in the latter portion of the response. experiments are described in which monocular accommodation response/stimulus curves were measured with snellen targets over the stimulus range from +1.0 to -5.0 d, using artificial pupils with diameters of 1.0, 1.5, 2.0, 2.5 and 3.0 mm and a constant retinal illuminance of 600 td. the results agree with those of earlier authors in showing a diminished response with smaller pupils. the slopes of the quasi-linear central portions of the response/stimulus curves are well described in terms of a geometrical optical approximation in which the accommodation system works to produce a retinal blur circle whose diameter is a linear function of the dioptric difference between the magnitudes of the stimulus and the accommodative resting state, this blur circle diameter being independent of the pupil diameter. further consideration of diffractive effects suggests that contrast changes in the intermediate spatial frequency components (approximately 5 c/deg) of the retinal image may play a dominant role in guiding the response.
in this paper, we addressed the named entity recognition (ner) problem for morphologically rich languages by employing a semi-supervised learning approach based on neural networks. we adopted a fast unsupervised method for learning continuous vector representations of words, and used these representations along with language independent features to develop a ner system. we evaluated our system for the highly inflectional turkish and czech languages. we improved the state-of-the-art f-score obtained for turkish without using gazetteers by 2.26% and for czech by 1.53%. unlike the previous state-of-the-art systems developed for these languages, our system does not make use of any language dependent features. therefore, we believe it can easily be applied to other morphologically rich languages. in this paper, we present our effort to consolidate and push further the named entity recognition (ner) research for the czech language. the research in czech is based upon a non-standard basis. some systems are constructed to provide hierarchical outputs whereas the rests give flat entities. direct comparison among these system is therefore impossible. our first goal is to tackle this issue. we build our own ner system based upon conditional random fields (crf) model. it is constructed to output either flat or hierarchical named entities thus enabling an evaluation with all the known systems for czech language. we show a 3.5 – 11% absolute performance increase when compared to previously published results. as a last step we put our system in the context of the research for other languages. we show results for english, spanish and dutch corpora. we can conclude that our system provides solid results when compared to the foreign state of the art.
the identification of different kinds of multiword expressions require different solutions, on the other hand, there might be domain-related differences in their frequency and typology. in this paper, we show how our methods developed for identifying noun compounds and light verb constructions can be adapted to different domains and different types of texts. our results indicate that with little effort, existing solutions for detecting multiword expressions can be successfully applied to other domains as well. much work on idioms has focused on type identification, i.e., determining whether a sequence of words can form an idiomatic expression. since an idiom type often has a literal interpretation as well, token classification of potential idioms in context is critical for nlp. we explore the use of informative prior knowledge about the overall syntactic behaviour of a potentially-idiomatic expression (type-based knowledge) to determine whether an instance of the expression is used idiomatically or literally (token-based knowledge). we develop unsupervised methods for the task, and show that their performance is comparable to that of state-of-the-art supervised techniques.
this article describes a pilot youth advocacy initiative for obesity prevention informed by social cognitive theory, social network theory, and theories of community mobilization. with assistance from school and health leaders, adolescent-aged youth led a cafeteria food labeling and social marketing campaign. we implemented an anonymous survey 2 weeks prior to and again at the conclusion of the campaign, and used cafeteria records to track servings of fruits and vegetables. the campaign resulted in a significant increase in youths’ confidence to identify healthy foods (or 1.97, 95 % ci 1.01, 3.84, p = .048), and a significant increase in per person per day servings of fruits (0.02, p = .03) and vegetables (0.01, p = .02). the results of our pilot were promising, and the integration of concepts from multiple theories benefited the implementation process. obesity prevention initiatives should include strategies that encourage youth to create health promotion community networks and lead changes to their social and physical environments. objectives we assessed the statewide impact of the 2004 texas public school nutrition policy on foods and beverages served or sold in schools.   methods we collected lunch food production records from 47 schools in 11 texas school districts for the school years before (2003-2004) and after (2004-2005) policy implementation. cafeteria servings of fruit, vegetables (regular and fried), and milk served each day were calculated. twenty-three schools from 5 districts provided records of à la carte sales of candy, chips, desserts, drinks, ice cream, and water. we examined aggregated school-level differences in total items served or sold per day per student between study years.   results school demographics were similar to state data. regardless of district and school size, cafeterias served significantly fewer high-fat vegetable items per student postpolicy (p < .001). postpolicy snack bar sales of large bags of chips were significantly reduced (p = .006), and baked chips sales significantly increased (p = .048).   conclusions school food policy changes have improved foods served or sold to students. it is not known whether improved lunch choices influence consumption for the whole day.
statistical effective energy function (seef) is derived from the statistical analysis of the database of known protein structures. dehouck–gilis–rooman (dgr) group has recently created a new generation of seef in which the additivity of the energy terms was manifested by decomposing the total folding free energy into a sum of lower order terms. we have tried to optimize the potential function based on their work. by using decoy datasets as screening filter, and through modification of algorithms in calculation of accessible surface area and residue–residue interaction cutoff, four new combinations of the energy terms were found to be comparable to dgr potential in performance test. most importantly, the term number was reduced from the original 30 terms to only 5 in our results, thereby substantially decreasing the computation time while the performance was not sacrificed. our results further proved the additivity and manipulability of the dgr original energy function, and our new combination of the energy could be used in prediction of protein structures. we describe predictions made using the rosetta structure prediction methodology for both template‐based modeling and free modeling categories in the seventh critical assessment of techniques for protein structure prediction. for the first time, aggressive sampling and all‐atom refinement could be carried out for the majority of targets, an advance enabled by the rosetta@home distributed computing network. template‐based modeling predictions using an iterative refinement algorithm improved over the best existing templates for the majority of proteins with less than 200 residues. free modeling methods gave near‐atomic accuracy predictions for several targets under 100 residues from all secondary structure classes. these results indicate that refinement with an all‐atom energy function, although computationally expensive, is a powerful method for obtaining accurate structure predictions. proteins 2007. © 2007 wiley‐liss, inc.
prolotherapy involves the injection of nonbiologic solutions, typically at soft tissue attachments and within joint spaces, to reduce pain and improve function in painful musculoskeletal conditions. a variety of solutions have been used; dextrose prolotherapy is the most rigorously studied and is the focus of this review. although the mechanism of action is not clearly known, it is likely to be multifactorial. data on effectiveness for temporomandibular dysfunction are promising but insufficient for recommendations. research on the mechanism of action and clinical effects of dextrose prolotherapy are under way. flaws in the design, conduct, analysis, and reporting of randomised trials can cause the effect of an intervention to be underestimated or overestimated. the cochrane collaboration’s tool for assessing risk of bias aims to make the process clearer and more accurate
digital platforms in healthcare institutions enable tracking and recording of patient care pathways. besides the electronic health records (ehrs), the event logs from hospital information systems (his) are a very efficient source of information, from both operational and clinical point of view. process mining allows comparison of a patient care pathway with the event log(s) from his, to understand how well the reality as depicted in the event log fits the expectation as modeled using a care pathway. in this paper, we present sepvis, a visual analytics tool which aims to fill the gap in current process-centric applications by looking at patients' pathways from a clinical point of view. we demonstrate the utility of sepvis in selected use cases derived by the guidelines in the management of sepsis patients. under the umbrella of buzzwords such as “business activity monitoring” (bam) and “business process intelligence” (bpi) both academic (e.g., emit, little thumb, inwolve, process miner, and minson) and commercial tools (e.g., aris ppm, hp bpi, and ilog jviews) have been developed. the goal of these tools is to extract knowledge from event logs (e.g., transaction logs in an erp system or audit trails in a wfm system), i.e., to do process mining. unfortunately, tools use different formats for reading/storing log files and present their results in different ways. this makes it difficult to use different tools on the same data set and to compare the mining results. furthermore, some of these tools implement concepts that can be very useful in the other tools but it is often difficult to combine tools. as a result, researchers working on new process mining techniques are forced to build a mining infrastructure from scratch or test their techniques in an isolated way, disconnected from any practical applications. to overcome these kind of problems, we have developed the prom framework, i.e., an “pluggable” environment for process mining. the framework is flexible with respect to the input and output format, and is also open enough to allow for the easy reuse of code during the implementation of new process mining ideas. this paper introduces the prom framework and gives an overview of the plug-ins that have been developed.
significance mesoscale convective systems (mcss) are the primary source of precipitation over the tropics and midlatitudes, and their lifetime can have a large influence on the variability of rainfall, especially extreme rainfall that causes flooding. the hypothesis that aerosols can increase the lifetime of the mcss by weakening or delaying precipitation has long been proposed, but we have not known whether that increase is significant on global and regional scales, and, if so, how it compares with the influence of meteorological conditions. we use multiyear collocated geostationary and polar-orbital satellite datasets to provide, to our knowledge, the first observational assessment of such an aerosol effect and its relative importance compared with other meteorological conditions in determining the variability of mcss’ lifetime. using collocated measurements from geostationary and polar-orbital satellites over tropical continents, we provide a large-scale statistical assessment of the relative influence of aerosols and meteorological conditions on the lifetime of mesoscale convective systems (mcss). our results show that mcss’ lifetime increases by 3–24 h when vertical wind shear (vws) and convective available potential energy (cape) are moderate to high and ambient aerosol optical depth (aod) increases by 1 sd (1σ). however, this influence is not as strong as that of cape, relative humidity, and vws, which increase mcss’ lifetime by 3–30 h, 3–27 h, and 3–30 h per 1σ of these variables and explain up to 36%, 45%, and 34%, respectively, of the variance of the mcss’ lifetime. aod explains up to 24% of the total variance of mcss’ lifetime during the decay phase. this result is physically consistent with that of the variation of the mcss’ ice water content (iwc) with aerosols, which accounts for 35% and 27% of the total variance of the iwc in convective cores and anvil, respectively, during the decay phase. the effect of aerosols on mcss’ lifetime varies between different continents. aod appears to explain up to 20–22% of the total variance of mcss’ lifetime over equatorial south america compared with 8% over equatorial africa. aerosols over the indian ocean can explain 20% of total variance of mcss’ lifetime over south asia because such mcss form and develop over the ocean. these regional differences of aerosol impacts may be linked to different meteorological conditions. we estimate the extent of upper tropospheric aerosol layers (ut als) surrounding mesoscale convective systems (mcss) and explore the relationships between ut al extent and the morphology, location, and developmental stage of collocated mcss in the tropics. our analysis is based on satellite data collected over equatorial africa, south asia, and the amazon basin between june 2006 and june 2008. we identify substantial variations in the relationships between convective properties and aerosol transport by region and stage of convective development. the most extensive ut als over equatorial africa are associated with mature mcss, while the most extensive ut als over south asia and the amazon are associated with growing mcss. convective aerosol transport over the amazon is weaker than that observed over the other two regions despite similar transport frequencies, likely due to the smaller sizes and shorter mean lifetimes of mcss over the amazon. variations in ut als in the vicinity of tropical mcss are primarily explained by variations in the horizontal sizes of the associated mcss and are largely unrelated to aerosol loading in the lower troposphere. we also identify potentially important relationships with the number of convective cores, vertical wind shear, and convective fraction during the growing and mature stages of mcs development. relationships between convective properties and aerosol transport are relatively weak during the decaying stage of convective development. our results provide an interpretive framework for devising and evaluating numerical model experiments that examine relationships between convective properties and als in the upper troposphere.
feral swine were targeted for control at avon park air force range in south-central florida to avert damage to sensitive wetland habitats on the 40,000-ha base. we conducted a 5-year study to assess impacts from control to this population that had been recreationally hunted for many years. control was initiated in early 2009. the feral swine population was monitored from 2008 to 2012 using a passive tracking index (pti) during the dry and wet seasons and using recreational hunter take rates from the dry season. all three indices showed substantial feral swine declines after implementing control, with indices leveling for the final two study years. military missions and recreational hunting seasons impacted temporal and spatial consistency of control application, thereby limiting further impacts of control efforts on the feral swine population. the pti was also able to monitor coyotes, another invasive species on the base, and detect florida black bear and florida panther, species of particular concern. summaryin the last decades, wild boar (sus scrofa) distribution has increased world-wide, the iberian peninsula being no exception. the wild boar now inhabits almost the entire iberian territory, where today it is one of the most important big game species. in this paper, for the first time, bag analysis from two ecological different regions are presented and compared to the employed hunting techniques. one represents the well-preserved mediterranean forests of south-western spain, the other, located in the south of portugal, is a farmland with interspersed forest areas. our results indicate a stronger hunting intensity and also a higher wild boar population density in the portuguese study areas. the stronger hunting intensity may result in a younger wild boar population. we also found considerable differences between the shooting techniques used in both regions and those employed in the north-east of the peninsula. it does therefore not seem advisable to directly compare bag statistics from different regions of the iberian peninsula.zusammenfassungin den letzten jahrzehnten hat das wildschwein (sus scrofa) sein vebreitungsgebiet weltweit ausgedehnt. die iberische halbinsel bildet diesbezüglich keine ausnahme. das wildschwein kommt dort gegenwärtig nahezu überall vor und stellt eine der wichtigsten gro\wildarten dar. in dieser arbeit werden erstmals streckenanalysen aus zwei ökologisch unterschiedlichen regionen der iberischen halbinsel vorgelegt und im hinblick auf die eingesetzten jagdmethoden verglichen. eine region repräsentiert die gut erhaltenen mediterranen wälder südwest-spaniens. die andere, im süden portugals gelegene untersuchungsregion ist ein agrargebiet mit eingestreuten wäldern. unsere ergebnisse weisen auf einen höheren jagddruck sowie eine grö\ere populationsdichte der wildschweine im portugiesischen untersuchungsgebiet hin. der grö\ere jagddruck kann ursache für ein im mittel geringeres alter der dortigen wildschwein-population sein. es wurden ferner beachtliche unterschiede in den bejagungsmethoden zwischen den beiden untersuchungsgebieten und dem nordosten iberiens beobachtet. wegen dieser unterschiede erscheint ein direkter vergleich von streckenergebnissen aus verschiedenen regionen der iberischen halbinsel nicht ratsam.résuméau cours des dernières décennies, la distribution mondiale du sanglier (sus scrofa) a fortement augmenté, la péninsule ibérique ne faisant pas exception à cet égard. le sanglier colonise pratiquement l'entièreté du territoire ibérique où il représente aujourd'hui une des espèces-gibier les plus importantes. dans cette contribution, pour la première fois, l'analyse des tableaux de tir réalisés dans deux régions écologiquement différentes est présentée et rapportée aux techniques cynégétiques utilisées. l'une correspond aux forêts méditerranéennes bien conservées du sud-ouest de l'espagne, l'autre, située au sud du portugal, est constituée d'une alternance de terres agricoles et de forêts. nos résultats indiquent une pression cynégétique plus intense de même qu'une densité de population en sangliers plus élevée dans la partie portugaise de l'aire d'étude. la pression cynégétique plus forte peut donner lieu à une population de sangliers plus jeune. nous avons également constaté des différences considérables entre les techniques de tir utilisées dans les deux régions et celles utilisées dans le nord-est de la péninsule. il ne semble dès lors pas recommandable de comparer directement les statistiques de tir de différentes régions de la péninsule ibérique.
previous research on gaze behaviour in sport has typically reported summary fixation statistics thereby largely ignoring the temporal sequencing of gaze. in the present study on penalty kicking in soccer, our aim was to apply a markov chain modelling method to eye movement data obtained from goalkeepers. building on the discrete analysis of gaze employed by dicks et al. (atten percept psychophys 72(3):706–720, 2010b), we wanted to statistically model the relative probabilities of the goalkeeper’s gaze being directed to different locations throughout the penalty taker’s approach (dicks et al. in atten percept psychophys 72(3):706–720, 2010b). examination of gaze behaviours under in situ and video-simulation task constraints reveals differences in information pickup for perception and action (attention, perception and psychophysics 72(3), 706–720). the probabilities of fixating anatomical locations of the penalty taker were high under simulated movement response conditions. in contrast, when actually required to intercept kicks, the goalkeepers initially favoured watching the penalty taker’s head but then rapidly shifted focus directly to the ball for approximately the final second prior to foot-ball contact. the increased spatio-temporal demands of in situ interceptive actions over laboratory-based simulated actions lead to different visual search strategies being used. when eye movement data are modelled as time series, it is possible to discern subtle but important behavioural characteristics that are less apparent with discrete summary statistics alone. it is still not known what underlies successful performance in goaltending. some studies have reported that advanced cues from the shooter's body (hip, kicking leg or support leg) are most important (savelsbergh, g. j. p., williams, a. m., van der kamp, j., & ward, p. (2002). visual search, anticipation and expertise in soccer goalkeepers. journal of sports sciences, 20, 279-287; savelsbergh, g. j. p., williams, a. m., van der kamp, j., & ward, p. (2005). anticipation and visual search behaviour in expert soccer goalkeepers. ergonomics, 48, 1686-1697; williams, a. m., & burwitz, l. (1993). advanced cue utilization in soccer. in t. reilly, j. clarys, & a. stibbe (eds.), science and football ii (pp. 239-243). london, england: e&fn spon), while others have found that the early tracking of the object prior to and during flight is most critical (bard, c., & fleury, m. (1981). considering eye movement as a predictor of attainment. in: i. m. cockerill, & w. m. macgillvary (eds.), vision and sport (pp. 28-41). cheltenham, england: stanley thornes (publishers) ltd.). these results are similar to those found in a number of interceptive timing studies (land, m. f., & mcleod, p. (2000). from eye movements to actions: how batsmen hit the ball. nature neuroscience, 3, 1340-1345; ripoll and fleurance, 1988; vickers, j. n., & adolphe, r. m. (1997). gaze behaviour during a ball tracking and aiming skill. international journal of sports vision, 4, 18-27). the coupled gaze and motor behavior of elite goaltenders were determined while responding to wrist shots taken from 5 m and 10 m on ice. the results showed that the goalies faced shots that were significantly different in phase durations due to distance (5 versus 10 m), but this was not a factor in making saves. instead, the ability to stop the puck was dependent on the location, onset and duration of the final fixation/tracking gaze (or quiet eye) prior to initiating the saving action. the relative onset of quiet eye was significantly (p<.001) earlier (8.6%) and the duration was longer on saves (m=80.5%; 952.3 ms) compared to goals (onset 18.86%; m=70.1%, 826.1 ms). the quiet eye was located on the puck/stick during the preparation and execution of the shot in 70.53% of all trials, or on the ice in front of the release point of the puck (25.68%) and rarely on the body of the shooter (2.1%). the results are discussed within the context of current research on goaltending with specific emphasis on the timing of critical cues and the effect of tasks constraints.
echocardiography can be used to estimate myocardial contractility by the assessment of the circumferential end-systolic stress-corrected left ventricular (lv) fractional shortening measured at midwall level (stress-corrected mws). whether stress-corrected mws at rest predicts exercise peak oxygen uptake (peak v̇o2) is unknown. also, it is not known whether the propagation rate of the early lv filling wave (e wave propagation rate, v̇p), a new pre-load insensitive index of lv diastolic function, and echocardiographically assessed indices of arterial stiffness correlate to peak v̇o2. accordingly, we performed echocardiographic studies and exercise tests with respiratory gas analysis in 15 young healthy male subjects (mean age 27 years, range 18–36). neither stress-corrected-mws (r=0.20, p=ns) nor ejection fraction (r=−0.05, p=ns) correlated significantly with peak v̇o2. adjustment for age and resting heart rate had no effect on the results. in separate multiple regression models adjusting for standard covariates (age, lv size and heart rate), peak v̇o2 correlated with v̇p (beta=0.98, p<0.01), as well as with e/a (beta=0.85, p<0.01), and with the isovolumic relaxation time (indicator of lv relaxation) (beta=−0.59, p<0.05). arterial stiffness indices showed no significant relation to peak v̇o2. we conclude that in young healthy male subjects, resting myocardial contractility and arterial stiffness are not significant correlates of peak v̇o2, whereas lv diastolic function, and in particular v̇p, influences the variability of peak v̇o2. objectives the study was done to evaluate reliability of echocardiographic left ventricular (lv) mass.   background echocardiographic estimation of lv mass is affected by several sources of variability.   methods we assessed intrapatient reliability of lv mass measurements in 183 hypertensive patients (68% men, 65 +/- 9 years) enrolled in the prospective randomized enalapril study evaluating regression of ventricular enlargement (preserve) trial after a screening echocardiogram (echo) showed lv hypertrophy. a second echo was repeated at randomization (45 +/- 25 days later). two-dimensional (2d)-guided m-mode or 2d linear measurements of lv cavity and wall dimensions were verified by one experienced reader.   results mean lv mass was similar at first and second echo (243 +/- 53 vs. 241 +/- 54 g) and showed high reliability as estimated by intraclass correlation coefficient (rho) = 0.93. within-patient 5th, 10th, 90th and 95th percentiles of between-study difference in lv mass were -32 g, -28 g, +25 g and +35 g. mean lv mass fell less from the first to the second echo than expected from a formula to predict regression to the mean (2 +/- 19 vs. 17 +/- 12 g, p < 0.001). reliability was also high for lv internal diameter (rho = 0.87), septal (rho = 0.85) and posterior wall thickness (rho = 0.83). substantial or moderate reliability was observed for measures of lv systolic function and diastolic filling (rho from 0.71 to 0.57).   conclusions left ventricular mass had high reliability and little regression to the mean; between-study lv mass change of +/-35 g or +/-17 g had > or = 95% or > or = 80% likelihood of being true change.
sea quark distributions in the nucleon have naively been expected to be generated perturbatively by gluon splitting in this case there is no reason for the light quark and anti quark sea distributions to be di erent no asymmetries in the strange or heavy quark sea distributions are predicted in the improved parton model however recent experiments have called these naive expectations into question a violation of the gottfried sum rule has been measured in several experiments suggesting that u d in the proton additionally other measurements while not de nitive show that there may be an asymmetry in the strange and anti strange quark sea distributions these e ects may require nonperturbative explanations in this review we rst discuss the perturbative aspects of the sea quark distributions we then describe the experiments that could point to nonperturbative contributions to the nucleon sea current phenomenological models that could explain some of these e ects are reviewed the quark and gluon distributions of the photon are determined in leading and higher order by imposing a vector-meson dominance (vmd) valencelike structure at a low resolution scale adopted from the pion. this leaves only one free parameter, not sufficiently constrained by vmd, to be fixed by experiment. our predictions are in agreement with presently available data for {ital f}{sub 2}{sup {gamma}}({ital x},{ital q}{sup 2}). simple parametri- zations of the resulting parton distributions are presented in the range 10{sup {minus}5}{approx lt}{ital x}{lt}1, 0.3{approx lt}{ital q}{sup 2}{approx lt}10{sup 6} gev{sup 2} as obtained from the leading- and higher-order evolution equations.
purposethe goal of the present study was to compare the outcomes of operative and non-operative patients with adult spinal deformity (asd) over 75 years of age.methodsa retrospective review of a multicenter prospective adult spinal deformity database was conducted examining patients with asd over the age of 75 years. demographics, comorbidities, operation-related variables, complications, radiographs, and health-related quality of life (hrqol) measures collected included oswestry disability index, short form-36, and scoliosis research society-22 preoperatively, and at 1 and 2 years later. minimum clinically important difference (mcid) was calculated and also compared.results27 patients (12 operative, 15 non-operative) were studied. there were no significant differences (p > 0.05) between operative and non-operative patients for age, body mass-index, and comorbidities, but operative patients had worse baseline hrqol than non-operative patients. operative patients had a significant improvement in radiographic parameters in 2-year hrqol, whereas non-operative patients did not (p > 0.05). operative patients were significantly more likely to reach mcid (range 41.7–81.8 vs. 0–33.3 %, p < 0.05). in the surgical group, 9 (75 %) patients had at least 1 complication (24 total complications).conclusionsin the largest series to date comparing operative and non-operative management of adult spinal deformity in elderly patients greater than 75 years of age, reconstructive surgery provides significant improvements in pain and disability over a 2-year period. furthermore, operative patients were more likely to reach mcid than non-operative patients. when counseling elderly patients with asd, such data may be helpful in the decision-making process regarding treatment. purpose of the study parameters determining sagittal balance are essential for optimal analysis and treatment of many spinal disorders. the purpose of this work was to validate a software designed to measure the principal parameters involved in sagittal balance of the spine.   material and methods six parameters (lumbar lordosis, thoracic kyphosis, sagittal tilt at t9, pelvic index, pelvic tilt, slope of the sacrum) were measured on lateral views of the spine from 100 healthy volunteers free of any spinal disease. two measurement techniques were used: manual measurement and automatic computerized measurement with this software. we hypothesized that manual measures could be accepted as reference values because they are currently the most widely used and because the computerized measurements were obtained using digitalized images that may have modified interpretation. the software was therefore validated by comparing the angles measured manually with the computer output. inter- and intraobserver coefficients of variation were calculated for the two measurement techniques. one operator performed both series of measurements (manual and computerized). two other operators preformed two series of independent measures using one of the measurement techniques. finally, two new operators performed a complete series of measurements using both measurement techniques. comparisons were performed with the t test for paired variables with calculation of the coefficients of correlation. intraclass coefficients of correlation were determined for inter- and intra-observer variability.   results there was an excellent correlation between the manual measurements and the computerized measurements with intra-class coefficients of correlation varying from 0.82 to 0.96. inter- and intra-observer variabilities were comparable for the two measurement techniques used to determine thoracic kyphosis, lumbar lordosis, pelvic index, pelvic tilt, and slope of the sacrum. inter- and intra-observer variability was lower when the sagittal tilt was measured with the software specially designed.   conclusion this comparison between two techniques for measuring pelvic and spinal parameters of sagittal balance of the spine demonstrated a good correlation between manual and the computerized measurements obtained with the software to be evaluated. computer-assisted measurements not only provided a saving in time but also minimized inter- and intra-observer variability for the estimation of certain parameters.
the important role of referring expressions in human communication has inspired much research in the fields of computational linguistics and psycholinguistics. building on the research done by viethen, goudbeek and krahmer (cogsci, 2012) the present study takes a cross-linguistic perspective on examining the use of the colour attribute in distinguishing a target referent. it aims at answering the following research question: does the availability of adequate basic colour terms in a language affect the use of colour in reference production? we conducted a language production experiment with native speakers of dutch and greek. our results confirm that the use of the colour attribute in reference production depends on the colour term resources of a particular language. in addition, we have recorded a large cross-linguistic difference in the proportion of the colour use, which we relate to the particular colour nuances used. we examine the problem of generating definite noun phrases that are appropriate referring expressions; that is, noun phrases that (a) successfully identify the intended referent to the hearer whilst (b) not conveying to him or her any false conversational implicatures (grice, 1975). we review several possible computational interpretations of the conversational implicature maxims, with different computational costs, and argue that the simplest may be the best, because it seems to be closest to what human speakers do. we describe our recommended algorithm in detail, along with a specification of the resources a host system must provide in order to make use of the algorithm, and an implementation used in the natural language generation component of the idas system.
rna-seq is currently the technology of choice for global measurement of transcript abundances in cells. despite its successes, isoform-level quantification remains difficult because short rna-seq reads are often compatible with multiple alternatively spliced isoforms. existing methods rely heavily on uniquely mapping reads, which are not available for numerous isoforms that lack regions of unique sequence. to improve quantification accuracy in such difficult cases, we developed a novel computational method, prior-enhanced rsem (prsem), which uses a complementary data type in addition to rna-seq data. we found that chip-seq data of rna polymerase ii and histone modifications were particularly informative in this approach. in qrt-pcr validations, prsem was shown to be superior than competing methods in estimating relative isoform abundances within or across conditions. data-driven simulations suggested that prsem has a greatly decreased false-positive rate at the expense of a small increase in false-negative rate. in aggregate, our study demonstrates that prsem transforms existing capacity to precisely estimate transcript abundances, especially at the isoform level. histones are frequently decorated with covalent modifications. these histone modifications are thought to be involved in various chromatin-dependent processes including transcription. to elucidate the relationship between histone modifications and transcription, we derived quantitative models to predict the expression level of genes from histone modification levels. we found that histone modification levels and gene expression are very well correlated. moreover, we show that only a small number of histone modifications are necessary to accurately predict gene expression. we show that different sets of histone modifications are necessary to predict gene expression driven by high cpg content promoters (hcps) or low cpg content promoters (lcps). quantitative models involving h3k4me3 and h3k79me1 are the most predictive of the expression levels in lcps, whereas hcps require h3k27ac and h4k20me1. finally, we show that the connections between histone modifications and gene expression seem to be general, as we were able to predict gene expression levels of one cell type using a model trained on another one.
the objective of this study was to develop and explore new, in silico experimental methods for deciphering complex, highly variable absorption and food interaction pharmacokinetics observed for a modified-release drug product. toward that aim, we constructed an executable software analog of study participants to whom product was administered orally. the analog is an object- and agent-oriented, discrete event system, which consists of grid spaces and event mechanisms that map abstractly to different physiological features and processes. analog mechanisms were made sufficiently complicated to achieve prespecified similarity criteria. an equation-based gastrointestinal transit model with nonlinear mixed effects analysis provided a standard for comparison. subject-specific parameterizations enabled each executed analog’s plasma profile to mimic features of the corresponding six individual pairs of subject plasma profiles. all achieved prespecified, quantitative similarity criteria, and outperformed the gastrointestinal transit model estimations. we observed important subject-specific interactions within the simulation and mechanistic differences between the two models. we hypothesize that mechanisms, events, and their causes occurring during simulations had counterparts within the food interaction study: they are working, evolvable, concrete theories of dynamic interactions occurring within individual subjects. the approach presented provides new, experimental strategies for unraveling the mechanistic basis of complex pharmacological interactions and observed variability. absorption models used in the estimation of pharmacokinetic drug characteristics from plasma concentration data are generally empirical and simple, utilizing no prior information on gastro-intestinal (gi) transit patterns. our aim was to develop and evaluate an estimation strategy based on a mechanism-based model for drug absorption, which takes into account the tablet movement through the gi transit. this work is an extension of a previous model utilizing tablet movement characteristics derived from magnetic marker monitoring (mmm) and pharmacokinetic data. the new approach, which replaces mmm data with a gi transit model, was evaluated in data sets where mmm data were available (felodipine) or not available (diclofenac). pharmacokinetic profiles in both datasets were well described by the model according to goodness-of-fit plots. visual predictive checks showed the model to give superior simulation properties compared with a standard empirical approach (first-order absorption rate + lag-time). this model represents a step towards an integrated mechanism-based nlme model, where the use of physiological knowledge and in vitro–in vivo correlation helps fully characterize pk and generate hypotheses for new formulations or specific populations.
pancreatic adenocarcinoma is the fourth leading cause of cancer death in the united states. it is identified by its rapid, invasive progression with a profound resistance to treatments such as chemotherapy. unfortunately, there is a lack of information on how to effectively inhibit and control the rapid growth of pancreatic tumors, as well as limited information for diagnostics. with current methods, pancreatic cancer will continue to prevail as a leading cause of cancer death. we propose to study the complexity of pancreatic tumors with a systematic and analytical approach. cancer is an abnormal growth of tissue caused by uncontrolled cell division. observing the growth of these cells would prove to have a good basis to monitor the growth of a tumor. here we create a 3-d simulation of tumor growth through mathematical modeling, using data from pancreatic cells grown in vitro. using 3-d models will help to understand pancreatic tumors at cellular and molecular levels. the project aims to observe realistic growth of the tumor, accomplished from growing tumor cells on a monolayer in order to find parameters for our 3d mathematical model. this method will prove more beneficial than testing only on a monolayer cell line. although cell death and the toxicity of drug dosage can be tested using a cell monolayer alone, it does not meet the demands of testing drug delivery in a realistic tumor environment that the mathematical model would provide. the monolayer lacks the dimensions that the drug would have to travel if it were delivered to a real in vivo tumor. a possible continuation of this project in the future could be to utilize the mathematical based approach to predict optimal therapy for the pancreatic tumor in order to develop models that can better test patient care for tumors. computer modeling, another stepping stone through mathematical modeling, will possibly lead to testing the toxic effects of drugs on a 3-d model through computer modeling will aid in understanding the delivery of drugs throughout the tumor in vivo. abstract we study solid tumor (carcinoma) growth in the nonlinear regime using boundary-integral simulations. the tumor core is nonnecrotic and no inhibitor chemical species are present. a new formulation of the classical models [18,24,8,3] is developed and it is demonstrated that tumor evolution is described by a reduced set of two dimensionless parameters and is qualitatively unaffected by the number of spatial dimensions. one parameter describes the relative rate of mitosis to the relaxation mechanisms (cell mobility and cell-to-cell adhesion). the other describes the balance between apoptosis (programmed cell-death) and mitosis. both parameters also include the effect of vascularization. our analysis and nonlinear simulations reveal that the two new dimensionless groups uniquely subdivide tumor growth into three regimes associated with increasing degrees of vascularization: low (diffusion dominated, e.g., in vitro), moderate and high vascularization, that correspond to the regimes observed in vivo. we demonstrate that critical conditions exist for which the tumor evolves to nontrivial dormant states or grows self-similarly (i.e., shape invariant) in the first two regimes. this leads to the possibility of shape control and of controlling the release of tumor angiogenic factors by restricting the tumor volume-to-surface-area ratio. away from these critical conditions, evolution may be unstable leading to invasive fingering into the external tissues and to topological transitions such as tumor breakup and reconnection. interestingly we find that for highly vascularized tumors, while they grow unbounded, their shape always stays compact and invasive fingering does not occur. this is in agreement with recent experimental observations [30] of in vivo tumor growth, and suggests that the invasive growth of highly-vascularized tumors is associated to vascular and elastic anisotropies, which are not included in the model studied here.
received 27 july 2008 revised 29 september 2008 accepted 23 october 2008 bovicin hj50 is a new lantibiotic containing a disulfide bridge produced by streptococcus bovis hj50; its encoding gene bova was reported in our previous publication. to identify other genes involved in bovicin hj50 production, dna fragments flanking bova were cloned and sequenced. the bovicin hj50 biosynthesis gene locus was encoded by a 9.9 kb region of chromosomal dna and consisted of at least nine genes in the following order: bova, -m, -t, -e, -f, orf1, orf2, bovk and bovr. a thiol–disulfide oxidoreductase gene named sdb1 was located downstream of bovr. a knockout mutant of this gene retained antimicrobial activity and the molecular mass of bovicin hj50 in the mutant was the same as that of bovicin hj50 in s. bovis hj50, implying that sdb1 is not involved in bovicin hj50 production. transcriptional analyses showed that bova, bovm and bovt constituted an operon, and the transcription start site of the bova promoter was located at a g residue 45 bp upstream of the translation start codon for bova, while bove through bovr were transcribed together and the transcription start site of the bove promoter was located at a c residue 35 bp upstream of bove. we also demonstrated successful heterologous expression of bovicin hj50 in lactococcus lactis mg1363, which lacks thiol–disulfide oxidoreductase genes; this showed that thiol–disulfide oxidoreductase genes other than sdb1 are not essential for bovicin hj50 biosynthesis. three thermosensitive (ts) suicide vectors, pset4s, pset5s, and pset6s, have been constructed for gene replacement in streptococcus suis. each vector contains an antibiotic-resistance gene (spc or cat), a ts replication origin of pwv01 lineage, multiple cloning sites, lacz', and the cole1 replication origin of puc19. these vectors could be propagated at 37 degrees c in escherichia coli, but their replication was blocked above 37 degrees c in s. suis. moreover, the thermosensitivity of the replication origin was confirmed in s. equi ssp. equi, s. equi ssp. zooepidemicus, and s. dysgalactiae by using pset4s. for inactivation of the sly gene, which encodes a thiol-activated hemolysin of s. suis, pslyk, in which the sly gene was interrupted by the cat gene, was constructed using pset4s and introduced into s. suis dat2. after growth at the nonpermissive temperature under the antibiotic pressure, the chromosomal sly gene was replaced with the sly::cat gene of pslyk by a double-crossover event at a rate of 2.6% among chloramphenicol-resistant cells. moreover, complementation of the sly gene by use of the previously reported s. suis-e. coli shuttle vector pset2 was demonstrated. these results indicate that the ts suicide vectors described here will facilitate the genetic analysis of s. suis and other streptococci of veterinary importance by means of allelic exchange of the genes of interest via homologous recombination.
backgroundcancer therapy in malaysia primarily focuses on the clinical management of patients with cancer and malnutrition continues to be one of the major causes of death in these patients. there is a dearth of information on the nutrient intake and status of newly diagnosed patients with cancer prior to the initiation of treatment. the present study aims to assess the nutrient intake and status of newly diagnosed patients with cancer from the east coast of peninsular malaysia.methodsa cross-sectional study was conducted using a convenient sample of newly diagnosed adult patients with cancer (n = 70) attending the oncology clinic, hospital universiti sains malaysia in the east coast of peninsular malaysia. information on socio-demographic characteristics, clinical status, anthropometry, dietary intake and biochemical data including blood samples was obtained.resultsthe mean (sd) age, triceps skin fold (tsf), mid upper arm circumference (muac) and body mass index (bmi) of participants was 21.1(3.9) years, 17.6(7.9) mm, 24.1(5.5) cm, and 21.1(3.9) kg/m2, respectively; 39% participants had bmi <18.5 kg/m2. one-third of newly diagnosed patients with cancer were undernourished (i.e. women: muac <220 mm; men: <230 mm). the proportion (%) of participants with low haemoglobin (<120 g/l) and serum albumin (<38 g/dl) were 62% and 26%, respectively. the older women had significantly lower macro and micro nutrient intakes compared to men in the same age group (p <0.05).conclusionsat the time of diagnosis, greater than one-third of patients with cancer from the east coast of peninsular malaysia were underweight and undernourished. the majority of patients with cancer had poor micronutrient intakes; the older women had a poor macro and micronutrient intakes. before the initiation of rigorous clinical management of patients with cancer, screening for nutritional status, subsequent nutrition counseling, and interventions are essential to improve their nutritional status; consequently, response to cancer therapy, survival and quality of life. arm muscle area (ama, cm2) is currently calculated from triceps skinfold thickness (tsf, cm), and midarm circumference (mac, cm). in assessing the accuracy of the current equation by comparison to ama measured by computerized axial tomography, error in each of the four approximations made was found to result in a 20 to 25% overestimate of ama. two correctible error sources were: a 10 to 15% overestimation caused by assuming a circular midarm muscle compartment and a 5 to 10% overestimation due to inclusion of midarm cross-sectional bone area. corrected ama equations for men and women were respectively: [(mac - pi x tsf)2/4 pi] - 10, and [mac - pi x tsf)2/4 pip] - 6.5. with two additional study groups, the overall improved accuracy of the new equations was confirmed, although the average error for a given patient was 7 to 8%; the relationship between corrected ama and total body muscle mass was established [muscle mass (kg) = (ht, cm2) (0.0264 + 0.0029 x corrected ama)]; and the minimal range of corrected ama values compatible with survival (9 to 11 cm2) was defined. bedside estimates of undernutrition severity and prognosis can therefore be calculated from two simple measurements, tsf and mac.
backgroundalthough a genetic component has been identified as a risk factor for developing inflammatory bowel disease, there is evidence that dietary factors also play a role in the development of this disease.aimsthe aim of this study was to determine the effects of feeding a red meat diet with and without resistant starch (rs) to mice with dextran sulfate sodium (dss)-induced colitis.methodscolonic experimental colitis was induced in balb/c mice using dss. the severity of colitis was evaluated based on a disease activity index (based on bodyweight loss, stool consistency, rectal bleeding, and overall condition of the animal) and a histological score. estimations were made of numbers of a range of different bacteria in the treatment pools of cecal digesta using quantitative real-time pcr.resultsconsumption of a diet high in red meat increased dss-induced colitis as evidenced by higher disease activity and histopathological scores. addition of rs to the red meat diet exerted a beneficial effect in acute dss-induced colitis. subjective analysis of numbers of a range of bacterial targets suggest changes in the gut microbiota abundance were induced by red meat and rs treatments and these changes could contribute to the reported outcomes.conclusionsa dietary intake of red meat aggravates dss-induced colitis whereas co-consumption of resistant starch reduces the severity of colitis. background: we have previously demonstrated that inhibition of dipeptidyl peptidase (dp) activity partially attenuates dextran sulfate sodium (dss) colitis in mice. the aim of this study was to further investigate the mechanisms of this protection. materials and methods: wildtype (wt) and dpiv−/− mice consumed 2% dss in drinking water for 6 days to induce colitis. mice were treated with saline or the dp inhibitors ile‐pyrr‐(2‐cn)*tfa or ile‐thia. dp mrna and enzyme levels were measured in the colon. glucagon‐like peptide (glp)‐2 and glp‐1 concentrations were determined by radioimmunoassay, regulatory t‐cells (tregs) by fluorescence activated cell sorting (facs) on foxp3+t cells in blood, and neutrophil infiltration assessed by myeloperoxidase (mpo) assay. results: dp8 and dp2 mrna levels were increased (p < 0.05) in wt+saline mice compared to untreated wt mice with colitis. cytoplasmic dp enzyme activity was increased (p < 0.05) in dpiv−/− mice at day 6 of dss, while dp2 activity was increased (p < 0.05) in wt mice with colitis. glp‐1 (63%) and glp‐2 (50%) concentrations increased in wt+ile‐pyrr‐(2‐cn)*tfa mice compared to day‐0 controls. mpo activity was lower in wt+ile‐thia and wt+ile‐pyrr‐(2‐cn)*tfa treated mice compared to wt+saline (p < 0.001) at day 6 colitis. conclusions: dp expression and activity are differentially regulated during dss colitis, suggesting a pathophysiological role for these enzymes in human inflammatory bowel disease (ibd). dp inhibitors impaired neutrophil recruitment and maintenance of the treg population during dss‐colitis, providing further preclinical evidence for the potential therapeutic use of these inhibitors in ibd. finally, dpiv appears to play a critical role in mediating the protective effect of dp inhibitors. inflamm bowel dis 2010
meta-schedulers map jobs to computational resources that are part of a grid, such as clusters, that in turn have their own local job schedulers. existing grid meta-schedulers either target system-centric metrics, such as utilisation and throughput, or prioritise jobs based on utility metrics provided by the users. the system-centric approach gives less importance to users' individual utility, while the user-centric approach may have adverse effects such as poor system performance and unfair treatment of users. therefore, this paper proposes a novel meta-scheduler, based on the well-known double auction mechanism that aims to satisfy users' service requirements as well as ensuring balanced utilisation of resources across a grid. we have designed valuation metrics that commodify both the complex resource requirements of users and the capabilities of available computational resources. through simulation using real traces, we compare our scheduling mechanism with other common mechanisms widely used by both existing market-based and traditional meta-schedulers. the results show that our meta-scheduling mechanism not only satisfies up to 15% more user requirements than others, but also improves system utilisation through load balancing. many research and engineering fields, like bioinformatics or particle physics, are confident about the development of grid technologies to provide the huge amounts of computational and storage resources they require. although several projects are working on creating a reliable infrastructure consisting of persistent resources and services, the truth is that the grid will be a more and more dynamic entity as it grows. in this paper, we present a new tool that hides the complexity and dynamicity of the grid from developers and users, allowing the resolution of large computational experiments in a grid environment by adapting the scheduling and execution of jobs to the changing grid conditions and application dynamic demands.
this study investigated the effects of a 16-h protocol of heavy intermittent exercise on the intrinsic activity and protein and isoform content of skeletal muscle na(+)-k(+)-atpase. the protocol consisted of 6 min of exercise performed once per hour at approximately 91% peak aerobic power (vo(2 peak)) with tissue sampling from vastus lateralis before (b) and immediately after repetitions 1 (r1), 2 (r2), 9 (r9), and 16 (r16). eleven untrained volunteers with a vo(2 peak) of 44.3 +/- 2.3 ml x kg(-1) x min(-1) participated in the study. maximal na(+)-k(+)-atpase activity (v(max), in nmol x mg protein(-1) x h(-1)) as measured by the 3-o-methylfluorescein k(+)-stimulated phosphatase assay was reduced (p < 0.05) by approximately 15% with exercise regardless of the number of repetitions performed. in addition, v(max) at r9 and r16 was lower (p < 0.05) than at r1 and r2. vanadate-facilitated [(3)h]ouabain determination of na(+)-k(+)-atpase content (maximum binding capacity, pmol/g wet wt), although unaltered by exercise, increased (p < 0.05) 8.3% by r9 with no further increase observed at r16. assessment of relative changes in isoform abundance measured at b as determined by quantitative immunoblotting showed a 26% increase (p < 0.05) in the alpha(2)-isoform by r2 and a 29% increase in alpha(3) by r9. at r16, beta(3) was lower (p < 0.05) than at r2 and r9. no changes were observed in alpha(1), beta(1), or beta(2). it is concluded that repeated sessions of heavy exercise, although resulting in increases in the alpha(2)- and alpha(3)-isoforms and decreases in beta(3)-isoform, also result in depression in maximal catalytic activity. the purpose of this study was to investigate the hypothesis that a single, extended session of heavy exercise would be effective in inducing adaptations in energy metabolism during exercise in the absence of increases in oxidative potential. ten healthy males [maximal aerobic power (vo(2 peak)) = 43.4 +/- 2.2 (se) ml x kg(-1) x min(-1)] participated in a 16-h training session involving cycling for 6 min each hour at approximately 90% of maximal oxygen consumption. measurements of metabolic changes were made on tissue extracted from the vastus lateralis during a two-stage standardized submaximal cycle protocol before (pre) and 36-48 h after (post) the training session. at pre, creatine phosphate (pcr) declined (p < 0.05) by 32% from 0 to 3 min and then remained stable until 20 min of exercise at 60% vo(2 peak) before declining (p < 0.05) by a further 35% during 20 min of exercise at 75% vo(2 peak). muscle lactate (mmol/kg dry wt) progressively increased (p < 0.05) from 4.59 +/- 0.64 at 0 min to 17.8 +/- 2.7 and 30.9 +/- 5.3 at 3 and 40 min, respectively, whereas muscle glycogen (mmol glucosyl units/kg dry wt) declined (p < 0.05) from a rest value of 360 +/- 24 to 276 +/- 31 and 178 +/- 36 at similar time points. during exercise after the training session, pcr and glycogen were not as depressed (p < 0.05), and increases in muscle lactate were blunted (p < 0.05). all of these changes occurred in the absence of increases in oxidative potential as measured by the maximal activities of citrate synthase and malate dehydrogenase. these findings are consistent with other studies, namely, that muscle metabolic adaptations to regular exercise are an early adaptive event that occurs before increases in oxidative potential.
privacy preservation has recently received considerable attention for location-based mobile services. a lot of location cloaking approaches focus on identity and location protection, but few algorithms pay attention to prevent sensitive information disclosure using query semantics. in terms of personalized privacy requirements, all queries in a cloaking set, from some user’s point of view, are sensitive. these users regard the privacy is breached. this attack is called as the sensitivity homogeneity attack. we show that none of the existing location cloaking approaches can effectively resolve this problem over road networks. we propose a (k, l, p)-anonymity model and a personalized privacy protection cloaking algorithm over road networks, aiming at protecting the identity, location and sensitive information for each user. the main idea of our method is first to partition users into different groups as anonymity requirements. then, unsafe groups are adjusted by inserting relaxed conservative users considering sensitivity requirements. finally, segments covered by each group are published to protect location information. the efficiency and effectiveness of the method are validated by a series of carefully designed experiments. the experimental results also show that the price paid for defending against sensitivity homogeneity attacks is small. in this paper we discuss a new type of query in spatial databas es, called the trip planning query (tpq). given a set of points of interestp in space, where each point belongs to a specific category, a star ting points and a destinatione, tpq retrieves thebesttrip that starts at s, passes through at least one point from each category, and ends at e. for example, a driver traveling from boston to providence might want to stop to a gas station, a ban k and a post office on his way, and the goal is to provide him with the best possibl e route (in terms of distance, traffic, road conditions, etc.). the difficulty of this query lies in the existence of multiple choices per category. in this paper, w study fast approximation algorithms for tpq in a metric space. we provide a numb er of approximation algorithms with approximation ratios that depend o either the number of categories, the maximum number of points per category or b oth. therefore, for different instances of the problem, we can choose the alg orithm with the best approximation ratio, since they all run in polynomial time. furthermore, we use some of the proposed algorithms to derive efficient heuristi cs for large datasets stored in external memory. finally, we give an experimental ev luation of the proposed algorithms using both synthetic and real datasets .
in maize and other grasses there is a developmental gradient from the meristematic cells at the base of the stalk to the differentiated cells at the leaf tip. this gradient presents an opportunity to investigate changes in mitochondrial dna (mtdna) that accompany growth under light and dark conditions, as done previously for plastid dna. maize mtdna was analyzed by dapi-dna staining of individual mitochondria, gel electrophoresis/blot hybridization, and real-time qpcr. both the amount and integrity of the mtdna were found to decline with development. there was a 20-fold decline in mtdna copy number per cell from the embryo to the light-grown leaf blade. the amount of dna per mitochondrial particle was greater in dark-grown leaf blade (24 copies, on average) than in the light (2 copies), with some mitochondria lacking any detectable dna. three factors that influence the demise of mtdna during development are considered: (1) the decision to either repair or degrade mtdna molecules that are damaged by the reactive oxygen species produced as byproducts of respiration; (2) the generation of atp by photophosphorylation in chloroplasts, reducing the need for respiratory-competent mitochondria; and (3) the shift in mitochondrial function from energy-generating respiration to photorespiration during the transition from non-green to green tissue. in maize (zea mays l.), chloroplast development progresses from the basal meristem to the mature leaf tip, and light is required for maturation to photosynthetic competence. during chloroplast greening, it was found that chloroplast dna (cpdna) is extensively degraded, falling to undetectable levels in many individual chloroplasts for three maize cultivars, as well as zea mexicana (the ancestor of cultivated maize) and the perennial species zea diploperennis. in dark-grown maize seedlings, the proplastid-to-etioplast transition is characterized by plastid enlargement, cpdna replication, and the retention of high levels of cpdna. when dark-grown seedlings are transferred to white light, the dna content per plastid increases slightly during the first 4 h of illumination and then declines rapidly to a minimum at 24 h during the etioplast-to-chloroplast transition. plastid autofluorescence (from chlorophyll) continues to increase as cpdna declines, whereas plastid size remains constant. it is concluded that the increase in cpdna that accompanies plastid enlargement is a consequence of cell and leaf growth, rather than illumination, whereas light stimulates photosynthetic capacity and cpdna instability. when cpdna from total tissue was monitored by blot hybridization and real-time quantitative pcr, no decline following transfer from dark to light was observed. the lack of agreement between dna per plastid and cpdna per cell may be attributed to nupts (nuclear sequences of plastid origin).
this study evaluated the implementation of computerized cognitive-behavioral therapy (ccbt) for depression and anxiety in a university health center. students reporting symptoms of depression and/or anxiety were offered ccbt and randomized to a session email reminder or no-reminder condition. participants reported significant symptom and functional improvement after receiving treatment, comparable to outcomes achieved in controlled efficacy trials. however, rates of session completion were low, and reminders did not enhance retention. results suggest that ccbt is a promising intervention in this population, with little attenuation of gains relative to efficacy trials but low levels of treatment completion. objective while considerable attention has focused on improving the detection of depression, assessment of severity is also important in guiding treatment decisions. therefore, we examined the validity of a brief, new measure of depression severity.   measurements the patient health questionnaire (phq) is a self-administered version of the prime-md diagnostic instrument for common mental disorders. the phq-9 is the depression module, which scores each of the 9 dsm-iv criteria as "0" (not at all) to "3" (nearly every day). the phq-9 was completed by 6,000 patients in 8 primary care clinics and 7 obstetrics-gynecology clinics. construct validity was assessed using the 20-item short-form general health survey, self-reported sick days and clinic visits, and symptom-related difficulty. criterion validity was assessed against an independent structured mental health professional (mhp) interview in a sample of 580 patients.   results as phq-9 depression severity increased, there was a substantial decrease in functional status on all 6 sf-20 subscales. also, symptom-related difficulty, sick days, and health care utilization increased. using the mhp reinterview as the criterion standard, a phq-9 score > or =10 had a sensitivity of 88% and a specificity of 88% for major depression. phq-9 scores of 5, 10, 15, and 20 represented mild, moderate, moderately severe, and severe depression, respectively. results were similar in the primary care and obstetrics-gynecology samples.   conclusion in addition to making criteria-based diagnoses of depressive disorders, the phq-9 is also a reliable and valid measure of depression severity. these characteristics plus its brevity make the phq-9 a useful clinical and research tool.
α2-adrenoceptors (α2ar) lower central sympathetic output and peripheral catecholamine release, and may therefore prevent sympathetic hyperactivity and hypertension. the α2ar are dysfunctional in male spontaneously hypertensive rats (shr). premenopausal females are less hypertensive than males. the purpose of this study was to test if this difference could be explained by functional α2ar in the female shr. a 15-min tyramine-infusion was used to stimulate norepinephrine release through the re-uptake transporter, consequently preventing re-uptake. presynaptic control of vesicular release will therefore be reflected as differences in overflow to plasma. the surgical trauma activates secretion of epinephrine, also subjected to α2ar auto-inhibition. blood pressure was monitored through a femoral artery catheter and cardiac output by ascending aorta flow in 12-14 weeks-old (early hypertension) shr and normotensive rats (wky). total peripheral vascular resistance (tpr) was calculated. female shr, unlike male, were close to normotensive. pre-treatment with none-selective (clonidine) or non-a-selective (st-91) α2ar agonist reduced, and none-selective α2ar antagonist (l-659,066) increased tyramine-induced norepinephrine overflow in female wky and shr. l-659,066 also increased secretion of epinephrine. the l-659,066-induced increase in catecholamine release was further enhanced by additional pre-treatment with st-91 or angiotensin at1 receptor antagonist (losartan) in shr only. l-659,066 eliminated the tyramine-induced rise in tpr in both strains in female rats. conclusion: α2ar-mediated control of catecholamine release and vascular tension was therefore functional in female shr, unlike that previously observed in male shr. functional α2ar is likely to have a protective function and may explain the lack of hypertension in the young female shr. α2-adrenoceptors (ar) lower central sympathetic output and peripheral catecholamine release, thereby protecting against sympathetic hyperactivity and hypertension. norepinephrine re-uptake–transporter effectively (net) removes norepinephrine from the synapse. overflow to plasma will therefore not reflect release. here we tested if inhibition of re-uptake allowed presynaptic α2ar release control to be reflected as differences in norepinephrine overflow in anesthetized hypertensive spontaneously hypertensive rats (shr) and normotensive rats (wky). we also tested if α2ar modulated the experiment-induced epinephrine secretion, and a phenylephrine-induced, α1-adrenergic vasoconstriction. blood pressure was recorded through a femoral artery catheter, and cardiac output by ascending aorta flow. after pre-treatment with net inhibitor (desipramine), and/or α2ar antagonist (yohimbine, l-659,066) or agonist (clonidine, st-91), we injected phenylephrine. arterial blood was sampled 15 min later. plasma catecholamine concentrations were not influenced by phenylephrine, and therefore reflected effects of pre-treatment. desipramine and α2ar antagonist separately had little effect on norepinephrine overflow. combined, they increased norepinephrine overflow, particularly in shr. clonidine, but not st-91, reduced, and pertussis toxin increased norepinephrine overflow in shr and epinephrine secretion in both strains. l-659,066 + clonidine (central α2ar-stimulation) normalized the high blood pressure, heart rate, and vascular tension in shr. α2ar antagonists reduced phenylephrine-induced vasoconstriction equally in wky and shr. conclusions: α2aar inhibition increased norepinephrine overflow only when re-uptake was blocked, and then with particular efficacy in shr, possibly due to their high sympathetic tone. α2aar inhibited epinephrine secretion, particularly in shr. α2aar supported α1ar-induced vasoconstriction equally in the two strains. α2ar malfunctions were therefore not detected in shr under this basal condition.
coactivation of antagonist muscles is readily observed early in motor learning, in interactions with unstable mechanical environments and in motor system pathologies. here we present evidence that the nervous system uses coactivation control far more extensively and that patterns of cocontraction during movement are closely tied to the specific requirements of the task. we have examined the changes in cocontraction that follow dynamics learning in tasks that are thought to involve finely sculpted feedforward adjustments to motor commands. we find that, even following substantial training, cocontraction varies in a systematic way that depends on both movement direction and the strength of the external load. the proportion of total activity that is due to cocontraction nevertheless remains remarkably constant. moreover, long after indices of motor learning and electromyographic measures have reached asymptotic levels, cocontraction still accounts for a significant proportion of total muscle activity in all phases of movement and in all load conditions. these results show that even following dynamics learning in predictable and stable environments, cocontraction forms a central part of the means by which the nervous system regulates movement. cocontraction (the simultaneous activation of antagonist muscles around a joint) provides the nervous system with a way to adapt the mechanical properties of the limb to changing task requirements-both in statics and during movement. however, relatively little is known about the conditions under which the motor system modulates limb impedance through cocontraction. the goal of this study was to test for a possible relationship between cocontraction and movement accuracy in multi-joint limb movements. the electromyographic activity of seven single- and double-joint shoulder and elbow muscles was recorded using surface electrodes while subjects performed a pointing task in a horizontal plane to targets that varied randomly in size. movement speed was controlled by providing subjects with feedback on a trial-to-trial basis. measures of cocontraction were estimated both during movement and during a 200-ms window immediately following movement end. we observed an inverse relationship between target size and cocontraction: as target size was reduced, cocontraction activity increased. in addition, trajectory variability decreased and endpoint accuracy improved. this suggests that, although energetically expensive, cocontraction may be a strategy used by the motor system to facilitate multi-joint arm movement accuracy. we also observed a general trend for cocontraction levels to decrease over time, supporting the idea that cocontraction and associated limb stiffness are reduced over the course of practice.
cytochrome c (cyt c) participates in two crucial cellular processes, energy production and apoptosis, and unsurprisingly is a highly conserved protein. however, previous studies have reported for the primate lineage (i) loss of the paralogous testis isoform, (ii) an acceleration and then a deceleration of the amino acid replacement rate of the cyt c somatic isoform, and (iii) atypical biochemical behavior of human cyt c. to gain insight into the cause of these major evolutionary events, we have retraced the history of cyt c loci among primates. for testis cyt c, all primate sequences examined carry the same nonsense mutation, which suggests that silencing occurred before the primates diversified. for somatic cyt c, maximum parsimony, maximum likelihood, and bayesian phylogenetic analyses yielded the same tree topology. the evolutionary analyses show that a fast accumulation of non-synonymous mutations (suggesting positive selection) occurred specifically on the anthropoid lineage root and then continued in parallel on the early catarrhini and platyrrhini stems. analysis of evolutionary changes using the 3d structure suggests they are focused on the respiratory chain rather than on apoptosis or other cyt c functions. in agreement with previous biochemical studies, our results suggest that silencing of the cyt c testis isoform could be linked with the decrease of primate reproduction rate. finally, the evolution of cyt c in the two sister anthropoid groups leads us to propose that somatic cyt c evolution may be related both to cox evolution and to the convergent brain and body mass enlargement in these two anthropoid clades. rates of molecular evolution vary over time and, hence, among lineages. in contrast, widely used methods for estimating divergence times from molecular sequence data assume constancy of rates. therefore, methods for estimation of divergence times that incorporate rate variation are attractive. improvements on a previously proposed bayesian technique for divergence time estimation are described. new parameterization more effectively captures the phylogenetic structure of rate evolution on a tree. fossil information and other evidence can now be included in bayesian analyses in the form of constraints on divergence times. simulation results demonstrate that the accuracy of divergence time estimation is substantially enhanced when constraints are included.
abstract the strengths of interpersonal dyads formed by the attacker and defender in one-on-one situations are crucial for performance in team ball sports such as soccer. the purpose of this study was to analyze the kinematics of one-on-one defensive movements in soccer competitions, and determine the relationships between lower limb kinematics and the center of mass translation during cutting actions. six defensive scenes in which a player was responding to an offender’s dribble attack were selected for analysis. to reconstruct the three-dimensional kinematics of the players, we used a photogrammetric model-based image-matching technique. the hip and knee kinematics were calculated from the matched skeleton model. in addition, the center of mass height was expressed as a ratio of each participant’s body height. the relationships between the center of mass height and the kinematics were determined by the pearson’s product-moment correlation coefficient. the normalized center of mass height at initial contact was correlated with the vertical center of mass displacement (r = 0.832, p = 0.040) and hip flexion angle at initial contact (r = −0.823, p = 0.044). this suggests that the lower center of mass at initial contact is an important factor to reduce the downwards vertical center of mass translation during defensive cutting actions, and that this is executed primarily through hip flexion. it is therefore recommended that players land with an adequately flexed hip at initial contact during one-on-one cutting actions to minimize the vertical center of mass excursion. in many situations, e.g. sports injuries, three-dimensional kinematics cannot be obtained with traditional lab methods. however, if methods for reconstructing motion patterns from video sequences were available, our understanding of injury mechanisms could be improved. the aim of this study was to assess the accuracy of a new model-based image-matching technique for human motion reconstruction from one or more uncalibrated video sequences, using traditional motion analysis as a gold standard. a laboratory trial was conducted with one test subject performing jogging and side step cutting, while being filmed with three ordinary video cameras. this provided three single camera matchings, three double camera matchings and one triple camera matching for each of the motions. the test subject wore 33 reflective skin markers and was filmed with a seven-camera, 240 hz motion analysis system. root mean square (rms) hip and knee flexion/extension angle differences were less than 12 degrees for all the matchings. estimates for ad-/abduction (<15 degrees) and internal/external rotation (<16 degrees) were less precise. rms velocity differences up to 0.62 m/s were found for the single camera matchings, but for the triple camera matching the rms differences were less than 0.13 m/s for each direction. in conclusion, a new model-based image-matching technique has been developed, that can be used to estimate temporal joint angle histories, velocities and accelerations from uncalibrated video recordings. the kinematic estimates, in particular for center of mass velocity and acceleration, are clearly better when two or more camera views are available. this method can potentially be used to arrive at more precise descriptions of the mechanisms of sports injuries than what has been possible without elaborate methods for three-dimensional reconstruction from uncalibrated video sequences, e.g. for knee injuries.
body tilt angle affects the fatigue of human calf muscle at a high contractile force (i.e. 70 %mvc); but the range of forces across which this effect occurs is not known and we sought to determine this in the present study. fourteen men performed intermittent calf muscle contractions at either 30, 40, 50 and 60 %mvc (group 1 n = 7) or at 80 and 90 %mvc (group 2 n = 7). two tests were performed at each intensity in the supine (tilt angle = 0°) and inclined head-up position (tilt angle = 67°). mvc was measured prior to and during each calf exercise test, and the linear rate of decline in mvc during each test was used to estimate muscle fatigue. mvc prior to each test was unaffected by body tilt angle in groups 1 and 2. in group 1 muscle fatigue was significantly lower in the inclined than supine position at 50 %mvc (0.10 ± 0.05 vs. 0.19 ± 0.10 n s−1) and 60 %mvc (0.22 ± 0.20 vs. 0.36 ± 0.33 n s−1); but there was no significant difference in fatigue at 30 %mvc (0.07 ± 0.06 vs. 0.07 ± 0.07 n s−1) and 40 %mvc (0.12 ± 0.07 vs. 0.18 ± 0.08 n s−1). in group 2, muscle fatigue was significantly lower in the inclined compared with the supine position at 80 %mvc (0.90 ± 0.50 vs. 1.49 ± 0.87 n s−1) and 90 %mvc (1.19 ± 0.47 vs. 1.79 ± 0.78 n s−1). these data demonstrate that the postural effect on calf muscle fatigue during intermittent contractions is manifest at moderate to very high forces, but that it does not occur at low forces. to explore the effect of posture on muscle performance, we tested the effects of body tilt angle on the strength, endurance, and fatigue of, and blood flow into, the plantar flexors. human subjects were fixed to a tilt table that could tilt them from the horizontal (0 degrees ) to upright (90 degrees ) position and enabled force to be applied to a footplate through isometric action of the right calf muscle. in experiment 1, six subjects performed a strength test and graded test (intermittent contractions) to the point of failure at three tilt angles (0, 47, and 90 degrees ). in experiment 2, seven subjects performed a strength test and constant-force test [70% maximum force (f(max)); intermittent contractions] to the point of failure in the horizontal and three inclined positions (32, 47, and 67 degrees ). in experiment 3, leg blood flow was assessed during constant-force exercise at two intensities (30 and 70% f(max)) and two tilt angles (0 and 67 degrees ) in six subjects. strength was not affected (p > 0.05) by tilt angle. time to failure during the graded test was significantly higher at 47 degrees (25.9 +/- 2.0 min) and 90 degrees (25.1 +/- 3.0 min) than 0 degrees (22.2 +/- 2.6 min). time to failure during the constant-force test was also significantly higher at 32 degrees (7.1 +/- 3.6 min), 47 degrees (8.0 +/- 5.2 min), and 67 degrees (8.6 +/- 5.6 min) compared with 0 degrees (4.0 +/- 2.6 min). when graded or constant-force exercise was performed with arterial flow to the leg eliminated, there were no differences in exercise time between the horizontal and an inclined position. during nonischemic exercise, leg blood flow was significantly higher during exercise in the inclined position. these results demonstrate that head-up tilt improves endurance of the plantar flexors, that this effect occurs in the absence of an effect on strength, and that it depends on an intact peripheral circulation. moreover, the postural effect on muscle endurance appears to be due to a greater blood flow into the leg, an effect that is established during the initial contractions.
beyond recognizing the actions of individuals, activity group localization aims to determine ‘‘who participates in each group’’ and ‘‘what activity the group performs’’. in this paper, we propose a latent graphical model to group participants while inferring each group’s activity by exploring the relations among them, thus simultaneously addressing the problems of group localization and activity recognition. our key insight is to exploit the relational graph among the participants. specifically, each group is represented as a tree with an activity label while relations among groups are modeled as a fully connected graph. inference of such a graph is reduced into an extended minimum spanning forest problem, which is casted into a max-margin framework. it therefore avoids the limitation of high-ordered hierarchical model and can be solved efficiently. our model is able to provide strong and discriminative contextual cues for activity recognition and to better interpret scene information for localization. experiments on three datasets demonstrate that our model achieves significant improvements in activity group. localization and state-of-the-arts performance on activity recognition. in this paper we present a framework for the recognition of collective human activities. a collective activity is defined or reinforced by the existence of coherent behavior of individuals in time and space. we call such coherent behavior ‘crowd context’. examples of collective activities are “queuing in a line” or “talking”. following [7], we propose to recognize collective activities using the crowd context and introduce a new scheme for learning it automatically. our scheme is constructed upon a random forest structure which randomly samples variable volume spatio-temporal regions to pick the most discriminating attributes for classification. unlike previous approaches, our algorithm automatically finds the optimal configuration of spatio-temporal bins, over which to sample the evidence, by randomization. this enables a methodology for modeling crowd context. we employ a 3d markov random field to regularize the classification and localize collective activities in the scene. we demonstrate the flexibility and scalability of the proposed framework in a number of experiments and show that our method outperforms state-of-the art action classification techniques [7, 19].
ad-hoc networks enable mobile devices to communicate without any fixed infrastructure. while reliable multicasting has been identified as a key application in this context, we analyze different aspects of ad-hoc networks and their impact on application-layer multicast. as a result, we propose a technique of local broadcast-clustering, making use of the wireless medium's broadcast capability. we further describe a simple congestion control and also a technique for avoiding an overlay's routing inconsistencies and, thus, for stabilizing the delivery of multicast data. we describe a new scalable application-layer multicast protocol, specifically designed for low-bandwidth, data streaming applications with large receiver sets. our scheme is based upon a hierarchical clustering of the application-layer multicast peers and can support a number of different data delivery trees with desirable properties.we present extensive simulations of both our protocol and the narada application-layer multicast protocol over internet-like topologies. our results show that for groups of size 32 or more, our protocol has lower link stress (by about 25%), improved or similar end-to-end latencies and similar failure recovery properties. more importantly, it is able to achieve these results by using orders of magnitude lower control traffic.finally, we present results from our wide-area testbed in which we experimented with 32-100 member groups distributed over 8 different sites. in our experiments, average group members established and maintained low-latency paths and incurred a maximum packet loss rate of less than 1% as members randomly joined and left the multicast group. the average control overhead during our experiments was less than 1 kbps for groups of size 100.
backgrounddrug-drug interaction extraction (ddi) needs assistance from automated methods to address the explosively increasing biomedical texts. in recent years, deep neural network based models have been developed to address such needs and they have made significant progress in relation identification.methodswe propose a dependency-based deep neural network model for ddi extraction. by introducing the dependency-based technique to a bi-directional long short term memory network (bi-lstm), we build three channels, namely, linear channel, dfs channel and bfs channel. all of these channels are constructed with three network layers, including embedding layer, lstm layer and max pooling layer from bottom up. in the embedding layer, we extract two types of features, one is distance-based feature and another is dependency-based feature. in the lstm layer, a bi-lstm is instituted in each channel to better capture relation information. then max pooling is used to get optimal features from the entire encoding sequential data. at last, we concatenate the outputs of all channels and then link it to the softmax layer for relation identification.resultsto the best of our knowledge, our model achieves new state-of-the-art performance with the f-score of 72.0% on the ddiextraction 2013 corpus. moreover, our approach obtains much higher recall value compared to the existing methods.conclusionsthe dependency-based bi-lstm model can learn effective relation information with less feature engineering in the task of ddi extraction. besides, the experimental results show that our model excels at balancing the precision and recall values. syntactic features play an essential role in identifying relationship in a sentence. previous neural network models directly work on raw word sequences or constituent parse trees, thus often suffer from irrelevant information introduced when subjects and objects are in a long distance. in this paper, we propose to learn more robust relation representations from shortest dependency paths through a convolution neural network. we further take the relation directionality into account and propose a straightforward negative sampling strategy to improve the assignment of subjects and objects. experimental results show that our method outperforms the state-of-theart approaches on the semeval-2010 task 8 dataset.
for the low-cost hardware-based intrusion detection systems, this paper proposes a memory-efficient parallel string matching scheme. in order to reduce the number of state transitions, the finite state machine tiles in a string matcher adopt bit-level input symbols. long target patterns are divided into subpatterns with a fixed length; deterministic finite automata are built with the subpatterns. using the pattern dividing, the variety of target pattern lengths can be mitigated, so that memory usage in homogeneous string matchers can be efficient. in order to identify each original long pattern being divided, a two-stage sequential matching scheme is proposed for the successive matches with subpatterns. experimental results show that total memory requirements decrease on average by 47.8 percent and 62.8 percent for snort and clamav rule sets, in comparison with several existing bit-split string matching methods. due to the advantages of easy re-configurability and scalability, the memory-based string matching architecture is widely adopted by network intrusion detection systems (nids). in order to accommodate the increasing number of attack patterns and meet the throughput requirement of networks, a successful nids system must have a memory-efficient pattern-matching algorithm and hardware design. in this paper, we propose a memory-efficient pattern-matching algorithm which can significantly reduce the memory requirement. for total snort string patterns, the new algorithm achieves 29% of memory reduction compared with the traditional aho-corasick algorithm [5]. moreover, since our approach is orthogonal to other memory reduction approaches, we can obtain substantial gain even after applying the existing state-of-the-art algorithms. for example, after applying the bit-split algorithm [9], we can still gain an additional 22% of memory reduction.
real-time three-dimensional (rt3d) echocardiography is a new image acquisition technique that allows instantaneous acquisition of volumetric images for quantitative assessment of cardiac morphology and function. to quantify many important diagnostic parameters, such as ventricular volume, ejection fraction, and cardiac output, an automatic algorithm to delineate the left ventricle (lv) from rt3d echocardiographic images is essential. while a number of efforts have been made towards segmentation of the lv endocardial (endo) boundaries, the segmentation of epicardial (epi) boundaries remains problematic. in this paper, we present a coupled deformable model that addresses this problem. the idea behind our method is that the volume of the myocardium is close to being constant during a cardiac cycle and our model uses this coupling as an important constraint. we employ two surfaces, each driven by the image-derived information that takes into account ultrasound physics by modeling the speckle statistics using the nakagami distribution while maintaining the coupling. by simultaneously evolving two surfaces, the final segmentation of the myocardium is thus achieved. results from 80 sets of synthetic data and 286 sets of real canine data were evaluated against the ground truth and against outlines from three independent observers, respectively. we show that results obtained with our incompressibility constraint were more accurate than those obtained without constraint or with a wall thickness constraint, and were comparable to those from manual segmentation. this study investigated the use of artificial neural networks (ann) for image segmentation and spatial temporal contour linking for the detection of endocardial contours on echocardiographic images. using a backpropagation network, the system was trained with 279 sample regions obtained from eight training images to segment images into either tissue or blood pool region. the ann system was then applied to parasternal short axis images of 38 patients. spatial temporal contour linking was performed on the segmented images to extract endocardial boarders. left ventricular areas (end-systolic and end-diastolic) determined with the automated system were calculated and compared to results obtained by manual contour tracing performed by two independent investigators. in addition, ejection fractions (ef) were derived using the area-length method and compared with radionuclide ventriculography. image quality was classified as good in 12 (32%), moderate in 13 (34%) and poor in 13 (34%) patients. the ann system provided estimates of end-diastolic and end-systolic areas in 36 (89%) of echocardiograms, which correlated well with those obtained by manual tracing (r = 0.99, see = 1.44). a good agreement was also found for the comparison of ef between the ann system and tc-radionuclide ventriculography (rnv, r = 0.93, see = 6.36). the ann system also performed well in the subset of patients with poor image quality. endocardial contour detection using artificial neural networks and spatial temporal contour linking allows accurate calculations of ventricular areas from transthoracic echocardiograms and performs well even in images with poor quality. this system could greatly enhance the feasibility, accuracy and reproducibility of calculating cardiac areas to derive left ventricular volumes and ejection fractions.
1. what is computational linguistics? 1.1. a few sketches in the history of computational linguistics 2. automatic text processing 2.1. parsing 2.2. computational lexicons and ontologies 2.3. acquisition methodologies 3. applications 4. infrastructural language resources 4.1. european projects 5. nlp in the global information and knowledge society 5.1. nlp in europe 5.2. production and “intelligent” use of the digital content (also multimedia) 6. future perspectives 6.1. the promotion of national languages in the global society and the new internet generation glossary bibliography biographical sketch harnessing the statistical power of neural networks to perform language understanding and symbolic reasoning is difficult, when it requires executing efficient discrete operations against a large knowledge-base. in this work, we introduce a neural symbolic machine, which contains (a) a neural “programmer”, i.e., a sequence-to-sequence model that maps language utterances to programs and utilizes a key-variable memory to handle compositionality (b) a symbolic “computer”, i.e., a lisp interpreter that performs program execution, and helps find good programs by pruning the search space. we apply reinforce to directly optimize the task reward of this structured prediction problem. to train with weak supervision and improve the stability of reinforce, we augment it with an iterative maximum-likelihood training process. nsm outperforms the state-of-the-art on the webquestionssp dataset when trained from question-answer pairs only, without requiring any feature engineering or domain-specific knowledge.
atrial fibrillation (af) is the most frequent form of arrhythmia occurring in the industrialized world. because of its complex nature, each identified form of af requires specialized treatment. thus, an in-depth understanding of the bases of these arrhythmias is essential for therapeutic development. a variety of experimental studies aimed at understanding the mechanisms of af are performed using primary cultures of neonatal rat atrial cardiomyocytes (nrams). previously, we have shown that the distinct advantage of nram cultures is that they allow standardized, systematic, robust re-entry induction in the presence of a constitutively-active acetylcholine-mediated k+ current (ikach-c). experimental studies dedicated to mechanistic explorations of af, using these cultures, often use computer models for detailed electrophysiological investigations. however, currently, no mathematical model for nrams is available. therefore, in the present study we propose the first model for the action potential (ap) of a nram with constitutively-active acetylcholine-mediated k+ current (ikach-c). the descriptions of the ionic currents were based on patch-clamp data obtained from neonatal rats. our monolayer model closely mimics the action potential duration (apd) restitution and conduction velocity (cv) restitution curves presented in our previous in vitro studies. in addition, the model reproduces the experimentally observed dynamics of spiral wave rotation, in the absence and in the presence of drug interventions, and in the presence of localized myofibroblast heterogeneities. 1. voltage clamp studies of the excitatory sodium current, ina, were carried out in rabbit cardiac purkinje fibres using th two‐micro‐electrode technique. previous work has shown the rabbit purkinje fibre to have relatively simple morphology (sommer & johnson, 1968) and electrical structure (colatsky & tsien, 1979a) compared to other cardiac preparations. 2. non‐uniformities in membrane potential were kept small by reducing the size of ina to less than 50 microa/cm2 of total membrane surface area through prepulse inactivation or removal of external sodium, nao. temporal resolution was improved by cooling to 10‐26 degrees c. these adjustments did not greatly alter the measured properties of the sodium channel. 3. under these conditions, sodium currents were recorded satisfying a number of criteria for adequate voltage control. direct measurement of longitudinal non‐uniformity using a second voltage electrode showed only small deviations at the time of peak current. 4. the properties of the sodium channel were examined using conventional protocols. both peak sodium permeability, pna, and steady‐state sodium inactivation, h infinity, showed a sigmoidal dependence on membrane potential. pna rose steeply with small depolarizations, increasing roughly e‐fold per 3.2 mv, and reaching half‐maximal activation at ‐30 +/‐ 2 mv. the h infinity ‐v curve had a midpoint of ‐74.9 +/‐ 2 mv and a reciprocal slope of 4.56 +/‐ 0.13 mv at temperatures of 10‐19.5 degrees c, and showed a dependence on temperature, shifting to more negative potentials with cooling (approximately 3 mv/10 degrees c). recovery of ina from inactivation in double pulse experiments followed a single exponential time course with time constants of 108‐200 msec at 19 degrees c for holding potentials near ‐80 mv. no attempt was made to describe the activation kinetics because of uncertainties about the early time course of the current. 5. these data predict a maximum duration for ina of less than 1‐2 msec and a maximum peak current density of about 500 microa/cm2 under physiological conditions, i.e. 37 degrees c and 150 mm‐nao. this current magnitude is sufficient to discharge the membrane capacitance at rates comparable to those measured experimentally (311 +/‐ 27 v/sec, colatsky & tsien, 1979a). 6. the limitations of the method are discussed. the major problem is the longitudinal cable delay which limits the speed of voltage control. this makes it difficult to separate the activation of ina from the decay of the capacity transient for potentials positive to ‐15 mv. 7. it is concluded that the approach described is valid for measurements of sodium currents in the potential range where action potentials are initiated, making it possible to study cardiac sodium channels in an adult mammalian preparation which is free of enzymatic treatment.
exact assessment of the autonomic nervous system’s (ans) activity by means of heart rate variability (hrv) is a long-standing challenge. although many techniques have been proposed to take up the challenge, none ever proposed a rationale for the approach behind the technique or a satisfying discrimination of the two activities which underlie the autonomic control of hrv. we here propose a new method, providing both an understanding of the discrimination’s nature and a framework which we believe leads to a thorough assessment of the sympathovagal balance, as a trajectory between points in a well-chosen space. the methodology assumes tools from scale invariance/covariance physics. the sympathovagal balance is obtained on a beat-to-beat basis with the dynamics portrayed through a trajectory. furthermore, universal trajectories are sought which would comprehensively describe the effect of atropine and isoproterenol injections on systems underlying the heart pace variations. non-invasive assessment of the respective activities of the sympathetic and parasympathetic subsystems of the ans would be possible through cardiac autonomic measurements. general introduction from fractal objects to fractal spaces fractal dimension of a quantum path the fractal structure of the quantum space-time towards a linear theory of scale relativity prospects.
self-serving cognitions and callous-unemotional traits play important roles in adolescent antisocial behavior. the objective of this study was to cross-sectionally explore the mediating role of self-serving cognitions in the relationship between callous-unemotional traits and antisocial behavior. a sample of 972 high-school students completed self-report questionnaires assessing callous-unemotional traits, self-serving cognitive distortions and antisocial behavior. two competing models exploring indirect effects accounting for the relationships between self-serving cognitive distortions, callous-unemotional traits and antisocial behaviors were tested. both models revealed significant indirect effects, suggesting both pathways are possible. gender was found to moderate these models. these findings suggest the importance of targeting self-serving cognitions in therapeutic interventions and increase our understanding of the role of self-serving cognitions in antisocial behavior. this study investigates the relationship between the self-report youth psychopathic traits inventory (ypi) and the clinician-rated psychopathy checklist: youth version (pcl:yv). a representative sample of 92 girls and 70 boys, 12 to 20 years of age (mean age, 17 years), who received services at a clinic for adolescents with substance misuse problems, was studied. moderate correlations (r =.30—.51) were found between conceptually corresponding ypi and pcl:yv factor scores among both boys and girls, whereas correlations between individual subscales of the ypi and items of the pcl:yv were not as consistent. a cross-tabulation of groupings based on the three-factor models of the two instruments largely supported the categorical convergent validity of the ypi, particularly for low and high scorers. although more studies with larger samples are needed, results indicate that the ypi is a cost-effective measure of psychopathic traits in adolescents in research settings.
due to the wide application of composite insulators in the power industry, the insulator performance is challenged by various environments. to determine the flashover performance of rime-iced composite insulator, laboratory investigation was carried out in an artificial climate chamber to simulate different rime-ice morphology on the insulator surface. the configuration and characteristics of the rime-ice were demonstrated to establish the relationship between the rime-ice parameters and the flashover performance. in accordance with the discharge phenomena, the transition of leakage current (lc) until the flashover was analyzed by using a recurrent plot approach. after extracting the high frequency components by using a wavelet transform technique, the lc just before the flashover was extended to m dimensional phase space based on a phase space reconstructed method. the recurrent plot was obtained to reveal the non-linear characteristics of lc for identifying the dynamic behaviors on the insulator surface. it is shown that the propagation and properties of the discharges can be graphically projected on the topological structure of recurrent plot as a function of the rime-ice parameters. the process and underlying mechanism of flashover performance of rime-iced composite insulator can be visually reflected by the recurrent plot and the quantitative indicators of lc. due to the widespread use of polymeric insulating materials in radiation environments, there is an increasing demand to evaluate the radiation effects on the surface dielectric characteristics of polymeric insulating materials. this paper presents a recurrence plot approach to analyze the surface discharge of gamma-ray irradiated polymeric insulating materials based on the tracking test described in iec60112. because the resulting comparative tracking index has wide variation, an attempt has been made to evaluate the resistance to tracking more consistently. in this research, for different dosages of gamma-ray irradiation, the discharge currents are detected when the discharge occurs on the sample surface. recurrence plots of the discharge currents are derived. it is found that the resistance to tracking could be projected on a map as a function of the dosage of irradiation. the recurrence plots are sensitive and give visual methods for identification of the dosage of irradiation effects on the resistance to tracking. results obtained show that with the increase of dosage of irradiation, the resistance to tracking of polybutylene terephthalate decreases, but increases for polyethylene terephthalate.
a successful partial delete relaxation method is to compute hff in a compiled planning task ∏c which represents a set c of conjunctions explicitly. while this compilation view of such partial delete relaxation is simple and elegant, its meaning with respect to the original planning task is opaque. we provide a direct characterization of h+(∏c), without compilation, making explicit how it arises from a "marriage" of the critical-path heuristic hm with (a somewhat novel view of) h+. this explicit view allows us to derive a direct characterization of hff (∏c), which in turn allows us to compute a version of that heuristic function in time polynomial in |c|. heuristic functions based on the delete relaxation compute upper and lower bounds on the optimal delete-relaxation heuristic h+, and are of paramount importance in both optimal and satisficing planning. here we introduce a principled and flexible technique for improving h+, by augmenting delete-relaxed planning tasks with a limited amount of delete information. this is done by introducing special fluents that explicitly represent conjunctions of fluents in the original planning task, rendering h+ the perfect heuristic h* in the limit. previous work has introduced a method in which the growth of the task is potentially exponential in the number of conjunctions introduced. we formulate an alternative technique relying on conditional effects, limiting the growth of the task to be linear in this number. we show that this method still renders h+ the perfect heuristic h* in the limit. we propose techniques to find an informative set of conjunctions to be introduced in different settings, and analyze and extend existing methods for lower-bounding and upperbounding h+ in the presence of conditional effects. we evaluate the resulting heuristic functions empirically on a set of ipc benchmarks, and show that they are sometimes much more informative than standard delete-relaxation heuristics.
our research intends to explore whether a social perspective on it business alignment can help shed light on the it value creation process by considering different facets of interpersonal linkage. in this paper, we develop a theoretical model which could be discussed at the jais workshop. further, we use some empirical data from 149 us banks in order to find first empirical evidence whether our research focus represents a promising direction. we find initial support for our main hypotheses that communication, cross-domain knowledge and mutuality among and between it and business staff significantly impact it usage and business process outcomes. the final results of our research could contribute to our understanding of how the it resource should be understood and used to measurably contribute to firm goals. the initial findings support the caveat of recent studies suggesting that informal aspects of alignment might be quite notable (e.g. chan, 2002) and show that our theoretical understanding of alignment should be extended to better incorporate social aspects of daily work life. as interest into the nature and value of electronic data interchange (edi) within organizations continues to grow, it becomes increasingly desirable to establish a tactical linkage between the strategic value of edi and observed operational benefits. this article provides such a tactical linkage by presenting an approach to edi measurement consisting of four facets: volume, diversity, breadth, and depth of a firm's edi initiatives. each of these facets is defined and then described through its application within the contexts of seven case sites, where each case site represents a strategic business unit having a long, successful history of edi use. the article concludes with suggestions for both practice and research.
this paper presents two methods of large-scale recognition of planar objects with a simple representation and approximate search of local feature vectors. a central problem of the use of local feature vectors is the burden of computation and memory for finding nearest neighbors. to solve this problem, the proposed methods embody the following: (1) a simple bit representation of feature vectors and hashing enable us to fast access with less memory, (2) approximate search with query perturbation allows us to find approximate nearest neighbors efficiently. from large-scale experiments using 10,000 objects in the database and 2,000 query images, it was found that only 10‐20% of correct nearest neighbors were enough for achieving recognition rate of 98.0%. the processing time for achieving this rate was 8.3 ms / query (excluding time for feature extraction). we have also tested the scalability of a proposed method using the database of 100,000 objects and obtained the result of 92.3% accuracy in 4.5 ms /query. stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. mikolajczyk and schmid (june 2003) recently evaluated a variety of approaches and identified the sift [d. g. lowe, 1999] algorithm as being the most resistant to common image deformations. this paper examines (and improves upon) the local image descriptor used by sift. like sift, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using sift's smoothed weighted histograms, we apply principal components analysis (pca) to the normalized gradient patch. our experiments demonstrate that the pca-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard sift representation. we also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.
item recommendation is a personalized ranking task. to this end, many recommender systems optimize models with pairwise ranking objectives, such as the bayesian personalized ranking (bpr). using matrix factorization (mf) - the most widely used model in recommendation - as a demonstration, we show that optimizing it with bpr leads to a recommender model that is not robust. in particular, we find that the resultant model is highly vulnerable to adversarial perturbations on its model parameters, which implies the possibly large error in generalization. to enhance the robustness of a recommender model and thus improve its generalization performance, we propose a new optimization framework, namely adversarial personalized ranking (apr). in short, our apr enhances the pairwise ranking method bpr by performing adversarial training. it can be interpreted as playing a minimax game, where the minimization of the bpr objective function meanwhile defends an adversary, which adds adversarial perturbations on model parameters to maximize the bpr objective function. to illustrate how it works, we implement apr on mf by adding adversarial perturbations on the embedding vectors of users and items. extensive experiments on three public real-world datasets demonstrate the effectiveness of apr - by optimizing mf with apr, it outperforms bpr with a relative improvement of 11.2% on average and achieves state-of-the-art performance for item recommendation. our implementation is available at: \urlhttps://github.com/hexiangnan/adversarial_personalized_ranking. we present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. we describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. we give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. we experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.
this paper deals with a distributed decision procedure for determining the electricity price for a future smart grid. in order to derive the optimal regional prices and improve the convergence speed of the algorithm without private information of market players, we propose a price decision algorithm with an alternating decision making of market players. in this paper, we show that the optimal regional prices derived by using our proposed algorithm maximize the social welfare of power networks which includes profits of power consumers and power suppliers with renewable energy generators. also, we discuss the convergence property of the proposed price decision algorithm. finally, the feasibility of our proposed dynamic pricing methodology is shown with numerical simulation results. distributed optimal power flow (opf) is a challenging non-linear, non-convex problem of central importance to the future power grid. although many approaches are currently available in the literature, these require some form of central coordination to properly work. in this paper a fully distributed and robust algorithm for opf is proposed which does not require any form of central coordination. the algorithm is based upon the alternating direction multiplier method (admm) in a form recently proposed by the author, which, in turn, builds upon the work of schizas the approach is customized as a region-based optimization procedure, and it is tested in meaningful scenarios.
purpose – the purpose of this paper is to identify the utility of web of science, scopus and google scholar as citation analysis tools for the social sciences.design/methodology/approach – the 25 most‐accessed articles in 163 social sciences journals are searched in three citation databases.findings – web of science has long been the only tool for citation analysis. scopus and google scholar, while still new to the market, are complementary to web of science and in some cases can provide a more nuanced view of the importance of scholarly articles in the social sciences.practical implications – as libraries struggle to provide the best tools to their users, they may wish to consider the freely‐available google scholar as a substitute or complement to expensive databases such as web of science and scopus.originality/value – most analyses of citation databases have focused on the sciences. because this study examined the social sciences literature, it has expanded on the research available on web of science,... the web of science is no longer the only database which offers citation indexing of the social sciences. scopus, csa illumina and google scholar are new entrants in this market. the holdings and citation records of these four databases were assessed against two sets of data one drawn from the 2001 research assessment exercise and the other from the international bibliography of the social sciences. initially, csa illumina's coverage at journal title level appeared to be the most comprehensive. but when recall and average citation count was tested at article level and rankings extrapolated by submission frequency to individual journal titles, scopus was ranked first. when issues of functionality, the quality of record processing and depth of coverage are taken into account, scopus and web of science have a significant advantage over the other two databases. from this analysis, scopus offers the best coverage from amongst these databases and could be used as an alternative to the web of science as a tool to evaluate the research impact in the social sciences.
past studies suggested that decis ion support systems (dss ) must be an “enabling” system aiming to enhance users’ capabilities and to leverage their skills and intelligence . this suggests that users be the center of dss and users’ characteristics be an important factor of explaining their dss acceptance behavior. since dss are aimed to work in semi -structured and unstructured task environment, perceived task complexity can be used to explain users’ willingness to accept dss. further, several studies also used decision models for investigati ng users’ dss acceptance behavior. we argue that nature of dss (based on their underlying decision models) and its interaction with individual differences also play important roles on users’ dss acceptance behavior. with the conjecture that users’ dss acce ptance behavior directly affects the dss usage and dss success, our research question focuses on how do individual differences influence users’ dss acceptance behavior with consideration of task characteristics and nature of the dss . the contribution of th is paper is multifold. first, we extend the existing understanding of effects of individual differences on users’ dss acceptance behavior. second, we extend two major measurements of cognitive styles ( geft - group embedded figures test and mbti - myers -bri ggs type indicator ) for individual differences in the context of dss. third, we investigate multiple task complexities and multiple dss models. hypotheses are developed and will be tested with an experiment of 300 plus subjects. this paper describes a microeconomic theory-based tool, called cost analysis, which can be used in mis research to develop guidance for systems analysts and information resource managers. an example of this guidance is a matrix of decision making contexts versus appropriate mis/dss support. systems analysts can use this matrix to help identify appropriate mis/dss design alternatives. information resource managers can use this matrix to help plan for the proper evolution of mis/dss support. introduction to reduce the average decision quality produced. this quality can be increased to its initial level via increased this paper describes an approach for determining what investment in mis (e.g., more sophisticated mis) and/or kind of management information systems (mis) or deciin management (e.g., spending for management training sion support systems (dss) are appropriate for various or hiring more competent managers). thus, the cost of decision making contexts. this approach, called cost producing decisions at the intitial guality level increases analysis, is useful in research developing guidance for as problem complexity increases. systems analysts choosing information support for decision makers, and in research developing guidance for alternative mis can be compared based upon the cost of information resource managers planning the mis* portproducing equal quality decison in an environment folio. one result of cost analysis is a matrix of decision described in terms of problem complexity. if the commaking contexts versus appropriate mis support. this plexity assocated with a specific context results in higher matrix can be used by systems analysts to identify viable decision production costs using one mis than that using design alternatives. the matrix can also be used by inforanother mis, then the second mis is preferred. this cost mation resource managers to identify and plan for approanalysis approach is described in greater detail below, priate changes in the firm's mis portfolio. and applied to determining appropriate mis support for contexts within the following descriptive frameworks: cost analysis maps appropriate mis support to various decision contexts based upon problem complexity, and • product life cycle the impact of complexity upon the cost of making decisions. it is hypothesized that the cost of making decisions • gorry-scott morton management planning and of a given quality increases as problem complexity control activities increases.** problem complexity is defined along four dimensions: the product life cycle framework provides a vehicle for understanding the application of cost analysis to mis • problem duration-the time allowed for problem portfolio planning. a profile of appropriate mis is develsolution oped, in accord with changing decision making contexts associated with the manufacture of products progressing • problem homogeneity-the lack of problem type through their life cycles. these changing decision convariety texts reflect changes in marketing and manufucturing strategies. the gorry-scott morton framework provides • problem predictability-the ability to forcast the an opportunity for understanding the application of cost occurrence of problems analysis to systems design. categories of appropriate mis are developed for specific management planning • problem knowledge-the understanding of the and control activities. these catagories can be used by problem; problem structure systems analysts to identify appropriate mis support of managerial activities. a decrease in any of these dimensions represents an increase in problem complexity. for example, a decrease using these two frameworks as examples also allows a in problem knowledge in a decision context is expected demonstration of support for the validity of cost analysis.
our goal is to introduce and describe the utility of a new pipeline “contigs assembly pipeline using reference genome” (caprg), which has been developed to assemble “long sequence reads” for non-model organisms by leveraging a reference genome of a closely related phylogenetic relative. to facilitate this effort, we utilized two avian transcriptomic datasets generated using roche/454 technology as test cases for caprg assembly. we compared the results of caprg assembly using a reference genome with the results of existing methods that utilize de novo strategies such as velvet, pave, and mira by employing parameter space comparisons (intra-assembling comparison). caprg performed as well or better than the existing assembly methods based on various benchmarks for “gene-hunting.” further, caprg completed the assemblies in a fraction of the time required by the existing assembly algorithms. additional advantages of caprg included reduced contig inflation resulting in lower computational resources for annotation, and functional identification for contigs that may be categorized as “unknowns” by de novo methods. in addition to providing evaluation of caprg performance, we observed that the different assembly (inter-assembly) results could be integrated to enhance the putative gene coverage for any transcriptomics study. we have developed a new set of algorithms, collectively called "velvet," to manipulate de bruijn graphs for genomic sequence assembly. a de bruijn graph is a compact representation based on short words (k-mers) that is ideal for high coverage, very short read (25-50 bp) data sets. applying velvet to very short reads and paired-ends information only, one can produce contigs of significant length, up to 50-kb n50 length in simulations of prokaryotic data and 3-kb n50 on simulated mammalian bacs. when applied to real solexa data sets without read pairs, velvet generated contigs of approximately 8 kb in a prokaryote and 2 kb in a mammalian bac, in close agreement with our simulated results without read-pair information. velvet represents a new approach to assembly that can leverage very short reads in combination with read pairs to produce useful assemblies.
this double-blind, placebo-controlled, crossover study investigated the effect of blackcurrant anthocyanin (bca) intake on peripheral circulation during rest and during typing work by using near-infrared spectroscopy (nirs), and it also assessed improvement in shoulder stiffness caused by poor local circulation. in a resting circulation study, nine healthy male subjects took capsules of bca at a dosage of 17 mg kg−1 or placebo (isoenergetic sugar). nirs was used to measure left forearm blood flow (fbf) following venous occlusion and muscle oxygen consumption following arterial occlusion prior to and hourly for 4 h after ingestion of bca. plasma anthocyanin concentration was measured prior to ingestion and 1, 2, and 4 h later. fbf increased significantly 2 h after bca ingestion [bca 1.22 (0.13)-fold increase relative to pre-values vs placebo 0.83 (0.06) of pre-values; p<0.05] and then tended to increase for a further 3 h after ingestion [bca 1.26 (0.15)-fold increase relative to pre-values vs placebo 0.82 (0.07) of pre-values; p=0.078]. there was, however, no significant difference in muscle oxygen consumption between bca and placebo intake at any time point. in a typing work study, 11 healthy subjects took capsules of bca (7.7 mg kg−1) or placebo (isoenergetic sugar) daily for 2 weeks. the subjects then performed intermittent typing workload for 30 min in order to induce acute shoulder stiffness. during the workload, total hemoglobin and oxygenated hemoglobin (oxy-hb) were determined using nirs and myoelectric signals measured in the right trapezius muscle using electromyography (emg). the viscoelasticity of the trapezius muscle was also evaluated using a muscle stiffness meter before and after the typing workload. bca intake prevented the decrease in oxy-hb significantly (p<0.05), and also tended to alleviate the increase in root mean square (rms) of the emg during the typing workload, and also muscle stiffness after the workload. there was no improvement in typing performance with bca intake. the results of this study suggest that intake of bca may improve shoulder stiffness caused by typing work by increasing peripheral blood flow and reducing muscle fatigue. abstract we have investigated the etiology of lower-back muscle fatigue using simultaneous recordings of electromyography (emg), mechanomyography (mmg), and near-infrared spectroscopy (nirs) in an attempt to shed some light on the electrophysiological, mechanical, and metabolic characteristics, respectively. eight male subjects performed isometric back extensions at an angle of 15° with reference to the horizontal plane, for a period of 60 s. surface emg, mmg and nirs signals were recorded simultaneously from the center of the erector spinae at the level of l3. nirs was measured to determine the level of muscle blood volume (bv) and oxygenation (oxy-hb). the root mean square amplitude value (rms) of the emg signal was significantly increased at the initial phase of contraction and then fell significantly, while mean power frequency (mpf) of the emg signal decreased significantly and progressively as a function of time. there were also significant initial increases in rms-mmg that were followed by progressive decreases at the end of fatiguing contractions. mpf-mmg remained unchanged. muscle bv and oxy-hb decreased dramatically at the onset of the contraction and then remained almost constant throughout the rest of the contraction. these results, obtained by simultaneous recordings of emg, mmg, and nirs, demonstrate that the restriction of blood flow due to high intramuscular mechanical pressure is one of the most important factors in muscle fatigue in the lower-back muscles. in addition, the simultaneous recording system described here can be used to obtain more reliable information regarding the mechanism(s) of lower-back muscle fatigue.
we tested between two coding mechanisms that the brain may use to retain distance information about a target for a reaching movement across vergence eye movements. if the brain was to encode a retinal disparity representation (retinal model), i.e., target depth relative to the plane of fixation, each vergence eye movement would require an active update of this representation to preserve depth constancy. alternatively, if the brain was to store an egocentric distance representation of the target by integrating retinal disparity and vergence signals at the moment of target presentation, this representation should remain stable across subsequent vergence shifts (nonretinal model). we tested between these schemes by measuring errors of human reaching movements (n = 14 subjects) to remembered targets, briefly presented before a vergence eye movement. for comparison, we also tested their directional accuracy across version eye movements. with intervening vergence shifts, the memory-guided reaches showed an error pattern that was based on the new eye position and on the depth of the remembered target relative to that position. this suggests that target depth is recomputed after the gaze shift, supporting the retinal model. our results also confirm earlier literature showing retinal updating of target direction. furthermore, regression analyses revealed updating gains close to one for both target depth and direction, suggesting that the errors arise after the updating stage during the subsequent reference frame transformations that are involved in reaching. an experiment investigated in human adults the sensorimotor transformation involved in pointing to a spatial target identified previously by kinesthetic cues. in the “locating phase,” a computer-controlled mechanical arm guided the left [condition lr (left–right)] or right [condition rr (right–right)] finger of the blindfolded participant to one of 27 target positions. in the subsequent “pointing phase,” the participant tried to reach the same position with the right finger. the final finger position and the posture of the arm were measured in both conditions. constant errors were large but consistent and remarkably similar across conditions, suggesting that, whatever the locating hand, target position is coded in an extrinsic frame of reference (target position hypothesis). the main difference between the same-hand (rr) and different-hand (lr) conditions was a symmetric shift of the pattern of endpoints with respect to the midsagittal plane. this effect was modeled accurately by assuming a systematic bias in the perception of the postural angles of the locating arm. the analysis of the variable errors indicated that target position is represented internally in a spherical coordinate system centered on the shoulder of the pointing arm and that the main source of variability is within the planning stage of the pointing movement. locating and pointing postures depended systematically on target position. we tested qualitatively the hypothesis that the selection of both postures (inverse kinematic problem) is constrained by a minimum-distance principle. in condition rr, pointing posture depended also on the locating posture, implying the presence of a memory trace of the previous movement. a scheme is suggested to accommodate the results within an extended version of the target position hypothesis.
conventional pcr methods combined with linkage analysis based on short tandem repeats (strs) or karyomapping with single nucleotide polymorphism (snp) arrays, have been applied to preimplantation genetic diagnosis (pgd) for spinal muscular atrophy (sma), an autosome recessive disorder. however, it has limitations in sma diagnosis by karyomapping, and these methods are unable to distinguish wild-type embryos with carriers effectively. mutated allele revealed by sequencing with aneuploidy and linkage analyses (marsala) is a new method allowing embryo selection by a one-step next-generation sequencing (ngs) procedure, which has been applied in pgd for both autosome dominant and x-linked diseases in our group previously. in this study, we carried out pgd based on marsala for two carrier families with sma affected children. as a result, one of the couples has given birth to a healthy baby free of mutations in sma-causing gene. it is the first time that marsala was applied to pgd for sma, and we can distinguish the embryos with heterozygous deletion (carriers) from the wild-type (normal) ones accurately through this ngs-based method. in addition, direct mutation detection allows us to identify the affected embryos (homozygous deletion), which can be regarded as probands for linkage analysis, in case that the affected family member is absent. in the future, the ngs-based marsala method is expected to be used in pgd for all monogenetic disorders with known pathogenic gene mutation. preimplantation genetic diagnosis (pgd) is well established method for treatment of genetic problems associated with infertility. moreover, pgd with next-generation sequencing (ngs) provide new possibilities for diagnosis and new parameters for evaluation in, for example, aneuploidy screening. the aim of the study was to report the successful pregnancy outcome following pgd with ngs as the method for 24 chromosome aneuploidy screening in the case of robertsonian translocation. day 3 embryos screening for chromosomal aneuploidy was performed in two consecutive in vitro fertilization (ivf) cycles, first with fluorescent in situ hybridization (fish), and then with ngs-based protocol. in each ivf attempt, three embryos were biopsied. short duration of procedures enabled fresh embryo transfer without the need for vitrification. first ivf cycle with the embryo selected using pgd analysis with the fish method ended with pregnancy loss in week 8. the second attempt with ngs-based aneuploidy screening led to exclusion of the following two embryos: one embryo with 22 monosomy and one with multiple aneuploidies. the transfer of the only euploid blastocyst resulted in the successful pregnancy outcome. the identification of the euploid embryo based on the ngs application was the first successful clinical application of ngs-based pgd in the case of the robertsonian translocation carrier couple.
during competitions, elite cross-country skiers produce higher external work rates on uphill than on flat terrain. however, it is not presently known whether this reflects solely higher energy expenditure. furthermore, the kinematic factors associated with these higher rates of uphill work have not yet been examined. therefore, in the present investigation the work rate and associated kinematic parameters at similar metabolic rates during roller ski skating on flat and uphill terrains have been compared. seven elite male skiers performed six 5-min sub-maximal exercise bouts at the same low, moderate and high metabolic rates on 2 and 8% inclines, while roller skiing on a treadmill employing the g3 skating technique. the work rate was calculated as work against gravity and friction, whereas the energetic equivalent of vo2 was taken as the metabolic rate. gross efficiency was defined as work rate divided by metabolic rate. kinematic parameters were analyzed in three dimensions. at the same metabolic rate, the work rate, cycle rate, work per cycle and relative duration of propulsive phases during a cycle of movement were all higher on the 8% than on the 2% incline at all speeds (all p < 0.05). at similar work rates, gross efficiency was greater on the 8% incline (p < 0.05). in conclusion, these elite skiers consistently demonstrated higher work rates on the 8% incline. to achieve the higher work rates on the steeper incline, these elite skiers employed higher cycle rates and performed more work per cycle, in association with a longer relative propulsive phase. objective to examine the effect of an increase in roller ski rolling resistance on the physiological and upper body demands of roller skiing with the v2-alternate technique.   methods nine highly skilled cross-country skiers roller skied at three paced speeds on a flat oval loop using roller skis with high (hir) and low (lowr) rolling resistance. oxygen uptake (vo2), heart rate, and poling forces were measured during the last 30 s and rating of perceived exertion (rpe) was requested immediately after each 4-min bout of roller skiing.   results vo2 and all force-related variables increased significantly with speed and were higher (p < 0.01) for hir at given speeds. poling time was similar between hir and lowr, whereas poling recovery time was shorter (p = 0.0002) and cycle rate was higher (p = 0.002) for hir. for given vo2 levels, peak and average forces, heart rates, and rpe values were similar between hir and lowr, whereas average poling force across the cycle was greater (p = 0.006) and duty cycle (i.e., percentage of cycle when poling forces were applied) was higher (p = 0.0001) with hir.   conclusions 1) the decrease in poling recovery time and increase in cycle rate associated with an increase in roller ski rolling resistance is comparable to the effect previously observed from increasing grade and probably occurs as a means of limiting deceleration. 2) since changes in rolling resistance do not alter the relationships of rpe and heart rate with vo2, the central cardiovascular adaptations from roller ski training should not be affected by the rolling resistance of the roller skis. 3) higher resistance roller skis are likely to induce greater upper body aerobic adaptations than lower resistance roller skis.
action analysis in image and video has been attracting more and more attention in computer vision. recognizing specific actions in video clips has been the main focus. we move in a new, more general direction in this paper and ask the critical fundamental question: what is action, how is action different from motion, and in a given image or video where is the action? we study the philosophical and visual characteristics of action, which lead us to define actionness: intentional bodily movement of biological agents (people, animals). to solve the general problem, we propose the lattice conditional ordinal random field model that incorporates local evidence as well as neighboring order agreement. we implement the new model in the continuous domain and apply it to scoring actionness in both image and video datasets. our experiments demonstrate not only that our new model can outperform the popular ranking svm but also that indeed action is distinct from motion. detecting humans in films and videos is a challenging problem owing to the motion of the subjects, the camera and the background and to variations in pose, appearance, clothing, illumination and background clutter. we develop a detector for standing and moving people in videos with possibly moving cameras and backgrounds, testing several different motion coding schemes and showing empirically that orientated histograms of differential optical flow give the best overall performance. these motion-based descriptors are combined with our histogram of oriented gradient appearance descriptors. the resulting detector is tested on several databases including a challenging test set taken from feature films and containing wide ranges of pose, motion and background variations, including moving cameras and backgrounds. we validate our results on two challenging test sets containing more than 4400 human examples. the combined detector reduces the false alarm rate by a factor of 10 relative to the best appearance-based detector, for example giving false alarm rates of 1 per 20,000 windows tested at 8% miss rate on our test set 1.
backgroundoxygen sensing is a near universal signaling modality that, in eukaryotes ranging from protists such as dictyostelium and toxoplasma to humans, involves a cytoplasmic prolyl 4-hydroxylase that utilizes oxygen and α-ketoglutarate as potentially rate-limiting substrates. a divergence between the animal and protist mechanisms is the enzymatic target: the animal transcriptional factor subunit hypoxia inducible factor-α whose hydroxylation results in its poly-ubiquitination and proteasomal degradation, and the protist e3scfubiquitin ligase subunit skp1 whose hydroxylation might control the stability of other proteins. in dictyostelium, genetic studies show that hydroxylation of skp1 by phya, and subsequent glycosylation of the hydroxyproline, is required for normal oxygen sensing during multicellular development at an air/water interface. because it has been difficult to detect an effect of hypoxia on skp1 hydroxylation itself, the role of skp1 modification was investigated in a submerged model of dictyostelium development dependent on atmospheric hyperoxia.resultsin static isotropic conditions beneath 70-100% atmospheric oxygen, amoebae formed radially symmetrical cyst-like aggregates consisting of a core of spores and undifferentiated cells surrounded by a cortex of stalk cells. analysis of mutants showed that cyst formation was inhibited by high skp1 levels via a hydroxylation-dependent mechanism, and spore differentiation required core glycosylation of skp1 by a mechanism that could be bypassed by excess skp1. failure of spores to differentiate at lower oxygen correlated qualitatively with reduced skp1 hydroxylation.conclusionwe propose that, in the physiological range, oxygen or downstream metabolic effectors control the timing of developmental progression via activation of newly synthesized skp1. o(2) regulates multicellular development of the social amoeba dictyostelium, suggesting it may serve as an important cue in its native soil environment. dictyostelium expresses an hifα-type prolyl 4-hydroxylase (p4h1) whose levels affect the o(2)-threshold for culmination implicating it as a direct o(2)-sensor, as in animals. but dictyostelium lacks hifα, a mediator of animal prolyl 4-hydroxylase signaling, and p4h1 can hydroxylate pro143 of skp1, a subunit of e3(scf)ubiquitin-ligases. skp1 hydroxyproline then becomes the target of five sequential glycosyltransferase reactions that modulate the o(2)-signal. here we show that genetically induced changes in skp1 levels also affect the o(2)-threshold, in opposite direction to that of the modification enzymes suggesting that the latter reduce skp1 activity. consistent with this, overexpressed skp1 is poorly hydroxylated and skp1 is the only p4h1 substrate detectable in extracts. effects of pro143 mutations, and of combinations of skp1 and enzyme level perturbations, are consistent with pathway modulation of skp1 activity. however, some effects were not mirrored by changes in modification of the bulk skp1 pool, implicating a skp1 subpopulation and possibly additional unknown factors. altered skp1 levels also affected other developmental transitions in a modification-dependent fashion. whereas hydroxylation of animal hifα results in its polyubiquitination and proteasomal degradation, dictyostelium skp1 levels were little affected by its modification status. these data indicate that skp1 and possibly e3(scf)ubiquitin-ligase activity modulate o(2)-dependent culmination and other developmental processes, and at least partially mediate the action of the hydroxylation/glycosylation pathway in o(2)-sensing.
the management of the palatal cleft, dental arch, and subsequent maxillary form is a challenge for the craniomaxillofacial surgeon. the purpose of this paper is to present the experience of a senior surgeon (kes) who has treated over 2000 patients with cleft lip and palate. this paper focuses on the experience of a recent series of 103 consecutive orthognathic cases treated by one surgeon with a surgical-orthodontic, speech-oriented approach. it will concentrate on not only correcting the occlusion, as others have described, but also on how a surgeon who was trying to achieve optimal aesthetic balance, harmony, and beauty, approached this problem. craniofacial osteotomies have by convention been bilamellar translocations of the entire substance of the dysmorphic bone. this approach limits the surgeon by reducing the stable bone mass available for fixation, creating dependence on concave surfaces. most important, it changes the bony topography that determines the preoperative plan. this paper presents a new craniofacial concept and technique used in 26 patients with various dysmorphic syndromes who were reconstructed by performing a lamellar split osteotomy. this technique maintains the internal lamella in its native position, thereby allowing it to act as a reference for the bony topography and providing a stable facial framework for rigid fixation. this interlamellar osteotomy has led to improved aesthetic results in the orthomorphic reconstructions of congenital and other deformities. it can be used in any aesthetic patient in whom contour changes or augmentation of form is desired. it is recommended as a preferred method for achieving quantitative contour improvement in patients over 3 years of age.
in 2009, a novel lyssavirus (subsequently named ikoma lyssavirus, ikov) was detected in the brain of an african civet (civettictis civetta) with clinical rabies in the serengeti national park of tanzania. the degree of nucleotide divergence between the genome of ikov and those of other lyssaviruses predicted antigenic distinction from, and lack of protection provided by, available rabies vaccines. in addition, the index case was considered likely to be an incidental spillover event, and therefore the true reservoir of ikov remained to be identified. the advent of sensitive molecular techniques has led to a rapid increase in the discovery of novel viruses. detecting viral sequence alone, however, only allows for prediction of phenotypic characteristics and not their measurement. in the present study we describe the in vitro and in vivo characterization of ikov, demonstrating that it is (1) pathogenic by peripheral inoculation in an animal model, (2) antigenically distinct from current rabies vaccine strains and (3) poorly neutralized by sera from humans and animals immunized against rabies. in a laboratory mouse model, no protection was elicited by a licensed rabies vaccine. we also investigated the role of bats as reservoirs of ikov. we found no evidence for infection among 483 individuals of at least 13 bat species sampled across sites in the serengeti and southern kenya. abstract all lyssaviruses cause fatal encephalitis in mammals. there is sufficient antigenic variation within the genus to cause variable vaccine efficacy, but this variation is difficult to characterize quantitatively: sequence analysis cannot yet provide detailed antigenic information, and antigenic neutralization data have been refractory to high-resolution robust interpretation. here, we address these issues by using state-of-the-art antigenic analyses to generate a high-resolution antigenic map of a global panel of 25 lyssaviruses. we compared the calculated antigenic distances with viral glycoprotein ectodomain sequence data. although 67% of antigenic variation was predictable from the glycoprotein amino acid sequence, there are in some cases substantial differences between genetic and antigenic distances, thus highlighting the risk of inferring antigenic relationships solely from sequence data at this time. these differences included epidemiologically important antigenic differences between vaccine strains and wild-type rabies viruses. further, we quantitatively assessed the antigenic relationships measured by using rabbit, mouse, and human sera, validating the use of nonhuman experimental animals as a model for determining antigenic variation in humans. the use of passive immune globulin is a crucial component of rabies postexposure prophylaxis, and here we also show that it is possible to predict the reactivity of immune globulin against divergent lyssaviruses.
intracellular k+ plays an important role in controlling the cytoplasmic ion homeostasis for maintaining cell volume and inhibiting apoptotic enzymes in the cytosol and nucleus. cytoplasmic k+ concentration is mainly regulated by k+ uptake via na+-k+-atpase and k+ efflux through k+ channels in the plasma membrane. carbonyl cyanide p-trifluoromethoxyphenylhydrazone (fccp), a protonophore that dissipates the h+ gradient across the inner membrane of mitochondria, induces apoptosis in many cell types. in rat and human pulmonary artery smooth muscle cells (pasmc), fccp opened the large-conductance, voltage- and ca2+-sensitive kk+ (maxi-k) channels, increased k+ currents through maxi-k channels [i(k(ca))], and induced apoptosis. tetraethylammonia (1 mm) and iberiotoxin (100 nm) decreased i(k(ca)) by blocking the sarcolemmal maxi-k channels and inhibited the fccp-induced apoptosis in pasmc cultured in media containing serum and growth factors. furthermore, inhibition of k+ efflux by raising extracellular k+ concentration from 5 to 40 mm also attenuated pasmc apoptosis induced by fccp and the k+ ionophore valinomycin. these results suggest that fccp-mediated apoptosis in pasmc is partially due to an increase of maxi-k channel activity. the resultant k+ loss through opened maxi-k channels may serve as a trigger for cell shrinkage and caspase activation, which are major characteristics of apoptosis in pulmonary vascular smooth muscle cells. over recent years, it has become clear that mitochondria play a central role in many key aspects of animal physiology and pathophysiology. their central and ubiquitous task is clearly the production of atp. nevertheless, they also play subtle roles in glucose homeostasis, acting as the sensor for substrate supply in the transduction pathway that promotes insulin secretion by the pancreatic β‐cell and that modulates the excitability of the hypothalamic glucose‐sensitive neurons involved in appetite control. mitochondria may also act as sensors of availability of oxygen, the other major mitochondrial substrate, in the regulation of respiration. mitochondria take up calcium, and the high capacity mitochondrial calcium uptake pathway provides a mechanism that couples energy demand to increased atp production through the calcium‐dependent upregulation of mitochondrial enzyme activity. mitochondrial calcium accumulation may also have a substantial impact on the spatiotemporal dynamics of cellular calcium signals, with subtle differences of detail in different cell types. recent work has also revealed the centrality of mitochondrial dysfunction as an irreversible step in the pathway to both necrotic and apoptotic cell death. this review looks at recent developments in these rapidly evolving areas of cell physiology in an attempt to draw together disparate areas of research into a common theme.
obesity is associated with an increased frequency, morbidity, and mortality of several types of neoplastic diseases, including postmenopausal breast cancer. we found that human adipose tissue contains two populations of progenitors with cooperative roles in breast cancer. cd45(-)cd34(+)cd31(+)cd13(-)ccrl2(+) endothelial cells can generate mature endothelial cells and capillaries. their cancer-promoting effect in the breast was limited in the absence of cd45(-)cd34(+)cd31(-)cd13(+)cd140b(+) mesenchymal progenitors/adipose stromal cells (asc), which generated pericytes and were more efficient than endothelial cells in promoting local tumor growth. both endothelial cells and ascs induced epithelial-to-mesenchymal transition (emt) gene expression in luminal breast cancer cells. endothelial cells (but not ascs) migrated to lymph nodes and to contralateral nascent breast cancer lesions where they generated new vessels. in vitro and in vivo, endothelial cells were more efficient than ascs in promoting tumor migration and in inducing metastases. granulocyte colony-stimulating factor (g-csf) effectively mobilized endothelial cells (but not ascs), and the addition of chemotherapy and/or of cxcr4 inhibitors did not increase endothelial cell or asc blood mobilization. our findings suggest that adipose tissue progenitor cells cooperate in driving progression and metastatic spread of breast cancer. previous studies have suggested a "catalytic role" in neoplastic angiogenesis and cancer progression for bone marrow-derived endothelial progenitor cells (epc). however, preclinical and clinical studies have shown that the quantitative role of marrow-derived epcs in cancer vascularization is extremely variable. we have found that human and murine white adipose tissue (wat) is a very rich reservoir of cd45-cd34(+) epcs with endothelial differentiation potential, containing a mean of 263 times more cd45-cd34(+) cells/ml than bone marrow. compared with marrow-derived cd34(+) cells mobilized in blood by granulocyte colony-stimulating factor, purified wat-cd34(+) cells expressed similar levels of stemness-related genes, significantly increased levels of angiogenesis-related genes, and increased levels of fap-α, a crucial suppressor of antitumor immunity. in vitro, wat-cd34(+) cells generated mature endothelial cells and capillary tubes as efficiently as mature mesenchymal cells. the coinjection of human wat-cd34(+) cells from lipotransfer procedures contributed to tumor vascularization and significantly increased tumor growth and metastases in several orthotopic models of human breast cancer in immunodeficient mice. endothelial cells derived from human wat-cd34(+) cells lined the lumen of cancer vessels. these data indicate that cd34(+) wat cells can promote cancer progression and metastases. our results highlight the importance of gaining a better understanding of the role of different wat-derived cells used in lipotransfer for breast reconstruction in patients with breast cancer.
opals offer a practical way to realize 3d bandgap functional materials. we have fabricated and optically characterized opals incorporating optical fibre tapers. opals assembled from silver-coated microspheres exhibit enhanced the refractive index contrast and bandgap effects. a capillary deposition method for the preparation of opal and inverse opal films has been developed. by this method, one can control the film thickness and the crack arrangement in opal as well as inverse opal structures. this method combines tube capillarity with cell capillarity or with gravity depending on the stability of the suspensions. the combination of tube capillarity with cell capillarity is used to prepare opal films from stable suspensions. the tube capillary transports the suspension, while the cell capillary helps to assemble the spheres. the setup defines the drying fronts, thickness, and crack arrangements of the opal films. the combination of capillarity with gravity is useful for making opal films from unstable suspensions. opal films of spheres with size up to 1 mum can be easily prepared from this combination. here, the gravity influences the arrangement of the spheres. the two-capillary setup has also been used to infiltrate the opal films with a titania precursor. after calcination, inverse titania opal films with skeleton structure have been obtained.
as the number of cores increases in a single chip processor, several challenges arise: wire delays, contention for out-of-chip accesses, and core heterogeneity. in order to address these issues and the applications demands, future large-scale many-core processors are expected to be organized as a collection of numa clusters of heterogeneous cores. in this work we propose a scheduler that takes into account the non-uniform memory latency, the heterogeneity of the cores, and the contention to the memory controller to find the best matching core for the application's memory and compute requirements. scheduler decisions are based on an on-line classification process that determines applications requirements either as memory- or compute-bound. we evaluate our proposed scheduler on the 48-core intel scc using applications from spec cpu2006 benchmark suite. our results show that even when all cores are busy, migrating processes to cores that match better the requirements of applications results in overall performance improvement. in particular we observed a reduction of the execution time from 15% to 36% compared to a random static scheduling policy. on august 24, 2006, the standard performance evaluation corporation (spec) announced cpu2006 [2], which replaces cpu2000. the spec cpu benchmarks are widely used in both industry and academia [3].
transcellular placental maternofetal flux of calcium and magnesium is reduced in diabetic pregnancy in the rat which might be due to changes in placental cellularity. in order to investigate this wet and dry weight, dna and protein content were measured in placentas from untreated diabetic (d(o)), insulin-treated diabetic (d(i)) and control rats (c) on day 21 of gestation (term=23 days). wet and dry weights (mg; mean+/-s.e.m.) were 418+/-13, 474+/-19, 416+/-14 and 66+/-3, 75+/-3, 67+/-3 in c, d(o) and d(i) groups, respectively. total dna and protein content (mg) was 1.8+/-0.2, 1.7+/-0.1, 1.5+/-0.1 and 50.4+/-2.4, 54.9+/-2.6, 51.9+/-3.3 in c, d(o) and d(i) groups, respectively. the data suggest that placental cellularity is unaffected by maternal diabetes mellitus in the rat and is unlikely to directly affect maternofetal flux of calcium and magnesium. we describe a modified procedure of the diphenylamine-colorimetric method for assay of dna that is shorter than the procedure described by burton. this improvement is achieved by raising the sample incubation temperature to 50 degrees c. the higher temperature hastens and stabilizes the diphenylamine reaction with dna so that absorbances of samples can be measured as early as 3 h after the reaction is started. this shortened assay is able to detect as little as 3 micrograms of calf thymus dna. this method is suitable for measuring dna content of epidermal tissue.
serious losses have occurred at the u.s. fish and wildlife service, craig brook national fish hatchery, east orland, maine, among eggs that were taken from atlantic salmon salmo salar, which were held as captive broodfish during their returns to the penobscot river, naraguagus river, and machias river to spawn. bacterial isolations were attempted from external surfaces and the internal contents of individual eggs. externally and in all cases, pseudomonas fluorescens was the predominant bacterium associated with the surface of all eggs. these bacteria were resistant to a surface treatment of 1,667 ppm formalin for 15 min and, therefore, the monoclonal nature of p. fluorescens on egg surfaces was considered to result from its ability to resist the germicidal activity of formalin administered for antifungal treatments. flavobacterium psychrophilum, the cause of bacterial coldwater disease, was isolated from the interior of 23.6, 18.1, and 29.2% of the dead atlantic salmon eggs from penobscot river egg lots a-98, a-100, and a-101, respectively, and concentrations of this pathogen ranged from 1.0 × 10(3) to >5 × 10(8) cfu per gram of dead egg. flavobacterium psychrophilum was also isolated from 8.3, 26.7, and 10.0% of the dead eggs from naraguagus river egg lots n-158, n-161, and n-163, respectively, in which concentrations of this organism ranged from 1.0 × 10(3) to 7.5 × 10(8) cfu per gram of egg. this bacterium was also isolated from within 18.3% and 3.3% of the dead eggs from machias river egg lots m-128 and m-142, respectively, and its concentrations ranged from 1.0 × 10(3) to 1.5 × 10(8) cfu per gram of egg. the finding of f. psychrophilum from within these eggs is indicative of this pathogen's widespread and persistent prevalence in atlantic salmon in new england. fish hatchery management is efficient tool in intensive fish culture. the vital requirements of fish hatchery, hatchery construction, concrete tank construction, nursery, rearing and production ponds, fish seed hatchery, hormone in fish spawning, hypophysation, compounds used for induced breeding, hormone administration, spawning and rearing, steps in artificial propagation, hatchery management, nursery management are basic elements in effective hatchery management. the article reviews these vital elements to re-awaken fish farmers, fisheries students private and public sectors in the formulation of fisheries policies.
in this paper, we use deep representation learning for model-based single-channel source separation (scss) and artificial bandwidth extension (abe). both tasks are ill-posed and source-specific prior knowledge is required. in addition to well-known generative models such as restricted boltzmann machines and higher order contractive autoencoders two recently introduced deep models, namely generative stochastic networks (gsns) and sum-product networks (spns), are used for learning spectrogram representations. for scss we evaluate the deep architectures on data of the 2 nd chime speech separation challenge and provide results for a speaker dependent, a speaker independent, a matched noise condition and an unmatched noise condition task. gsns obtain the best pesq and overall perceptual score on average in all four tasks. similarly, frame-wise gsns are able to reconstruct the missing frequency bands in abe best, measured in frequency-domain segmental snr. they outperform spns embedded in hidden markov models and the other representation models significantly. we present a signal processing algorithm to convert speech signals with "standard telephone" quality into 7 khz wideband speech. a statistical approach based on a hidden markov model (hmm) is used, which takes into account several features of the band-limited speech. the narrowband input signal is classified into a limited number of speech sounds (hmm states) for which the wideband spectral envelope is estimated using the pre-trained model. the enhanced speech exhibits a significantly improved quality without objectionable artifacts.
this paper investigates whether japanese banks had been following herd behavior in the domestic loan market from 1975 through 2000. applying the technique developed by lakonishok, shleifer, and vishny [lakonishok, j., shleifer, a., vishny, r.v., 1992. the impact of institutional trading on stock prices, j. finan. econ. 32, 23-43] to the data from loans outstanding to different types of borrowers, we obtain evidence indicative of the existence of herding. city banks in japan had been following a cyclical pattern of herding with one of the peaks around the bubble period in the late 1980s. adjusting further for herding resulting from rational behavior, evidence indicative of the existence of irrational herding was observed only in the bubble period. our estimate indicates that a total of some 5 trillion yen of loan increase by city banks during the period of 1987-1989 can be attributed to irrational herd behavior. the results imply that irrational bank behavior in the late 1980s might have contributed to the problems japanese banks had with non-performing loans. we also obtained evidence for herding among regional banks and among geographically proximate banks. in a rational profit-maximizing world, banks should msdntain a credit policy of lending if and only if borrowers have positive net present value projects. why then are changes in credit policy seemingly correlated with changes in the condition of those demanding credit? this paper argues that rational bank managers with short horizons will set credit policies that influence and are influenced by other banks and demand side conditions. this leads to a theory of low frequency business cycles driven by bank credit policies. evidence from the banking crisis in new england in the early 1990s is consistent with the assumptions and predictions of the theory.
ants are dominant members of many terrestrial ecosystems and are regarded as indicators of environmental changes. however, little is known about the effects of invasive alien plants on ant populations, particularly as regards the density, spatial distribution and size of ant colonies, as well as their foraging behaviour. we addressed these questions in a study of grassland ant communities on five grasslands invaded by alien goldenrods (solidago sp.) and on five non-invaded grasslands without this plant. in each grassland, seven 100 m2 plots were selected and the ant colonies counted. ant species richness and colony density was lower in the plots on the invaded grasslands. moreover, both of these traits were higher in the plots near the grassland edge and with a higher number of plant species in the grasslands invaded by goldenrods but not in the non-invaded ones. on average, ant colony size was lower on the invaded grasslands than the non-invaded ones. also, ant workers travelled for longer distances to collect food items in the invaded areas than they did in the non-invaded ones, even after the experimental removal of some ant colonies in order to exclude the effect of higher colony density in the latter. our results indicate that invasive alien goldenrods have a profound negative effect on grassland ant communities which may lead to a cascade effect on the whole grassland ecosystem through modification of the interactions among species. the invasion diminishes a major index of the fitness of ants, which is a colony’s size, and probably leads to increased foraging effort of workers. this, in turn, may have important consequences for the division of labour and reproductive strategies within ant colonies. abstract.a method to estimate the number of workers in myrmica ant nests on abandoned meadows was developed based on removal of workers. ant workers have a tendency to climb up on wooden sticks put into their nests, therefore, assuming that the number of workers removed on sticks is related to the total number of workers within the nests, regression models for myrmica rubra, m. ruginodis and m. scabrinodis may be built. we used a general regression model to perform a backward stepwise elimination of explanatory variables. these were the number of workers removed on sticks, temperature at the nest and site (a categorical variable). in case of each species the final model contained only the number of workers removed as a significant variable. the method is apparently non-destructive as we did not observe decreased survival of nests surveyed as compared to control nests. the method can be a very useful tool in population studies of ants as well as in biodiversity projects, where ants are used as bioinidcators.
a number of studies have demonstrated high coordination of the hand grip force (gf; normal component of force acting at the digits-object contact area) and load force (lf; tangential component) in a variety of manipulation tasks. the aim of the study was to explore the mainly neglected effect of the change in lf direction and the effect of handedness on gf and lf coordination in bimanual manipulation task. subjects (n = 14) exerted a bimanual sinusoidal lf pattern against externally fixed handles in trials that gradually changed from unidirectional (lf exerted only in one direction) to fully bidirectional (equal lf peaks in two opposite directions). despite the gradual change of lf, unidirectional trials demonstrated high indices of force coordination, while in all bidirectional trials, no matter how low and brief lf exertion was in the opposite direction, all indices of gf and lf coordination deteriorated to a considerably lower level. the non-dominant hand demonstrated both a higher directional accuracy of exerting lf and higher gf modulation than the dominant one. we concluded that manipulation tasks performed in a single and two alternating directions may be based on partly distinctive neural control mechanisms, as well as that a switching of muscle synergies required in bidirectional tasks could play a role in the observed phenomenon. regarding the effect of hand dominance, the recorded advantage of the non-dominant hand could be considered as an addition to the current views of the non-dominant arm/hemisphere specialization in controlling limb position. the purpose of the study was to evaluate a method for testing bimanual prehension based on a novel experimental device. the device consists of two handles allowing for simultaneous measurement of bimanual hand grip forces (gf) and different patterns of load forces (lf) exerted during compression and tension along the longitudinal axis. in order to assess the reliability of the obtained measures, eight healthy subjects were tested over three consecutive test, while three moderately impaired neurological patients were tested once. in healthy subjects, high coordination was observed between gfs and lfs, as well as between two gfs and two lfs. the results also suggest a satisfactory task performance in regards to exerting the instructed lf profile, as well as a sufficient, but not excessive gf. the reliability of most of the assessed variables proved to be either moderate or high. when compared to healthy subjects, the data obtained from neurological patients mainly revealed irregular patterns of lfs, excessive gfs, as well as a relatively weak relationship between gfs and lfs. it was concluded that the evaluated methodological approach can be applied not only to explore uni- and bi-manual coordination of arm and hand grip forces in various prehensile activities, but also to serve as a basis for future development of specific clinical tests for neurological patients and other populations that demonstrate impaired hand function.
sound and acceleration are detected by hair bundles, mechanosensory structures located at the apical pole of hair cells in the inner ear. the different elements of the hair bundle, the stereocilia and a kinocilium, are interconnected by a variety of link types. one of these links, the tip link, connects the top of a shorter stereocilium with the lateral membrane of an adjacent taller stereocilium and may gate the mechanotransducer channel of the hair cell. mass spectrometric and western blot analyses identify the tip-link antigen, a hitherto unidentified antigen specifically associated with the tip and kinocilial links of sensory hair bundles in the inner ear and the ciliary calyx of photoreceptors in the eye, as an avian ortholog of human protocadherin-15, a product of the gene for the deaf/blindness usher syndrome type 1f/dfnb23 locus. multiple protocadherin-15 transcripts are shown to be expressed in the mouse inner ear, and these define four major isoform classes, two with entirely novel, previously unidentified cytoplasmic domains. antibodies to the three cytoplasmic domain-containing isoform classes reveal that each has a different spatiotemporal expression pattern in the developing and mature inner ear. two isoforms are distributed in a manner compatible for association with the tip-link complex. an isoform located at the tips of stereocilia is sensitive to calcium chelation and proteolysis with subtilisin and reappears at the tips of stereocilia as transduction recovers after the removal of calcium chelators. protocadherin-15 is therefore associated with the tip-link complex and may be an integral component of this structure and/or required for its formation. tip links are extracellular, cell-surface-associated filaments of unknown molecular composition that are thought to gate the mechanotransducer channel of the sensory hair cell. they disappear from the hair bundle in response to calcium chelation and lanthanum treatment and resist degradation by the protease subtilisin. a monoclonal antibody derived from a hybridoma screen identified a novel antigen associated with tip links, the tip-link antigen. the tip-link antigen is also associated with kinocilial links, subtilisin-resistant filaments that are sensitive to calcium chelation and connect the kinocilium to the tallest stereocilia of the hair bundle. furthermore, the tip-link antigen is expressed in the retina, where it is associated with the ciliary calyx, a ring of microvilli that surrounds the outer segment of the photoreceptor. the tip-link antigen rapidly disappears from the surface of the hair bundle in response to calcium chelation. it is also subtilisin resistant, relative to the ankle-link antigen, an antigen associated with another type of hair bundle link. the tip-link antigen is lanthanum sensitive and, like tip links, reappears on the surface of the hair bundle after calcium chelation. the monoclonal antibody to the tip-link antigen immunoprecipitates two concanavalin a-reactive polypeptides with apparent molecular masses of 200 and 250 kda from detergent extracts of the retina. these results provide the first identification of a cell surface antigen associated with tip links, indicate that tip links share properties in common with kinocilial links, and reveal a second epitope that, along with the ankle-link antigen, is common to both sensory hair bundles and the ciliary calyx of photoreceptors.
recent progress in semantic segmentation has been driven by improving the spatial resolution under fully convolutional networks (fcns). to address this problem, we propose a stacked deconvolutional network (sdn) for semantic segmentation. in sdn, multiple shallow deconvolutional networks, which are called as sdn units, are stacked one by one to integrate contextual information and bring the fine recovery of localization information. meanwhile, inter-unit and intra-unit connections are designed to assist network training and enhance feature fusion since the connections improve the flow of information and gradient propagation throughout the network. besides, hierarchical supervision is applied during the upsampling process of each sdn unit, which enhances the discrimination of feature representations and benefits the network optimization. we carry out comprehensive experiments and achieve the new state-ofthe- art results on four datasets, including pascal voc 2012, camvid, gatech, coco stuff. in particular, our best model without crf post-processing achieves an intersection-over-union score of 86.6% in the test set. we present a novel algorithm for estimating the broad 3d geometric structure of outdoor video scenes. leveraging spatio-temporal video segmentation, we decompose a dynamic scene captured by a video into geometric classes, based on predictions made by region-classifiers that are trained on appearance and motion features. by examining the homogeneity of the prediction, we combine predictions across multiple segmentation hierarchy levels alleviating the need to determine the granularity a priori. we built a novel, extensive dataset on geometric context of video to evaluate our method, consisting of over 100 ground-truth annotated outdoor videos with over 20,000 frames. to further scale beyond this dataset, we propose a semi-supervised learning framework to expand the pool of labeled data with high confidence predictions obtained from unlabeled data. our system produces an accurate prediction of geometric context of video achieving 96% accuracy across main geometric classes.
model-based languages such as matlab/simulink play an essential role in the model-driven development of software systems. to comply with new requirements, it is common practice to create new variants by copying existing systems and modifying them. commonly referred to as clone-and-own, severe problems arise in the long-run when no dedicated variability management is installed. to allow for a documented and structured reuse of systems, their variability information needs to be reverse-engineered. in this paper, we propose an advanced comparison procedure, the matching window technique, and a customizable metric. both allow us to overcome structural alterations commonly performed during clone-and-own. we analyze related matlab/simulink models and determine, classify and represent their variability information in an understandable way. with our technique, we assist model engineers in maintaining and evolving existing variants. we provide three feasibility studies with real-world models from the automotive domain and show our technique to be fast and precise. furthermore, we perform semi-structured interviews with domain experts to assess the potential applicability of our technique in practice. case study is a suitable research methodology for software engineering research since it studies contemporary phenomena in its natural context. however, the understanding of what constitutes a case study varies, and hence the quality of the resulting studies. this paper aims at providing an introduction to case study methodology and guidelines for researchers conducting case studies and readers studying reports of such studies. the content is based on the authors’ own experience from conducting and reading case studies. the terminology and guidelines are compiled from different methodology handbooks in other research domains, in particular social science and information systems, and adapted to the needs in software engineering. we present recommended practices for software engineering case studies as well as empirically derived and evaluated checklists for researchers and readers of case study research.
language adaptation (similarly to domain adaptation) is a general approach to extend existing resources from a better resourced language (donor) to a lesser resourced one (recipient) by exploiting the lexical and grammatical similarity between them when the two languages are related. the current study improves the state of the art in cross-lingual word embeddings by considering the impact of orthographic similarity between cognates. in particular, the use of the weighted levenshtein distance combined with orthogonalisation of the translation matrix and generalised correction for hubness can considerably improve the state of the art in induction of bilingual lexicons. in addition to intrinsic evaluation in the bilingual lexicon induction task, the paper reports extrinsic evaluation of the cross-lingual embeddings via their application to the named-entity recognition task across slavonic languages. the tools and the aligned word embedding spaces for the romance and slavonic language families have been released. the zero-shot paradigm exploits vector-based word representations extracted from text corpora with unsupervised methods to learn general mapping functions from other feature spaces onto word space, where the words associated to the nearest neighbours of the mapped vectors are used as their linguistic labels. we show that the neighbourhoods of the mapped elements are strongly polluted by hubs, vectors that tend to be near a high proportion of items, pushing their correct labels down the neighbour list. after illustrating the problem empirically, we propose a simple method to correct it by taking the proximity distribution of potential neighbours across many mapped vectors into account. we show that this correction leads to consistent improvements in realistic zero-shot experiments in the cross-lingual, image labeling and image retrieval domains.
in this paper, a new integrated weight particle filter (iwpf) algorithm is proposed based on the combination of correlation particle estimation (cpe) weight and sequential importance re-sampling (sir) weight. this method can reduce degeneracy phenomenon and re-sampling times of traditional particle filter. by choosing the typical nonlinear system model, the simulation results show that iwpf performs better than cpe and sir. in our simulation case, this method can provide a 15% increase of accuracy in state estimation and a 30% decrease of re-sampling times. this article analyses the recently suggested particle approach to filtering time series. we suggest that the algorithm is not robust to outliers for two reasons: the design of the simulators and the use of the discrete support to represent the sequentially updating prior distribution. here we tackle the first of these problems.
the c-jun nh2-terminal kinase (jnk), also known as stress-activated protein kinase, is a mitogen-activated protein kinase that determines cell survival in response to environmental stress. activation of jnk involves redox-sensitive mechanisms and physiological stimuli such as shear stress, the dragging force generated by blood flow over the endothelium. laminar shear stress has antiatherogenic properties and controls structure and function of endothelial cells by mechanisms including production of nitric oxide (no) and superoxide ([formula: see text]). here we show that both no and [formula: see text] are required for activation of jnk by shear stress in endothelial cells. the present study also demonstrates that exposure of endothelial cells to shear stress increases tyrosine nitration, a marker of reactive nitrogen species formation. furthermore, inhibitors or scavengers of no, [formula: see text], or reactive nitrogen species prevented shear-dependent increase in tyrosine nitration and activation of jnk. peroxynitrite alone, added to cells as a bolus or generated over 60 min by 3-morpholinosydnonimine, also activates jnk. these results suggest that reactive nitrogen species, in this case most likely peroxynitrite, act as signaling molecules in the mechanoactivation of jnk. shear stress differentially regulates production of many vasoactive factors at the level of gene expression in endothelial cells that may be mediated by mitogen-activated protein kinases, including extracellular signal-regulated kinase (erk) and n-terminal jun kinase (jnk). here we show, using bovine aortic endothelial cells (baec), that shear stress differentially regulates erk and jnk by mechanisms involving gi2 and pertussis toxin (ptx)-insensitive g-protein-dependent pathways, respectively. shear activated erk with a rapid, biphasic time course (maximum by 5 min and basal by 30-min shear exposure) and force dependence (minimum and maximum at 1 and 10 dyn/cm2 shear stress, respectively). ptx treatment prevented shear-dependent activation of erk1/2, consistent with a gi-dependent mechanism. in contrast, jnk activity was maximally turned on by a threshold level of shear force (0.5 dyn/cm2 or higher) with a much slower and prolonged time course (requiring at least 30 min to 4 h) than that of erk. also, ptx had no effect on shear-dependent activation of jnk. to further define the shear-sensitive erk and jnk pathways, vectors expressing hemagglutinin epitope-tagged erk (ha-erk) or ha-jnk were co-transfected with other vectors by using adenovirus-polylysine in baec. expression of the mutant αi2(g203), antisense gαi2 and a dominant negative ras (n17ras) prevented shear-dependent activation of ha-erk, while that of αi2(g204) and antisense αi3 did not. expression of a gβ/γ scavenger, the carboxyl terminus of β-adrenergic receptor kinase (βark-ct), and n17ras inhibited shear-dependent activation of ha-jnk. treatment of baec with genistein prevented shear-dependent activation of erk and jnk, indicating the essential role of tyrosine kinase(s) in both erk and jnk pathways. these results provide evidence that 1) gi2-protein, ras, and tyrosine kinase(s) are upstream regulators of shear-dependent activation of erk and 2) that shear-dependent activation of jnk is regulated by mechanisms involving gβ/γ, ras, and tyrosine kinase(s).
the glycosylation of cell surface proteins plays a crucial role in a multitude of biological processes, such as cell adhesion and recognition. to understand the process of protein glycosylation, the reaction mechanisms of the participating enzymes need to be known. however, the reaction mechanism of retaining glycosyltransferases has not yet been sufficiently explained. here we investigated the catalytic mechanism of human isoform 2 of the retaining glycosyltransferase polypeptide udp-galnac transferase by coupling two different qm/mm-based approaches, namely a potential energy surface scan in two distance difference dimensions and a minimum energy reaction path optimisation using the nudged elastic band method. potential energy scan studies often suffer from inadequate sampling of reactive processes due to a predefined scan coordinate system. at the same time, path optimisation methods enable the sampling of a virtually unlimited number of dimensions, but their results cannot be unambiguously interpreted without knowledge of the potential energy surface. by combining these methods, we have been able to eliminate the most significant sources of potential errors inherent to each of these approaches. the structural model is based on the crystal structure of human isoform 2. in the qm/mm method, the qm region consists of 275 atoms, the remaining 5776 atoms were in the mm region. we found that ppgalnact2 catalyzes a same-face nucleophilic substitution with internal return (sni). the optimized transition state for the reaction is 13.8 kcal/mol higher in energy than the reactant while the energy of the product complex is 6.7 kcal/mol lower. during the process of nucleophilic attack, a proton is synchronously transferred to the leaving phosphate. the presence of a short-lived metastable oxocarbenium intermediate is likely, as indicated by the reaction energy profiles obtained using high-level density functionals. we present the theoretical and technical foundations of the amsterdam density functional (adf) program with a survey of the characteristics of the code (numerical integration, density fitting for the coulomb potential, and sto basis functions). recent developments enhance the efficiency of adf (e.g., parallelization, near order‐n scaling, qm/mm) and its functionality (e.g., nmr chemical shifts, cosmo solvent effects, zora relativistic method, excitation energies, frequency‐dependent (hyper)polarizabilities, atomic vdd charges). in the applications section we discuss the physical model of the electronic structure and the chemical bond, i.e., the kohn–sham molecular orbital (mo) theory, and illustrate the power of the kohn–sham mo model in conjunction with the adf‐typical fragment approach to quantitatively understand and predict chemical phenomena. we review the “activation‐strain ts interaction” (ats) model of chemical reactivity as a conceptual framework for understanding how activation barriers of various types of (competing) reaction mechanisms arise and how they may be controlled, for example, in organic chemistry or homogeneous catalysis. finally, we include a brief discussion of exemplary applications in the field of biochemistry (structure and bonding of dna) and of time‐dependent density functional theory (tddft) to indicate how this development further reinforces the adf tools for the analysis of chemical phenomena. © 2001 john wiley & sons, inc. j comput chem 22: 931–967, 2001
diabetes mellitus is a chronic disease, which has an increasing trend all over the world. type 2 diabetes constitutes 90% of all diabetes. it is associated with weight gain and insulin resistance. research during recent years has suggested that shift work could be a risk factor of type 2 diabetes. since shift work is becoming more common, it could contribute to the increasing trend of diabetes. in this systematic review, we have studied the potential association between shift work and type 2 diabetes. we have also reviewed studies on control of diabetes in relation to shift work. objective: this study investigated the effect of alternating shift work (asw) on the onset of diabetes mellitus in japanese workers compared with onset in day-shift work (dsw). methods: a longitudinal study was carried out on a dsw group (n = 3203) and asw group (n = 2426) of a steel company who received their annual health checkups over a 10-year period between 1991 and 2001. the association between job schedule type and onset of diabetes mellitus (glycated hemoglobin a1c ≥6.0% or medication) was investigated by multivariate pooled logistic regression analyses. results: the odds ratio (95% confidence interval) for the development of diabetes mellitus in the asw group compared with the dsw group was 1.35 (1.05–1.75). conclusions: our study revealed that the asw is an independent risk factor for the onset of diabetes mellitus.
policy on child and adolescent mental health services (camhs) in england has undergone radical changes in the last 15 years, with far reaching implications for funding models, access to services and service delivery. using corpus analysis and critical discourse analysis, we explore how childhood, mental health and camhs are constituted in 15 policy documents, 9 pre-2010 and 6 post-2010. we trace how these constructions have changed over time and consider the practice implications of these changes. we identify how children’s distress is individualised, through medicalising discourses and shifting understandings of the relationship between socio-economic context and mental health. this is evidenced in a shift from seeing children’s mental health challenges as produced by social and economic inequities to a view that children’s mental health must be addressed early to prevent future socio-economic burden. we consider the implications of camhs policies for the relationship between children, families, mental health services and the state. the article concludes by exploring how concepts of ‘parity of esteem’ and ‘stigma reduction’ may inadvertently exacerbate the individualisation of children’s mental health. ▪ abstract this paper provides a survey of critical discourse analysis (cda), a recent school of discourse analysis that concerns itself with relations of power and inequality in language. cda explicitly intends to incorporate social-theoretical insights into discourse analysis and advocates social commitment and interventionism in research. the main programmatic features and domains of enquiry of cda are discussed, with emphasis on attempts toward theory formation by one of cda's most prominent scholars, norman fairclough. another section reviews the genesis and disciplinary growth of cda, mentions some of the recent critical reactions to it, and situates it within the wider picture of a new critical paradigm developing in a number of language-oriented (sub) disciplines. in this critical paradigm, topics such as ideology, inequality, and power figure prominently, and many scholars productively attempt to incorporate social-theoretical insights into the study of language.
backgroundhealth consumers have moved away from a reliance on medical practitioner advice to more independent decision processes and so their information search processes have subsequently widened. this study examined how persons with back pain searched for alternative treatment types and service providers. that is, what information do they seek and how; what sources do they use and why; and by what means do they search for it?methods12 persons with back pain were interviewed. the method used was convergent interviewing. this involved a series of semi-structured questions to obtain open-ended answers. the interviewer analysed the responses and refined the questions after each interview, to converge on the dominant factors influencing decisions about treatment patterns.resultspersons with back pain mainly search their memories and use word of mouth (their doctor and friends) for information about potential treatments and service providers. their search is generally limited due to personal, provider-related and information-supply reasons. however, they did want in-depth information about the alternative treatments and providers in an attempt to establish apriori their efficacy in treating their specific back problems. they searched different sources depending on the type of information they required.conclusionsthe findings differ from previous studies about the types of information health consumers require when searching for information about alternative or mainstream healthcare services. the results have identified for the first time that limited information availability was only one of three categories of reasons identified about why persons with back pain do not search for more information particularly from external non-personal sources. this research used the somewhat new methodology of convergent interviews to develop a conceptual framework about relationship constructs in an internet environment. more generally, this article describes and illustrates the processes and the strengths of convergent interviewing to investigate under‐researched areas, and compares it with alternative qualitative techniques like in‐depth interviews, case research and focus groups. the illustration involves interviews conducted with marketing managers and business consultants from ten service companies, about internet and relationship marketing. it is argued that convergent interviewing is more appropriate than some other qualitative methods to investigate under‐researched areas where there are few experts because it provides a way of quickly converging on key issues in the area, an efficient mechanism for data analysis after each interview, and a way of deciding when to stop collecting data. convergent interviews could become another useful qualitative research method to explore new issues about emerging marketing phenomena.
abstract cavitation is a key pathological feature of human tuberculosis (tb), and is a well-recognized risk factor for transmission of infection, relapse after treatment and the emergence of drug resistance. despite intense interest in the mechanisms underlying cavitation and its negative impact on treatment outcomes, there has been limited study of this phenomenon, owing in large part to the limitations of existing animal models. although cavitation does not occur in conventional mouse strains after infection with mycobacterium tuberculosis, cavitary lung lesions have occasionally been observed in c3heb/fej mice. however, to date, there has been no demonstration that cavitation can be produced consistently enough to support c3heb/fej mice as a new and useful model of cavitary tb. we utilized serial computed tomography (ct) imaging to detect pulmonary cavitation in c3heb/fej mice after aerosol infection with m. tuberculosis. post-mortem analyses were performed to characterize lung lesions and to localize matrix metalloproteinases (mmps) previously implicated in cavitary tb in situ. a total of 47-61% of infected mice developed cavities during primary disease or relapse after non-curative treatments. key pathological features of human tb, including simultaneous presence of multiple pathologies, were noted in lung tissues. optical imaging demonstrated increased mmp activity in tb lesions and mmp-9 was significantly expressed in cavitary lesions. tissue mmp-9 activity could be abrogated by specific inhibitors. in situ, three-dimensional analyses of cavitary lesions demonstrated that 22.06% of cd11b+ signal colocalized with mmp-9. c3heb/fej mice represent a reliable, economical and tractable model of cavitary tb, with key similarities to human tb. this model should provide an excellent tool to better understand the pathogenesis of cavitation and its effects on tb treatments. summary: we demonstrate for the first time a murine model that consistently produces pulmonary cavitary tb and provides a tractable and economical new tool for better understanding of cavitation. active tuberculosis (tb) often presents with advanced pulmonary disease, including irreversible lung damage and cavities. cavitary pathology contributes to antibiotic failure, transmission, morbidity and mortality. matrix metalloproteinases (mmps), in particular mmp‐1, are implicated in tb pathogenesis. we explored the mechanisms relating mmp/timp imbalance to cavity formation in a modified rabbit model of cavitary tb. our model resulted in consistent progression of consolidation to human‐like cavities (100% by day 28), with resultant bacillary burdens (>107 cfu/g) far greater than those found in matched granulomatous tissue (105 cfu/g). using a novel, breath‐hold computed tomography (ct) scanning and image analysis protocol, we showed that cavities developed rapidly from areas of densely consolidated tissue. radiological change correlated with a decrease in functional lung tissue, as estimated by changes in lung density during controlled pulmonary expansion (r2 = 0.6356, p < 0.0001). we demonstrated that the expression of interstitial collagenase (mmp‐1) was specifically greater in cavitary compared to granulomatous lesions (p < 0.01), and that timp‐3 significantly decreased at the cavity surface. our findings demonstrated that an mmp‐1/timp imbalance is associated with the progression of consolidated regions to cavities containing very high bacterial burdens. our model provided mechanistic insight, correlating with human disease at the pathological, microbiological and molecular levels. it also provided a strategy to investigate therapeutics in the context of complex tb pathology. we used these findings to predict a mmp/timp balance in active tb and confirmed this in human plasma, revealing the potential of mmp/timp levels as key components of a diagnostic matrix aimed at distinguishing active from latent tb (ppv = 92.9%, 95% ci 66.1–99.8%, npv = 85.6%; 95% ci 77.0–91.9%). copyright © 2014 pathological society of great britain and ireland. published by john wiley & sons, ltd
hydroxyproline (hyp) metabolism is a key source of glyoxylate production in the body and may be a major contributor to excessive oxalate production in the primary hyperoxalurias where glyoxylate metabolism is impaired. important gaps in our knowledge include identification of the tissues with the capacity to degrade hyp and the development of model systems to study this metabolism and how to suppress it. the expression of mrna for enzymes in the pathway was examined in 15 different human tissues. expression of the complete pathway was identified in liver, kidney, pancreas, and small intestine. hepg2 cells also expressed these mrnas and enzymes and were shown to metabolize hyp in the culture medium to glycolate, glycine, and oxalate. [(18)o]- and [(13)c(5)]hyp were synthesized and evaluated for their use with in vitro and in vivo models. [(18)o]hyp was not suitable because of an apparent tautomerism of [(18)o]glyoxylate between enol and hydrated forms, which resulted in a loss of isotope. [(13)c(5)]hyp, however, was metabolized to [(13)c(2)]glycolate, [(13)c(2)]glycine, and [(13)c(2)]oxalate in vitro in hepg2 cells and in vivo in mice infused with [(13)c(5)]hyp. these model systems should be valuable tools for exploring various aspects of hyp metabolism and will be useful in determining whether blocking hyp catabolism is an effective therapy in the treatment of primary hyperoxaluria. perspectives and summary 1006 introduction 1007 proline 1008 proline biosynthesis: the glutamate pathway 1008 proline biosynthesis: the om pathway 1015 proline degradation: the p5c pathway 1018 proline degradation: reguiation 1020 proline degradation: other pathways 1023 4-hydroxyprollne 1024 natural occurrence 1024 metabolism general features 1025 catabolism of free 4-hyp 1034 3-hydroxyproline 1041 metabolism 1042 3,4-dihydroxyproline 1044
author(s): chen, yixing; luo, xuan; hong, tianzhen | abstract: traditionally, in building energy modeling (bem) programs, occupancy inputs are deterministic and less indicative of real world scenarios, contributing to discrepancies between simulated and actual energy use in buildings. this paper presents an agent-based occupancy simulator, which models each occupant as an agent with specified movement events and statistics of space uses. to reduce the amount of data inputs, the simulator allows users to group occupants with similar behaviors as an occupant type, and spaces with similar function as a space type. it is a web-based application with friendly graphical user interface, cloud computing, and data storage. a case study is presented to demonstrate the usage of the occupancy simulator and its integration with energyplus and obfmu. it first shows the required data inputs and the results from the occupancy simulator. then, the generated occupant schedules are used in the energyplus and obfmu simulation to evaluate the impacts of occupant behavior on building energy performance. the simulation results indicate that the occupancy simulator can capture the diversity of space’s occupancy behavior rather than the static weekly profiles, and can generate realistic occupancy schedules to support building performance simulation. building occupancy is an important basic factor in building energy simulation but it is hard to represent due to its temporal and spatial stochastic nature. this paper presents a novel approach for building occupancy simulation based on the markov chain. in this study, occupancy is handled as the straightforward result of occupant movement processes which occur among the spaces inside and outside a building. by using the markov chain method to simulate this stochastic movement process, the model can generate the location for each occupant and the zone-level occupancy for the whole building. there is no explicit or implicit constraint to the number of occupants and the number of zones in the model while maintaining a simple and clear set of input parameters. from the case study of an office building, it can be seen that the model can produce realistic occupancy variations in the office building for a typical workday with key statistical properties of occupancy such as the time of morning arrival and night departure, lunch time, periods of intermediate walking-around, etc. due to simplicity, accuracy and unrestraint, this model is sufficient and practical to simulate occupancy for building energy simulations and stochastic analysis of building heating, ventilation, and air conditioning (hvac) systems.
the humoral immune response plays a critical role in controlling infection, and the rapid adaptation to a broad range of pathogens depends on a highly diverse antibody repertoire. the advent of high-throughput sequencing technologies in the past decade has enabled insights into this immense diversity. however, not only the variable, but also the constant region of antibodies determines their in vivo activity. antibody isotypes differ in effector functions and are thought to play a defining role in elicitation of immune responses, both in natural infection and in vaccination. we have developed an illumina miseq high-throughput sequencing protocol that allows determination of the human igg subtype alongside sequencing full-length antibody variable heavy chain regions. we thereby took advantage of the illumina procedure containing two additional short reads as identifiers. by performing paired-end sequencing of the variable regions and customizing one of the identifier sequences to distinguish igg subtypes, igg transcripts with linked information of variable regions and igg subtype can be retrieved. we applied our new method to the analysis of the igg variable region repertoire from pbmc of an hiv-1 infected individual confirmed to have serum antibody reactivity to the membrane proximal external region (mper) of gp41. we found that igg3 subtype frequencies in the memory b cell compartment increased after halted treatment and coincided with increased plasma antibody reactivity against the mper domain. the sequencing strategy we developed is not restricted to analysis of igg. it can be adopted for any ig subtyping and beyond that for any research question where phasing of distant regions on the same amplicon is needed. background in the context of sexual transmission of human immunodeficiency virus type 1 (hiv-1), current findings suggest that the mucosal barrier is the major site of viral selection, transforming the complex inoculum to a small, homogeneous founder virus population. we analyzed hiv-1 transmission in relation to viral and host characteristics within the zurich primary hiv-1 infection study.   methods clonal hiv-1 envelope sequences (on average 16 clones/patient) were isolated from the first available plasma samples during the early phase of infection from 145 patients with primary hiv-1 infection. phylogenetic and tropism analyses were performed. differences of viral diversities were investigated in association with several parameters potentially influencing hiv-1 transmission, eg, concomitant sexually transmitted infections (stis) and mode of transmission.   results median viral diversity within env c2-v3-c3 region was 0.39% (range 0.04%-3.23%). viral diversity did not correlate with viral load, but it was slightly correlated with the duration of infection. neither transmission mode, gender, nor sti predicted transmission of more heterogeneous founder virus populations that were found in 16 of 145 patients (11%; diversity >1%). only 2 patients (1.4%) were assuredly infected with cxcr4-tropic hiv-1 within a r5/x4-tropic--mixed population, as revealed and confirmed using several genotypic prediction algorithms and phenotypic assays.   conclusions our findings suggest that transmission of multiple hiv-1 variants might be a complex process that is not dependent on mucosal factors alone. cxcr4-tropic viruses can be sexually transmitted in rare instances, but their clinical relevance remains to be determined.
the reservoir for neisseria meningitidis (nm) is the human oropharynx. implementation of nm serogroup c (nmc) glycoconjugate vaccines directly reduced nmc carriage. prophylactic vaccines are now available to prevent disease caused by the five major nm disease causing serogroups (abcwy). nm serogroup b (nmb) vaccines are composed of antigens that are conserved across nm serogroups and therefore have the potential to impact all nm carriage. to assess the effect of these vaccines on carriage, standardized approaches to identify and group nm are required. real-time pcr (rt-pcr) capsule grouping assays that were internally controlled to confirm nm species were developed for eight serogroups associated with carriage (a, b, c, e, w, x, y and z). the grouping scheme was validated using diverse bacterial species associated with carriage and then used to evaluate a collection of diverse nm carriage isolates (n=234). a scheme that also included pora and ctra probes was able to speciate the isolates, while ctra also provided insights on the integrity of the polysaccharide loci. isolates were typed for the nm vaccine antigen factor h binding protein (fhbp), and were found to represent the known diversity of this antigen. the pora rt-pcr yielded positive results with all 234 of the nm carriage isolates. genogrouping assays classified 76.5% (179/234) of these isolates to a group, categorized 53 as nongenogroupable (ngg) and two as mixed results. thirty seven ngg isolates evidenced a disrupted capsular polysaccharide operon judged by a ctra negative result. only 28.6% (67/234) of the isolates were serogrouped by slide agglutination (sasg), highlighting the reduced capability of carriage strains to express capsular polysaccharide. these rt-pcr assays provide a comprehensive means to identify and genogroup n. meningitidis in carriage studies used to guide vaccination strategies and to assess the impact of novel fhbp containing vaccines on meningococcal carriage. background in 1999, meningococcal serogroup c conjugate (mcc) vaccines were introduced in the united kingdom for those under 19 years of age. the impact of this intervention on asymptomatic carriage of meningococci was investigated to establish whether serogroup replacement or protection by herd immunity occurred.   methods multicenter surveys of carriage were conducted during vaccine introduction and on 2 successive years, resulting in a total of 48,309 samples, from which 8599 meningococci were isolated and characterized by genotyping and phenotyping.   results a reduction in serogroup c carriage (rate ratio, 0.19) was observed that lasted at least 2 years with no evidence of serogroup replacement. vaccine efficacy against carriage was 75%, and vaccination had a disproportionate impact on the carriage of sequence type (st)-11 complex serogroup c meningococci that (rate ratio, 0.06); these meningococci also exhibited high rates of capsule expression.   conclusions the impact of vaccination with mcc vaccine on the prevalence of carriage of group c meningococci was consistent with herd immunity. the high impact on the carriage of st-11 complex serogroup c could be attributed to high levels of capsule expression. high vaccine efficacy against disease in young children, who were not protected long-term by the schedule initially used, is attributed to the high vaccine efficacy against carriage in older age groups.
the concept of search tree uniication presented in this paper serves a basis for the declarative interpretation of process-based logic programs. each logic process created explicitly from a sub-goal deenes an own sub-search tree. processes of the same logic program are not independent but rely on the partial result of each other, i.e. they communicate with each other. therefore, sub-search trees are related along communication patterns. explicit communications between processes determine links between diierent search trees. the equivalent declarative notion to executing a program consisting of diierent but related logic programs is uniication of individual search trees. search tree uniication can give declarative meaning of process-based logic programs as well. search tree uniication is a higher abstraction that captures distributed logic programs in a declarative way. the notion that computation = controlled deduction was first proposed by pay hayes [19] and more recently by bibel [2] and vaughn-pratt [31]. a similar thesis that database systems should be regarded as consisting of a relational component, which defines the logic of the data, and a control component, which stores and retrieves it, has been successfully argued by codd [10]. hewitt's argument [20] for the programming language planner, though generally regarded as an argument against logic, can also be regarded as an argument for the thesis that algorithms be regarded as consisting of both logic and control components. in this paper we shall explore some of the useful consequences of that thesis.
this paper compares the performance of several machine learning algorithms for the automatic categorization of corporate announcements in the australian stock exchange (asx) signal g data stream. the article also describes some of the applications that the categorization of corporate announcements may enable. we have performed tests on two categorization tasks: market sensitivity, which indicates whether an announcement will have an impact on the market, and report type, which classifies each announcement into one of the report categories defined by the asx. we have tried neural networks, a näıve bayes classifier, and support vector machines and achieved good results. statistical approaches to processing natural language text have become dominant in recent years. this foundational text is the first comprehensive introduction to statistical natural language processing (nlp) to appear. the book contains all the theory and algorithms needed for building nlp tools. it provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. the book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications.
sea surface temperature fields (1870–2100) forced by co2-induced climate change under the ipcc sres a1b co2 scenario, from three world climate research programme coupled model intercomparison project phase 3 (wcrp cmip3) models (ccsm3, csiro mk 3.5, and gfdl cm 2.1), were used to examine how coral sensitivity to thermal stress and rates of adaption affect global projections of coral-reef bleaching. the focus of this study was two-fold, to: (1) assess how the impact of degree-heating-month (dhm) thermal stress threshold choice affects potential bleaching predictions and (2) examine the effect of hypothetical adaptation rates of corals to rising temperature. dhm values were estimated using a conventional threshold of 1°c and a variability-based threshold of 2σ above the climatological maximum coral adaptation rates were simulated as a function of historical 100-year exposure to maximum annual ssts with a dynamic rather than static climatological maximum based on the previous 100 years, for a given reef cell. within ccsm3 simulations, the 1°c threshold predicted later onset of mild bleaching every 5 years for the fraction of reef grid cells where 1°c > 2σ of the climatology time series of annual sst maxima (1961–1990). alternatively, dhm values using both thresholds, with csiro mk 3.5 and gfdl cm 2.1 ssts, did not produce drastically different onset timing for bleaching every 5 years. across models, dhms based on 1°c thermal stress threshold show the most threatened reefs by 2100 could be in the central and western equatorial pacific, whereas use of the variability-based threshold for dhms yields the coral triangle and parts of micronesia and melanesia as bleaching hotspots. simulations that allow corals to adapt to increases in maximum sst drastically reduce the rates of bleaching. these findings highlight the importance of considering the thermal stress threshold in dhm estimates as well as potential adaptation models in future coral bleaching projections. [1] we present the met office hadley centre's sea ice and sea surface temperature (sst) data set, hadisst1, and the nighttime marine air temperature (nmat) data set, hadmat1. hadisst1 replaces the global sea ice and sea surface temperature (gisst) data sets and is a unique combination of monthly globally complete fields of sst and sea ice concentration on a 1° latitude-longitude grid from 1871. the companion hadmat1 runs monthly from 1856 on a 5° latitude-longitude grid and incorporates new corrections for the effect on nmat of increasing deck (and hence measurement) heights. hadisst1 and hadmat1 temperatures are reconstructed using a two-stage reduced-space optimal interpolation procedure, followed by superposition of quality-improved gridded observations onto the reconstructions to restore local detail. the sea ice fields are made more homogeneous by compensating satellite microwave-based sea ice concentrations for the impact of surface melt effects on retrievals in the arctic and for algorithm deficiencies in the antarctic and by making the historical in situ concentrations consistent with the satellite data. ssts near sea ice are estimated using statistical relationships between sst and sea ice concentration. hadisst1 compares well with other published analyses, capturing trends in global, hemispheric, and regional sst well, containing sst fields with more uniform variance through time and better month-to-month persistence than those in gisst. hadmat1 is more consistent with sst and with collocated land surface air temperatures than previous nmat data sets.
serum uric acid (ua) is positively associated with hypertension (htn). htn is common in pediatric patients receiving hemodialysis (hd) and peritoneal dialysis (pd). we assessed the relationship between ua and bp in 63 pediatric dialysis patients by measuring pre-treatment ua levels and bp in hd patients and in-center ua levels and blood pressure (bp) in pd patients. ua levels were similar in both groups [6.8 ± 0.2 (hd) vs. 6.5 ± 0.3 (pd), p = 0.6]. pre-treatment systolic bp percentile was associated with a high ua level [91.9 ± 2.3 (>6.0 mg/dl) vs. 79.3 ± 5.8 mm hg (≤6.0 mg/dl), p = 0.01] in hd patients only. there was a negative relationship between ua and dialysis vintage (r = −0.31, p = 0.01). in both groups, there was no relationship between ua and kt/v. in hd patients, fluid overload was unrelated to ua level [4.2 ± 0.6% (≤6.0 mg/dl) vs. 4.3 ± 0.3% (>6.0 mg/dl), p = 0.9]. moreover, pre-hd treatment systolic bp percentile correlated with ua (beta 0.36, p = 0.02) independent of volume. ua levels were higher in patients receiving anti-hypertensive medications [6.3 ± 0.2 (no meds] vs 7.0 ± 0.2 (bp meds) mg/dl,  p= 0.01]. finally, there was no relationship between serum ua and normalized protein catabolic rate (r = 0.14; p = 0.4). in summary, serum ua impacts bp in pediatric hd patients, independent of volume, nutritional and weight status. achieving dry weight during hemodialysis (hd) while minimizing symptoms is critical for optimizing patient outcome by preventing chronic fluid overload, hypertension, and cardiomyopathy. dry weight changes frequently in children because of growth and development and waxing and waning of appetite. we have previously shown non-invasive hematocrit monitoring (nivm) helps to decrease intradialytic symptoms, while still achieving target dry weights in children receiving chronic hd. in the current study, we prospectively evaluated an nivm-guided ultrafiltration (uf) management algorithm to determine target dry weight in nine pediatric patients (mean age 16.6±2.8 years, mean weight 41.6±11.1 kg). use of nivm could potentially lead to overly aggressive uf with increased interdialytic symptoms, post treatment thirst, and interdialytic weight gain (idwg). to evaluate the effectiveness of our nivm uf algorithm, we studied the effect of three different nivm-guided uf models (100%, 90%, and 80% uf models) on intradialytic and interdialytic symptoms, pre-/post-treatment blood pressure (bp), and percentage idwg. to assess interdialytic symptoms, patients completed two questionnaires, one for each day between treatments. no statistically significant difference was seen between the three uf models with respect to intradialytic or interdialytic symptoms, pre-/post-hd bp, or percentage idwg. only one of nine patients received non-acei chronic antihypertensive medication, yet all patients had pre- and post-hd bp <95th percentile for age and height. the current study suggests that routine determination of target dry weight using nivm and aiming for 100% uf helps to achieve the target dry weight, reduces both the risk of chronic fluid overload and the need for antihypertensive medication, and does not lead to increased intra- or interdialytic symptomatology in pediatric patients treated with chronic hd.
the randomized controlled trial (rct) is generally accepted as the most reliable method of conducting clinical research. to obtain an unbiased evaluation of the effectiveness of spine surgery, patients should be randomly assigned to either new or standard treatment. the aim of the present article is to provide a short overview of the advantages and challenges of rcts and to present a summary of the conclusions of the cochrane reviews in spine surgery and later published trials in order to evaluate their contribution to quality management and feasibility in practice. from the searches, 130 rcts were included, 95 from cochrane reviews and systematic reviews, and 35 from additional search. no study comparing surgery with sham surgery was identified. the first rct in spine surgery was published in 1974 and compared debridement and ambulatory treatment in tuberculosis of the spine. the contribution of rcts in spinal surgery has markedly increased over the last 10 years, which indicates that rcts are feasible in this field. the results demonstrate missing quality specifications. despite the number of published trials there is conflicting or limited evidence to support various techniques of instrumentation. the only intervention that receives strong evidence is discectomy for faster relief in carefully selected patients due to lumbar disc prolapse with sciatica. for future trials, authors, referees, and editors are recommended to follow the consort statement. rcts provide evidence to support clinical opinions before implementation of new techniques, but the individual clinical experience is still important for the doctor who has to face the patient. background surgical investigations and interventions account for large health care utilisation and costs, but the scientific evidence for most procedures is still limited.   objectives degenerative conditions affecting the lumbar spine are variously described as lumbar spondylosis or degenerative disc disease (which we regarded as one entity) and may be associated with back pain and associated leg symptoms, instability, spinal stenosis and/or degenerative spondylolisthesis. the objective of this review was to assess current scientific evidence on the effectiveness of surgical interventions for degenerative lumbar spondylosis.   search strategy we searched central, medline, pubmed, spine and issls abstracts, with citation tracking from the retrieved articles. we also corresponded with experts. all data found up to 31 march 2004 are included.   selection criteria randomised (rcts) or quasi-randomised trials of surgical treatment of lumbar spondylosis.   data collection and analysis two authors assessed trial quality and extracted data from published papers. additional information was sought from the authors if necessary.   main results thirty-one published rcts of all forms of surgical treatment for degenerative lumbar spondylosis were identified. the trials varied in quality: only the more recent trials used appropriate methods of randomization, blinding and independent assessment of outcome. most of the earlier published results were of technical surgical outcomes with some crude ratings of clinical outcome. more of the recent trials also reported patient-centered outcomes of pain or disability, but there is still very little information on occupational outcomes. there was a particular lack of long term outcomes beyond two to three years. seven heterogeneous trials on spondylolisthesis, spinal stenosis and nerve compression permitted limited conclusions. two new trials on the effectiveness of fusion showed conflicting results. one showed that fusion gave better clinical outcomes than conventional physiotherapy, while the other showed that fusion was no better than a modern exercise and rehabilitation programme. eight trials showed that instrumented fusion produced a higher fusion rate (though that needs to be qualified by the difficulty of assessing fusion in the presence of metal-work), but did not improve clinical outcomes, while there is other evidence that it may be associated with higher complication rates. three trials with conflicting results did not permit any conclusions about the relative effectiveness of anterior, posterior or circumferential fusion. preliminary results of two small trials of intra-discal electrotherapy showed conflicting results. preliminary data from three trials of disc arthroplasty did not permit any firm conclusions.   authors' conclusions limited evidence is now available to support some aspects of surgical practice. surgeons should be encouraged to perform further rcts in this field.
peak force (pf), contractile rate of force development (rfd) and contractile impulse (ci) are of great importance to competitive weightlifters (wl). these athletes routinely perform successive bouts of high-intensity resistance exercise (hire) within the same day (double-day training) with the aim of improving muscular function and weightlifting performance. the purpose of this investigation was to determine and compare the pf, contractile rfd and ci responses to double-day training between wl and resistance trained (rt) adults (n = 16 per group). furthermore, we sought to establish whether acute changes in muscle function were associated with acute changes in muscle architecture. isometric front squat pf, contractile rfd, ci and the pennation angle (θp), anatomical and physiological thickness of the m. vastus lateralis (vl) were determined before and after two equivalent hire sessions separated by 4–6 h rest. each session consisted of ten single repetitions of the dynamic barbell front squat interspersed with 2-min rest, using a load equivalent to 90% of the pre-session pf. weightlifters demonstrated greater pf at all time points when compared to rt adults and exhibited no significant within or between session changes in pf, contractile rfd or ci. conversely, rt adults demonstrated within- and between-session decreases in pf and between-session increases in contractile rfd and ci. as no correlations were found between the relative within-session changes in muscle function and the concomitant changes in muscle architecture, other factors must contribute to the divergent responses in pf, contractile rfd and ci between wl and rt adults. abstract‘explosive’ muscle strength or contractile rate of force development (rfd) is a term to describe the ability to rapidly develop muscular force, and can be measured as the slope of the torque–time curve obtained during isometric conditions. previously, conflicting results have been reported regarding the relationship between contractile rfd and various physiological parameters. one reason for this discrepancy may be that rfd in various time intervals from the onset of contraction is affected by different physiological parameters. the aim of the present study was to investigate the relationship between voluntary contractile rfd in time intervals of 0–10, 0–20,..., 0–250 ms from the onset of contraction and two main parameters: (1) voluntary maximal muscle strength and (2) electrically evoked muscle twitch contractile properties. the main finding was that voluntary rfd became increasingly more dependent on mvc and less dependent on muscle twitch contractile properties as time from the onset of contraction increased. at time intervals later than 90 ms from the onset of contraction maximal muscle strength could account for 52–81% of the variance in voluntary rfd. in the very early time interval (<40 ms from the onset of contraction) voluntary rfd was moderately correlated to the twitch contractile properties of the muscle and was to a less extent related to mvc. the present results suggest that explosive movements with different time spans are influenced by different physiological parameters. this may have important practical implications when designing resistance training programs for specific sports.
a number of studies suggest that the clinical manifestation of neurological deficits in hepatic encephalopathy results from pathologically synchronized neuronal oscillations and altered oscillatory coupling. in the present study spontaneous and evoked oscillatory brain activities were analyzed jointly with established behavioral measures of altered visual oscillatory processing. critical flicker and fusion frequencies (cff, fuf) were measured in 25 patients diagnosed with liver cirrhosis and 30 healthy controls. magnetoencephalography (meg) data were collected at rest and during a visual task employing repetitive stimulation. resting meg and evoked fields were analyzed. cff and fuf were found to be reduced in patients, providing behavioral evidence for deficits in visual oscillatory processing. these alterations were found to be related to resting brain activity in patients, namely that the lower the dominant meg frequency at rest, the lower the cff and fuf. an analysis of evoked fields at sensor level indicated that in comparison to normal controls, patients were not able to dynamically adapt to flickering visual stimulation. evoked activity was also analyzed based on independent components (ics) derived by independent component analysis. the similarity between the shape of each ic and an artificial sine function representing the stimulation frequency was tested via magnitude squared coherence. in controls, we observed a small number of components that correlated strongly with the sine function and a high number of ics that did not correlate with the sine function. interestingly, patient data were characterized by a high number of moderately correlating components. taken together, these results indicate a fundamental divergence of the cerebral resonance activity in cirrhotic patients. objective hepatic encephalopathy (he) is characterized by neuropsychological and motor deficits. the present study tested the hypothesis that worsening of motor and sensory symptoms of he results from a common basic deficit in the cerebral oscillatory processing within the human motor and visual system.   methods we investigated in 32 patients with liver cirrhosis and he grades 0-2 critical flicker frequency (cff) and cortico-muscular (m1-emg) coherence as a measure of coupling between the surface emgs of hand muscles and primary motor cortex (m1) activity recorded non-invasively with magnetoencephalography (meg) during forearm elevation.   results patients with he-grade 2 developed excessive m1-emg coherence at low frequencies. in contrast, maximum m1-emg coherence in patients with no he showed frequency and amplitude in the physiological range. cff was continuously reduced with worsening grades of he. correlation analysis revealed significant correlation between the frequency of m1-emg coherence and cff.   conclusions taken together, we demonstrate that increased grades of he lead to a pathological m1-emg drive which is reduced in frequency. these effects are correlated with an impaired perception of oscillatory visual stimuli.   significance the results suggest that pathological oscillatory neural processing in different human cerebral systems may represent a basic mechanism for the clinical manifestation of he.
we discuss the geometric engineering and large n transition for an = 1 u(n) chiral gauge theory with one adjoint, one conjugate symmetric, one antisymmetric and eight fundamental chiral multiplets. our iib realization involves an orientifold of a non-compact calabi-yau a2 fibration, together with d5-branes wrapping the exceptional curves of its resolution as well as the orientifold fixed locus. we give a detailed discussion of this background and of its relation to the hanany-witten realization of the same theory. in particular, we argue that the t-duality relating the two constructions maps the 2 orientifold of the hanany-witten realization into a 4 orientifold in type iib. we also discuss the related engineering of theories with so/sp gauge groups and symmetric or antisymmetric matter. abstract we discuss some aspects of the physics of branes in the presence of orientifolds and the corresponding world-volume gauge dynamics. we show that at strong coupling orientifolds sometimes turn into bound states of orientifolds and branes, and give a world-sheet argument for the flip of the sign of an orientifold plane split into two disconnected parts by an ns5-brane. we also describe the moduli space of vacua of n = 2 supersymmetric gauge theories with symplectic and orthogonal gauge groups, and analyze a set of four-dimensional n = 1 supersymmetric gauge theories with chiral matter content using branes.
in this thesis, we study methods to leverage information from fully-structured knowledge bases  (kbs), in particular the encyclopedic knowledge graph (kg) dbpedia, for different text-related  tasks from the area of information retrieval (ir) and natural language processing (nlp). the  key idea is to apply entity linking (el) methods that identify mentions of kb entities in text,  and then exploit the structured information within kgs. developing entity-centric methods for  text understanding using kg exploration is the focus of this work.    we aim to show that structured background knowledge is a means for improving performance in  different ir and nlp tasks that traditionally only make use of the unstructured text input itself.  thereby, the kb entities mentioned in text act as connection between the unstructured text and  the structured kg. we focus in particular on how to best leverage the knowledge as contained in  such fully-structured (rdf) kgs like dbpedia with their labeled edges/predicates – which is in  contrast to previous work on wikipedia-based approaches we build upon, which typically relies  on unlabeled graphs only. the contribution of this thesis can be structured along its three parts:    in part i, we apply el and semantify short text snippets with kb entities. while only retrieving  types and categories from dbpedia for each entity, we are able to leverage this information  to create semantically coherent clusters of text snippets. this pipeline of connecting text to  background knowledge via the mentioned entities will be reused in all following chapters.    in part ii, we focus on semantic similarity and extend the idea of semantifying text with entities  by proposing in chapter 5 a model that represents whole documents by their entities. in this  model, comparing documents semantically with each other is viewed as the task of comparing  the semantic relatedness of the respective entities, which we address in chapter 4. we propose  an unsupervised graph weighting schema and show that weighting the dbpedia kg leads to  better results on an existing entity ranking dataset. the exploration of weighted kg paths turns  out to be also useful when trying to disambiguate the entities from an open information extraction  (oie) system in chapter 6. with this weighting schema, the integration of kg information  for computing semantic document similarity in chapter 5 becomes the task of comparing the two  kg subgraphs with each other, which we address by an approximate subgraph matching. based  on a well-established evaluation dataset for semantic document similarity, we show that our unsupervised  method achieves competitive performance similar to other state-of-the-art methods.  our results from this part indicate that kgs can contain helpful background knowledge, in particular  when exploring kg paths, but that selecting the relevant parts of the graph is an important  yet difficult challenge.    in part iii, we shift to the task of relevance ranking and first study in chapter 7 how to best  retrieve kb entities for a given keyword query. combining again text with kb information, we  extract entities from the top-k retrieved, query-specific documents and then link the documents  to two different kbs, namely wikipedia and dbpedia. in a learning-to-rank setting, we study  extensively which features from the text, thewikipedia kb, and the dbpedia kg can be helpful  for ranking entities with respect to the query. experimental results on two datasets, which build  upon existing trec document retrieval collections, indicate that the document-based mention  frequency of an entity and the wikipedia-based query-to-entity similarity are both important  features for ranking. the kg paths in contrast play only a minor role in this setting, even when  integrated with a semantic kernel extension. in chapter 8, we further extend the integration of  query-specific text documents and kg information, by extracting not only entities, but also relations  from text. in this exploratory study based on a self-created relevance dataset, we find that  not all extracted relations are relevant with respect to the query, but that they often contain information  not contained within the dbpedia kg. the main insight from the research presented in  this part is that in a query-specific setting, established ir methods for document retrieval provide  an important source of information even for entity-centric tasks, and that a close integration of  relevant text document and background knowledge is promising.    finally, in the concluding chapter we argue that future research should further address the integration  of kg information with entities and relations extracted from (specific) text documents,  as their potential seems to be not fully explored yet. the same holds also true for a better kg  exploration, which has gained some scientific interest in recent years. it seems to us that both aspects  will remain interesting problems in the next years, also because of the growing importance  of kgs for web search and knowledge modeling in industry and academia. an empirical evaluation of models of text document similarity michael d. lee (michael.lee@adelaide.edu.au) department of psychology, university of adelaide south australia, 5005, australia brandon pincombe (brandon.pincombe@dsto.defence.gov.au) intelligence surveillance and reconnaissance division, defence science and technology organisation po box 1500, edinburgh sa 5111 australia matthew welsh (matthew.welsh@adelaide.edu.au) australian school of petroleum engineering, university of adelaide south australia, 5005, australia abstract modeling the semantic similarity between text docu- ments presents a significant theoretical challenge for cognitive science, with ready-made applications in in- formation handling and decision support systems deal- ing with text. while a number of candidate models exist, they have generally not been assessed in terms of their ability to emulate human judgments of simi- larity. to address this problem, we conducted an ex- periment that collected repeated similarity measures for each pair of documents in a small corpus of short news documents. an analysis of human performance showed inter-rater correlations of about 0.6. we then considered the ability of existing models—using word- based, n-gram and latent semantic analysis (lsa) approaches—to model these human judgments. the best performed lsa model produced correlations of about 0.6, consistent with human performance, while the best performed word-based and n-gram models achieved correlations closer to 0.5. many of the re- maining models showed almost no correlation with hu- man performance. based on our results, we provide some discussion of the key strengths and weaknesses of the models we examined. introduction modeling the semantic similarity between text docu- ments is an interesting problem for cognitive science, for both theoretical and practical reasons. theoret- ically, it involves the study of a basic cognitive pro- cess with richly structured natural stimuli. practically, search engines, text corpus visualizations, and a vari- ety of other applications for filtering, sorting, retriev- ing, and generally handling text rely fundamentally on similarity measures. for this reason, the ability to as- sess semantic similarity in an accurate, automated, and scalable way is a key determinant of the effectiveness of most information handling and decision support soft- ware that deals with text. a variety of different approaches have been devel- oped for modeling text document similarity. these in- clude simple word-based, keyword-based and n-gram measures (e.g., salton, 1989; damashek, 1995), and more complicated approaches such as latent seman- tic analysis (lsa: deerwester et al., 1990; landauer and dumais, 1997). while all of these approaches have achieved some level of practical success, they have gen- erally not been assessed in terms of their ability to model human judgments of text document similarity. the most likely reason for this failure is that no suit- able empirical data exist, and considerable effort is in- volved in collecting pairwise ratings of text document similarity for even a moderate number of documents. this paper reports the collection of data that give ten independent ratings of the similarity of every pair of 50 short text documents, and so represents an attempt to establish a ‘psychological ground truth’ for evaluating models. using the new data, we report a first eval- uation of the ability of word-based, n-gram and lsa approaches to model human judgments. experiment materials the text corpus evaluated by human judges contained 50 documents selected from the australian broadcast- ing corporation’s news mail service, which provides text e-mails of headline stories. the documents varied in length from 51 to 126 words, and covered a number of broad topics. a further 314 documents from the same were collected to act as a larger ‘backgrounding’ corpus for lsa. both document sets were assessed against a stan- dard corpus of five english texts using four models of language. these were the log-normal, generalized in- verse gauss-poisson (with γ = −0.5), yule-simon and zipfian models (baayen, 2001). both document sets were within the normal range of english text for word frequency spectrum and vocabulary growth and were therefore regarded as representative of normal english texts. subjects the subjects were 83 university of adelaide students (29 males and 54 females), with a mean age of 19.7 years. they were each paid with a ten (australian) dollar gift voucher for every 100 document pair ratings made.
the advent of high-resolution digital cameras and sophisticated multi-view stereo algorithms offers the promise of unprecedented geometric fidelity in image-based modeling tasks, but it also puts unprecedented demands on camera calibration to fulfill these promises. this paper presents a novel approach to camera calibration where top-down information from rough camera parameter estimates and the output of a multi-view-stereo system on scaled-down input images is used to effectively guide the search for additional image correspondences and significantly improve camera calibration parameters using a standard bundle adjustment algorithm (lourakis and argyros 2008). the proposed method has been tested on six real datasets including objects without salient features for which image correspondences cannot be found in a purely bottom-up fashion, and objects with high curvature and thin structures that are lost in visual hull construction even with small errors in camera parameters. three different methods have been used to qualitatively assess the improvements of the camera parameters. the implementation of the proposed algorithm is publicly available at furukawa and ponce (2008b). we show that surface reconstruction from oriented points can be cast as a spatial poisson problem. this poisson formulation considers all the points at once, without resorting to heuristic spatial partitioning or blending, and is therefore highly resilient to data noise. unlike radial basis function schemes, our poisson approach allows a hierarchy of locally supported basis functions, and therefore the solution reduces to a well conditioned sparse linear system. we describe a spatially adaptive multiscale algorithm whose time and space complexities are proportional to the size of the reconstructed model. experimenting with publicly available scan data, we demonstrate reconstruction of surfaces with greater detail than previously achievable.
yersinia pestis, the causative agent of plague, is best known for historical pandemics, but still actively causes disease in many parts of the world. y. pestis is a recently derived clone of the pathogenic species yersinia pseudotuberculosis, but is more associated with human infection. numerous studies have documented genomic changes since the two species differentiated, although all of these studies used a relatively small sample set for defining these differences. in this study, we compared the complete genomic content between a diverse set of y. pestis and y. pseudotuberculosis genomes, and identified unique loci that could serve as diagnostic markers or for better understanding the evolution and pathogenesis of each group. comparative genomics analyses also identified subtle variations in gene content between individual monophyletic clades within these species, based on a core genome single nucleotide polymorphism phylogeny that would have been undetected in a less comprehensive genome dataset. we also screened loci that were identified in other published studies as unique to either species and generally found a non-uniform distribution, suggesting that the assignment of these unique genes to either species should be re-evaluated in the context of current sequencing efforts. overall, this study provides a high-resolution view into the genomic differences between y. pestis and y. pseudotuberculosis, demonstrating fine-scale differentiation and unique gene composition in both species. the blast programs are widely used tools for searching protein and dna databases for sequence similarities. for protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the blast programs to be decreased substantially while enhancing their sensitivity to weak similarities. a new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped blast program that runs at approximately three times the speed of the original. in addition, a method is introduced for automatically combining statistically significant alignments produced by blast into a position-specific score matrix, and searching the database using this matrix. the resulting position-specific iterated blast (psi-blast) program runs at approximately the same speed per iteration as gapped blast, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. psi-blast is used to uncover several new and interesting members of the brct superfamily.
to examine the effect of pain and mild cognitive impairment (mci)—together and separately—on performance‐based and self‐reported mobility outcomes in older adults in primary care with mild to moderate self‐reported mobility limitations. background the prevalence of mild cognitive impairment (mci) and mobility limitations is high among older adults. the aim of this study was to investigate the association between mci status and both performance-based and self-report measures of mobility in community-dwelling older adults.   methods an analysis was conducted on baseline data from the boston rehabilitative impairment study in the elderly study, a cohort study of 430 primary care patients aged 65 or older. neuropsychological tests identified participants with mci and further subclassified those with impairment in memory domains (amci), nonmemory domains (namci), and multiple domains (mdmci). linear regression models were used to assess the association between mci status and mobility performance in the habitual gait speed, figure of 8 walk, short physical performance battery, and self-reported late life function and disability instrument's basic lower extremity and advanced lower extremity function scales.   results participants had a mean age of 76.6 years, and 42% were characterized with mci. participants with mci performed significantly worse than participants without mci (no-mci) on all performance and self-report measures (p < .01). all mci subtypes performed significantly worse than no-mci on all mobility measures (p < .05) except for amci versus no-mci on the figure of 8 walk (p = .054) and basic lower extremity (p = .11). moreover, compared with amci, mdmci manifested worse performance on the figure of 8 walk and short physical performance battery, and namci manifested worse performance on short physical performance battery and basic lower extremity.   conclusions among older community-dwelling primary care patients, performance on a broad range of mobility measures was worse among those with mci, appearing poorest among those with nonmemory mci.
leg venous pressure markedly falls during upright exercise via a muscle pump effect, creating de novo perfusion pressure. we examined physiological roles of this mechanism in increasing femoral artery blood flow (fabf) and its alterations in chronic heart failure (chf). in 10 normal subjects and 10 patients with chf, standard hemodynamic variables, mean ankle vein pressure (mavp), and fabf with doppler techniques were obtained during graded upright bicycle exercise. to evaluate a nonspecific blood flow response, normal subjects also performed supine exercise. in normal subjects, mavp rapidly declined by 45 mmhg and fabf correspondingly increased 5.3-fold without a systemic pressor response during 10 s of light upright exercise at 5 w. approximately 67% of the blood flow response was attributed to the venous pressure drop-dependent mechanism. in chf patients, mavp declined by only 36 mmhg and fabf increased only 1.7-fold during the same upright exercise. the muscle venous pump has an ability to increase fabf at least threefold via the venous pressure drop-dependent mechanism. this mechanism is impaired in chf patients. summaryxamoterol acts as aβ1-adrenoceptor agonist at low sympathetic activity and as an antagonist at high activity. although its long-term efficacy has been proven in patients with mild to moderate heart failure, it remains unclear which effect, agonism or antagonism, accounts for its long-term activity.to clarify the effect of xamoterol on cardiac sympathetic activity in daily life, 24-h r-r interval histograms were obtained during administration of xamoterol 100 mg b. d. for 1 week to 10 patients with mild to moderate heart failure. eight normal subjects were also studied as controls. to examine the relation between the effect of xamoterol and sympathetic activity, plasma noradrenaline (na) levels were measured under 5 graded conditions simulating daily living.xamoterol administration significantly decreased the standard deviation of the r-r interval, both in patients with heart failure and in normal subjects. the mean r-r interval, however, was increased in patients with heart failure, relative to normal subjects.in both groups, the r-r interval histograms had two peaks, i. e. a short daytime peak and a long night-time peak. xamoterol decreased the median of the night-time peak without changing the daytime peak in normal subjects. in contrast, it increased the median of the daytime peak without producing a significant change in the nighttime peak in patients with heart failure. levels of plasma na were significantly higher in patients than in normal subjects under all conditions.thus, in normal subjects xamoterol predominantly increased the slower heart rate at night with only a minor effect on the higher heart rate in the daytime, whereas it predominantly attenuated the daytime tachycardia induced by sympathetic stimulation in patients with heart failure.it is concluded that xamoterol tends overall to act as aβ-adrenoceptor antagonist during the day, especially in the daytime in patients with mild to moderate heart failure. its antagonist rather than its agonist effect may account for the long-term efficacy of xamoterol in patients with mild to moderate heart failure.
regular interactions between commensal bacteria and the enteric mucosal immune environment are necessary for normal immunity. alterations of the commensal bacterial communities or mucosal barrier can disrupt immune function. chronic stress interferes with bacterial community structure (specifically, α-diversity) and the integrity of the intestinal barrier. these interferences can contribute to chronic stress-induced increases in systemic il-6 and tnf-α. chronic stress, however, produces many physiological changes that could indirectly influence immune activity. in addition to il-6 and tnf-α, exposure to acute stressors upregulates a plethora of inflammatory proteins, each having unique synthesis and release mechanisms. we therefore tested the hypothesis that acute stress-induced inflammatory protein responses are dependent on the commensal bacteria, and more specifically, lipopolysaccharide (lps) shed from gram-negative intestinal commensal bacteria. we present evidence that both reducing commensal bacteria using antibiotics and neutralizing lps using endotoxin inhibitor (ei) attenuates increases in some (inflammasome dependent, il-1 and il-18), but not all (inflammasome independent, il-6, il-10, and mcp-1) inflammatory proteins in the blood of male f344 rats exposed to an acute tail shock stressor. acute stress did not impact α- or β- diversity measured using 16s rrna diversity analyses, but selectively reduced the relative abundance of prevotella. these findings indicate that commensal bacteria contribute to acute stress-induced inflammatory protein responses, and support the presence of lps-mediated signaling in stress-evoked cytokine and chemokine production. the selectivity of the commensal bacteria in stress-evoked il-1β and il-18 responses may implicate the inflammasome in this response. motivation biological sequence data is accumulating rapidly, motivating the development of improved high-throughput methods for sequence classification.   results ublast and usearch are new algorithms enabling sensitive local and global search of large sequence databases at exceptionally high speeds. they are often orders of magnitude faster than blast in practical applications, though sensitivity to distant protein relationships is lower. uclust is a new clustering method that exploits usearch to assign sequences to clusters. uclust offers several advantages over the widely used program cd-hit, including higher speed, lower memory use, improved sensitivity, clustering at lower identities and classification of much larger datasets.   availability binaries are available at no charge for non-commercial use at http://www.drive5.com/usearch.
purposeusing a population health services perspective, this article defines and assesses an efficient criteria-based algorithm to identify treatment prevalent and incident cases of schizophrenia. we refer here “treatment” prevalence and incidence since its evaluation depends on a patient receiving a health care service with a diagnosis of schizophrenia.methodsa population-based cohort study was conducted among all adults having a hospital discharge or a physician claim for schizophrenia in the public health plan databases between january 1996 and december 2006. four algorithms to characterize patients with schizophrenia were defined. to identify treatment incident cases in 2006, we removed from the treatment prevalent pool patients with a previous record of schizophrenia between 1996 and 2006 (10-year clearance period). using this 10-year period as reference, kappa coefficients (kc) and positive predictive values (ppv) were calculated to determine the “optimal” length of clearance period to identify incident cases.resultsthe lifetime treatment prevalence and incidence of schizophrenia varied from 0.59 to 1.46% and from 42 to 94 per 100,000, respectively. when compared to the 10-year clearance period, the kc is excellent in a clearance period of 6–7 years. to achieve a ppv of 90%, a clearance period of 7–8 years would be necessary.conclusionswith an appropriate algorithm, treatment prevalence and incidence of schizophrenia can be conveniently estimated using administrative data. these estimates are a vital step toward appropriate planning of services for schizophrenia. simple interval estimate methods for proportions exhibit poor coverage and can produce evidently inappropriate intervals. criteria appropriate to the evaluation of various proposed methods include: closeness of the achieved coverage probability to its nominal value; whether intervals are located too close to or too distant from the middle of the scale; expected interval width; avoidance of aberrations such as limits outside [0,1] or zero width intervals; and ease of use, whether by tables, software or formulae. seven methods for the single proportion are evaluated on 96,000 parameter space points. intervals based on tail areas and the simpler score methods are recommended for use. in each case, methods are available that aim to align either the minimum or the mean coverage with the nominal 1 -alpha.
six-month-olds reliably discriminate different monkey and human faces whereas 9-month-olds only discriminate different human faces. it is often falsely assumed that perceptual narrowing reflects a permanent change in perceptual abilities. in 3 experiments, ninety-six 12-month-olds' discrimination of unfamiliar monkey faces was examined. following 20 s of familiarization, and two 5-s visual-paired comparison test trials, 12-month-olds failed to show discrimination. however, following 40 s of familiarization and two 10-s test trials, 12-month-olds showed reliable discrimination of novel monkey faces. a final experiment was performed demonstrating 12-month-olds' discrimination of the monkey face was due to the increased familiarization rather than increased time of visual comparison. results are discussed in the context of perceptual narrowing, in particular the flexible nature of perceptual narrowing. experience plays a crucial role for the normal development of many perceptual and cognitive functions, such as speech perception. for example, between 6 and 10 months of age, the infant's ability to discriminate among native speech sounds improves, whereas the ability to discriminate among foreign speech sounds declines. however, a recent investigation suggests that some experience with non-native languages from 9 months of age facilitates the maintenance of this ability at 12 months. nelson has suggested that the systems underlying face processing may be similarly sculpted by experience with different kinds of faces. in the current investigation, we demonstrate that, in human infants between 6 and 9 months of age, exposure to non-native faces, in this case, faces of barbary macaques (macaca sylvanus), facilitates the discrimination of monkey faces, an ability that is otherwise lost around 9 months of age. these data support, and further elucidate, the role of early experience in the development of face processing.
power system state estimation (psse) is a critical task for grid operation efficiency and system stability. physical laws dictate quadratic relationships between observable quantities and voltage state variables, hence rendering the psse problem nonconvex and np-hard. existing se solvers largely rely on iterative optimization methods or semidefinite relaxation (sdr) techniques. even when based on noiseless measurements, convergence of the former is sensitive to the initialization, while the latter is challenged by small-size measurements especially when voltage magnitudes are not available at all buses. at the price of running time, this paper proposes a novel feasible point pursuit (fpp)-based se solver, which iteratively seeks feasible solutions for a nonconvex quadratically constrained quadratic programming reformulation of the weighted least-squares (wls) se problem. numerical tests corroborate that the novel fpp-based se markedly improves upon the gauss-newton based wls and sdr-based se alternatives, also when noisy measurements are available. state estimation (se) is an important task allowing power networks to monitor accurately the underlying system state, which is useful for security-constrained dispatch and power system control. for nonlinear ac power systems, se amounts to minimizing a weighted least-squares cost that is inherently nonconvex, thus giving rise to many local optima. as a result, estimators used extensively in practice rely on iterative optimization methods, which are destined to return only locally optimal solutions, or even fail to converge. a semidefinite programming (sdp) formulation for se has been advocated, which relies on the convex semidefinite relaxation (sdr) of the original problem and thereby renders it efficiently solvable. theoretical analysis under simplified conditions is provided to shed light on the near-optimal performance of the sdr-based se solution at polynomial complexity. the new approach is further pursued toward complementing traditional nonlinear measurements with linear synchrophasor measurements and reducing computational complexity through distributed implementations. numerical tests on the standard ieee 30- and 118-bus systems corroborate that the se algorithms outperform existing alternatives, and approach near-optimal performance.
numerous studies have shown that being able to resolve and recover from conflicts is of key importance for relationship satisfaction and stability in adults. less is known about the importance of these relationship dynamics in adolescent romantic relationships. therefore, this study investigated whether conflict resolution and recovery predict breakups in middle adolescent couples. couples who are able to resolve and recover from conflict were expected to demonstrate a lower probability of breaking up. in total, 80 adolescent couples (m age = 15.48, sd = 1.16) participated in a 4-wave prospective questionnaire and observational study, with one year between measurements. in addition to self-report measures, adolescents were observed in real-time during conflicts with their partners. multilevel proportional hazard analyses revealed that, contrary to the hypothesis, conflict resolution and conflict recovery did not predict the likelihood of breakup. survival differences were not attributable to conflict resolution or conflict recovery. more research is needed to consider the unique relationship factors of adolescent romantic relationships to determine why some relationships survive while others do not. preliminary psychometric data are presented for two inventories that assess conflict in couples. the ineffective arguing inventory (iai) is a self-report measure that assesses a dysfunctional style of couple conflict resolution. the conflict resolution style inventory (crsi) has complementary self-report and partner-report versions that assess four personal conflict resolution styles for each member of the couple. subjects were both partners of 75 gay, 51 lesbian, 108 married non-parent, and 99 married parent couples. findings for each inventory are presented regarding the factor structure of items, the internal consistency of composite scores, the 1-year stability of composite scores, the relation between couple members' composite scores, and the link between composite scores and relationship satisfaction, change in satisfaction, and relationship dissolution. generally, results warrant further examination of the iai and crsi as measures of conflict for couples. all couples have to deal with conflict. further, how that conflict is managed is linked to relationship satisfaction, change in relationship satisfaction, and relationship stability (gottman, 1994; heavey, layne, & christensen, 1993; markman, renick, floyd, stanley, & clements, 1993; noller & white, 1990). to date, perhaps the most productive method for studying relationship conflict has been to code videotapes of partner conversations for small samples of couples in a laboratory setting (e.g., gottman, 1994). without denying the value of these behavioral observations--in particular, for assessing sequences of couples' interactional styles during conflict--the present study is based on the premise that self-report and partner-report methodologies are also valuable ways to study couple conflict and may complement observational methodologies. one of the major limitations of observational studies of couple conflict is that they utilize very small, nonrepresentative samples. in fact, some of the inconsistent findings in observational studies regarding the types of conflict resolution strategies that are linked to declines in relationship satisfaction over time have been attributed to biased samples (gottman, 1993). the availability of psychometrically sound self-report and partner-report measures of conflict resolution would help address this limitation by providing researchers with one method by which the link between conflict resolution and both relationship maintenance and relationship dissolution could be studied in large, representative samples. some measures of couple conflict are available, including self-report measures of couple conflict resolution patterns (e.g., the problem-solving communication scale of the marital satisfaction inventory; snyder, 1981), self-report measures of individual conflict resolution styles (e.g., the marital coping inventory, bowman, 1990), and self-report and partner-report measures of each partner's conflict resolution styles (e.g., the interpersonal communication skills inventory; boyd & roach, 1977) as well as sequences of partners' conflict resolution styles (e.g., the communication patterns questionnaire; christensen, 1988). however, no measure of couple conflict resolution could be found that was brief, was based on a coherent conceptual framework, and had comprehensively documented psychometric properties. documenting psychometric properties include validating the measure against the major relationship outcomes used in behavioral observations in this area of study--relationship satisfaction, change in relationship satisfaction, and relationship stability (gottman, 1994; gottman & krokoff, 1989; markman et al., 1993). accordingly, the purpose of this article is to present such preliminary psychometric data for two brief nonobservational measures of couple conflict. the first measure--the ineffective arguing inventory (iai)--assesses how the couple handles conflict, whereas the second measure the conflict resolution styles inventory (crsi)--assesses each partner's individual style of handling conflict. …
a web-based business always wants to have the ability to track users’ browsing behavior history. this ability can be achieved by using web log mining technologies. in this paper, we introduce a self-organizing map (som) based approach to mining web log data. the som network maps the web pages into a two-dimensional map based on the users’ browsing history. web pages with the similar browsing patterns are clustered together. together with associate rules, the cluster generated by the som network has significant meaning to web browsing behavior. the experimental results demonstrate the feasibility and the effectiveness of this approach. this article describes the implementation of a system that is able to organize vast document collections according to textual similarities. it is based on the self-organizing map (som) algorithm. as the feature vectors for the documents statistical representations of their vocabularies are used. the main goal in our work has been to scale up the som algorithm to be able to deal with large amounts of high-dimensional data. in a practical experiment we mapped 6,840,568 patent abstracts onto a 1,002,240-node som. as the feature vectors we used 500-dimensional vectors of stochastic figures obtained as random projections of weighted word histograms.
•  atp transfer from mitochondria to the cytoplasm occurs mainly through phosphate transfer to creatine by mitochondrial creatine kinase (mick) but also by transport and/or diffusion of adp and atp through specific mitochondrial transport protein complexes. •  determining the effect of exercise on phosphate shuttling may require contractile signals in situ and varying creatine concentrations to alter mick activity. •  mitochondrial respiratory sensitivity to adp was assessed in permeabilized muscle fibre bundles (pmfbs) before and after 2 h cycling exercise in human skeletal muscle. •  in relaxed pmfbs, adp sensitivity decreased post‐exercise when mick phosphate shuttling was low (no creatine) with no change in net adp sensitivity in the presence of creatine, whereas in contracting fibres post‐exercise adp sensitivity was higher with creatine. •  this shows mick activity is increased post‐exercise, especially during contraction in pmfbs, and suggests exercise regulates phosphate shuttling, which would improve maintenance of energy homeostasis during contraction. the hypothesis that the aging process is associated with mitochondrial dysfunction and oxidative stress has been investigated in human skeletal muscle. muscle biopsy samples were taken from seven old male subjects [os; 75 (range 61–86) years] and eight young male subjects [ys; 25 (22–31) years]. oxidative function was measured both in permeabilised muscle fibres and isolated mitochondria. despite matching the degree of physical activity, os had a lower training status than ys as judged from pulmonary maximal o2 consumption (v̇o2max, −36%) and handgrip strength (−20%). both maximal respiration and creatine-stimulated respiration were reduced in muscle fibres from os (−32 and −34%, respectively). in contrast, respiration in isolated mitochondria was similar in os and ys. the discrepancy might be explained by a biased harvest of "healthy" mitochondria and/or disruption of structural components during the process of isolation. cytochrome c oxidase was reduced (−40%, p<0.01), whereas ucp3 protein tended to be elevated in os (p=0.09). generation of reactive oxygen species by isolated mitochondria and measures of antioxidative defence (muscle content of glutathione, glutathione redox status, antioxidative enzymes activity) were not significantly different between os and ys. it is concluded that aging is associated with mitochondrial dysfunction, which appears to be unrelated to reduced physical activity. the hypothesis of increased oxidative stress in aged muscle could not be confirmed in this study.
spherical deconvolution (sd) is commonly used for estimating fiber orientation distribution functions (fodfs) from diffusion-weighted signals. existing sd methods can be classified into two categories: 1) continuous representation based sd (cr-sd), where typically spherical harmonic (sh) representation is used for convenient analytical solutions, and 2) discrete representation based sd (dr-sd), where the signal profile is represented by a discrete set of basis functions uniformly oriented on the unit sphere. a feasible fodf should be non-negative and should integrate to unity throughout the unit sphere s(2). however, to our knowledge, most existing sh-based sd methods enforce non-negativity only on discretized points and not the whole continuum of s(2). maximum entropy sd (mesd) and cartesian tensor fiber orientation distributions (ct-fod) are the only sd methods that ensure non-negativity throughout the unit sphere. they are however computational intensive and are susceptible to errors caused by numerical spherical integration. existing sd methods are also known to overestimate the number of fiber directions, especially in regions with low anisotropy. dr-sd introduces additional error in peak detection owing to the angular discretization of the unit sphere. this paper proposes a sd framework, called non-negative sd (nnsd), to overcome all the limitations above. nnsd is significantly less susceptible to the false-positive peaks, uses sh representation for efficient analytical spherical deconvolution, and allows accurate peak detection throughout the whole unit sphere. we further show that nnsd and most existing sd methods can be extended to work on multi-shell data by introducing a three-dimensional fiber response function. we evaluated nnsd in comparison with constrained sd (csd), a quadratic programming variant of csd, mesd, and an l1-norm regularized non-negative least-squares dr-sd. experiments on synthetic and real single-/multi-shell data indicate that nnsd improves estimation performance in terms of mean difference of angles, peak detection consistency, and anisotropy contrast between isotropic and anisotropic regions. we present a method for the estimation of various features of the tissue micro-architecture using the diffusion magnetic resonance imaging. the considered features are designed from the displacement probability density function (pdf). the estimation is based on two steps: first the approximation of the signal by a series expansion made of gaussian-laguerre and spherical harmonics functions; followed by a projection on a finite dimensional space. besides, we propose to tackle the problem of the robustness to rician noise corrupting in-vivo acquisitions. our feature estimation is expressed as a variational minimization process leading to a variational framework which is robust to noise. this approach is very flexible regarding the number of samples and enables the computation of a large set of various features of the local tissues structure. we demonstrate the effectiveness of the method with results on both synthetic phantom and real mr datasets acquired in a clinical time-frame.
hart, cef and tracy, bl. yoga as steadiness training: effects on motor variability in young adults. j strength cond res 22(5): 1659-1669, 2008-exercise training programs can increase strength and improve submaximal force control, but the effects of yoga as an alternative form of steadiness training are not well described. the purpose was to explore the effect of a popular type of yoga (bikram) on strength, steadiness, and balance. young adults performed yoga training (n = 10, 29 ± 6 years, 24 yoga sessions in 8 weeks) or served as controls (n = 11, 26 ± 7 years). yoga sessions consisted of 1.5 hours of supervised, standardized postures. measures before and after training included maximum voluntary contraction (mvc) force of the elbow flexors (ef) and knee extensors (ke), steadiness of isometric ef and ke contractions, steadiness of concentric (con) and eccentric (ecc) ke contractions, and timed balance. the standard deviation (sd) and coefficient of variation (cv, sd/mean force) of isometric force and the sd of acceleration during con and ecc contractions were measured. after yoga training, mvc force increased 14% for ke (479 ± 175 to 544 ± 187 n, p < 0.05) and was unchanged for the ef muscles (219 ± 85 to 230 ± 72 n, p > 0.05). the cv of force was unchanged for ef (1.68 to 1.73%, p > 0.05) but was reduced in the ke muscles similarly for yoga and control groups (2.04 to 1.55%, p < 0.05). the variability of con and ecc contractions was unchanged. for the yoga group, improvement in ke steadiness was correlated with pretraining steadiness (r = −0.62 to −0.84, p < 0.05); subjects with the greatest ke force fluctuations before training experienced the greatest reductions with training. percent change in balance time for individual yoga subjects averaged +228% (19.5 ± 14 to 34.3 ± 18 seconds, p < 0.05), with no change in controls. for young adults, a short-term yoga program of this type can improve balance substantially, produce modest improvements in leg strength, and improve leg muscle control for less-steady subjects. purpose to determine the contribution of visuomotor correction to increased force fluctuations in the elbow flexor and knee extensor muscles of elderly adults.   methods young (n = 22, 23 +/- 3 yr) and elderly (n = 23, 74 +/- 7 yr) adults performed constant-force contractions at target forces of 2.5, 30, and 65% mvc. visual feedback was provided (6-8 s) and then removed (6-8 s). after removal of drift (< 0.5 hz) from the force, the standard deviation (sd) and coefficient of variation (cv) of force were calculated from vision and no-vision data.   results maximal voluntary contraction (mvc) force was 19% lower for elbow flexors and 37% lower for knee extensors in elderly adults than in young adults. overall, the cv of force was 27% greater in the vision condition compared with the no-vision condition. the cv of force for vision was greater for elderly adults than for young adults at the 2.5% mvc target force and lower at 30 and 65% mvc. for the 2.5% mvc target force, the decline in cv of force from vision to no vision was greater for elderly adults than for young adults. at 30 and 65% mvc, the decline was significant but similar for young and elderly adults. for elbow flexors, the change in power from vision to no vision was greater for 0- to 4-hz (reduced power) and 8- to 12-hz (increased power) frequencies for elderly adults compared with young adults.   conclusion visuomotor correction contributed to force fluctuations in large proximal muscles. the contribution was greater for healthy elderly adults at low forces. visuomotor processes thus contributed to the age-related increase in force fluctuations.
although risk and benefits of risky activities are positively correlated in the real world, empirical results indicate that people perceive them as negatively correlated. the common explanation is that confounding benefits and losses stems from affect. in this article, we address the issue that has not been clearly established in studies on the affect heuristic: to what extent boundary conditions, such as judgments' generality and expertise, influence the presence of the inverse relation in judgments of hazards. these conditions were examined in four studies in which respondents evaluated general or specific benefits and risks of "affect-rich" and "affect-poor" hazards (ranging from investments to applications of stem cell research). in line with previous research, affect is defined as good or bad feelings integral to a stimulus. in contrast to previous research, affect is considered as related both to personal feelings and to social controversies associated with a hazard. expertise is related to personal knowledge (laypersons vs. experts) as well as to objective knowledge (targets well vs. poorly known to science). the direct comparison of the input from personal and objective ignorance into the inverse relation has not been investigated previously. it was found that affect invoked by a hazard guides general but not specific judgments of its benefits and risks. technical expertise helps to avoid simplified evaluations of consequences as long as they are well known to science. for new, poorly understood hazards (e.g., stem cell research), expertise does not protect from the perception of the inverse relation between benefits and risks. hypotheses involving mediation are common in the behavioral sciences. mediation exists when a predictor affects a dependent variable indirectly through at least one intervening variable, or mediator. methods to assess mediation involving multiple simultaneous mediators have received little attention in the methodological literature despite a clear need. we provide an overview of simple and multiple mediation and explore three approaches that can be used to investigate indirect processes, as well as methods for contrasting two or more mediators within a single model. we present an illustrative example, assessing and contrasting potential mediators of the relationship between the helpfulness of socialization agents and job satisfaction. we also provide sas and spss macros, as well as mplus and lisrel syntax, to facilitate the use of these methods in applications.
hypothalamic serotonin inhibits food intake and stimulates energy expenditure. high-fat feeding is obesogenic, but the role of polyunsaturated fats is not well understood. this study examined the influence of different high-pufa diets on serotonin-induced hypophagia, hypothalamic serotonin turnover, and hypothalamic protein levels of serotonin transporter (st), and sr-1b and sr-2c receptors. male wistar rats received for 9 weeks from weaning a diet high in either soy oil or fish oil or low fat (control diet). throughout 9 weeks, daily intake of fat diets decreased such that energy intake was similar to that of the control diet. however, the fish group developed heavier retroperitoneal and epididymal fat depots. after 12 h of either 200 or 300 μg intracerebroventricular serotonin, food intake was significantly inhibited in control group (21–25%) and soy group (37–39%) but not in the fish group. serotonin turnover was significantly lower in the fish group than in both the control group (−13%) and the soy group (−18%). sr-2c levels of fish group were lower than those of control group (50%, p = 0.02) and soy group (37%, p = 0.09). st levels tended to decrease in the fish group in comparison to the control group (16%, p = 0.339) and the soy group (21%, p = 0.161). thus, unlike the soy-oil diet, the fish-oil diet decreased hypothalamic serotonin turnover and sr-2c levels and abolished serotonin-induced hypophagia. fish-diet rats were potentially hypophagic, suggesting that, at least up to this point in its course, the serotonergic impairment was either compensated by other factors or not of a sufficient extent to affect feeding. that fat pad weight increased in the absence of hyperphagia indicates that energy expenditure was affected by the serotonergic hypofunction. objective using rats we examined whether maternal intake of hydrogenated fat rich in trans fatty acids affects brain fatty acid profile, hypothalamic content of insulin receptor and insulin receptor substrate-1 proteins, and the hypophagic effect of centrally administered insulin in 3-mo-old male progeny.   methods throughout pregnancy and lactation, wistar rats ate isocaloric/normolipidic diets with soybean oil (control) or soybean oil-derived hydrogenated fat (trans diet) as a fat source. upon weaning, the trans offspring continued on the trans diet (trans group) or were switched to a control diet (trans-control group).   results compared with control rats, trans rats had lower brain levels of eicosapentaenoic acid. compared with trans rats, trans-control rats had increased levels of total polyunsaturated fatty acids and arachidonic acid and decreased levels of trans fatty acids, saturated fatty acids, and monounsaturated fatty acids. insulin receptor and insulin receptor substrate-1 levels were significantly lower (44% and 38%, respectively) in trans than in control rats. in trans-control rats, insulin receptor was 26% lower (p < 0.05), whereas insulin receptor substrate-1 was 50% lower, than in control rats. insulin decreased 24-h feeding in control (27%) and trans (38%) rats but failed to do so in trans-control rats. the latter group had increased serum glucose levels.   conclusions the data suggest that the early (intrauterine/perinatal) exposure to hydrogenated fat rich in trans fatty acids programmed the hypothalamic feeding control mechanisms. as young adults, only trans-control animals showed loss of insulin-induced hypophagia, indicating that the mismatch between early and later nutritional environments was relevant. however, the trans group also showed signs of altered appetite signaling mechanisms, suggesting that the early adaptations may have deleterious consequences later in life.
during assessment year 2004-2005, income tax department of government of india has shifted to new paradigm by introducing an emerging e-government service - e-filling (online tax filing). this government-to-citizens (g2c) service has significant benefits for both- government as well as for taxpayers in terms of cost effective, convenient, time saving, accuracy, fast, secure, more productive and efficient. while several benefits incurred in e-filing, all the taxpayers of country many not be able to realize these benefits due to several factors. a large number of taxpayers still prefer pen and paper based tax filing or take help of intermediaries (e.g. tax consultant) in order to file return. in developing country like india, internet and technology is still out of reach of many citizens and people are not technologically matured to utilize full potentiality of internet and technology. the purpose of this study is to investigate the underlying factors that influence citizens' intensions to adopt e-filing in the indian context. quantitative approach is used in this study to investigate adoption factors and total 349 questionnaires were received and 294 were found valid to analyze. participants in the survey were indian citizens who file their taxes to indian authorities.  the proposed e-filing integrated adoption model is built on prior theories - technology adoption model (tam), diffusion of innovation (doi), perceived characteristics of innovating (pci), web trust theory and perceived risk, web service quality. the result of the analysis showed that perceive usefulness (pu), perceived ease-of-use (peou), compatibility, service quality, trust of the internet, trust of the government, result demonstrability, service quality and social influence are found to be significant predictors of citizens' intention to use e-filing.  this study has established a comprehensive research model integrating major theories and dimensions of adoption. the study may assist government or other concern authorities to understand citizens' behavior and their perceptions towards e-fling system and other e-government services too. the study suggests that upgrading e-filing system services will improve taxpayers' compliance that will improve the intention of taxpayers positively to use it. future research might employ a larger sample to generalize to the whole country. furthermore, qualitative research like interview with selected taxpayers can cater other factors related to efficiency and effectiveness of e-filing. abstract. electronic government, or e‐government, increases the convenience and accessibility of government services and information to citizens. despite the benefits of e‐government – increased government accountability to citizens, greater public access to information and a more efficient, cost‐effective government – the success and acceptance of e‐government initiatives, such as online voting and licence renewal, are contingent upon citizens’ willingness to adopt this innovation. in order to develop ‘citizen‐centred’ e‐government services that provide participants with accessible, relevant information and quality services that are more expedient than traditional ‘brick and mortar’ transactions, government agencies must first understand the factors that influence citizen adoption of this innovation. this study integrates constructs from the technology acceptance model, diffusions of innovation theory and web trust models to form a parsimonious yet comprehensive model of factors that influence citizen adoption of e‐government initiatives. the study was conducted by surveying a broad diversity of citizens at a community event. the findings indicate that perceived ease of use, compatibility and trustworthiness are significant predictors of citizens’ intention to use an e‐government service. implications of this study for research and practice are presented.
item-to-item collaborative filtering (aka.item-based cf) has been long used for building recommender systems in industrial settings, owing to its interpretability and efficiency in real-time personalization. it builds a user's profile as her historically interacted items, recommending new items that are similar to the user's profile. as such, the key to an item-based cf method is in the estimation of item similarities. early approaches use statistical measures such as cosine similarity and pearson coefficient to estimate item similarities, which are less accurate since they lack tailored optimization for the recommendation task. in recent years, several works attempt to learn item similarities from data, by expressing the similarity as an underlying model and estimating model parameters by optimizing a recommendation-aware objective function. while extensive efforts have been made to use shallow linear models for learning item similarities, there has been relatively less work exploring nonlinear neural network models for item-based cf. in this work, we propose a neural network model named neural attentive item similarity model (nais) for item-based cf. the key to our design of nais is an attention network, which is capable of distinguishing which historical items in a user profile are more important for a prediction. compared to the state-of-the-art item-based cf method factored item similarity model (fism) [1] , our nais has stronger representation power with only a few additional parameters brought by the attention network. extensive experiments on two public benchmarks demonstrate the effectiveness of nais. this work is the first attempt that designs neural network models for item-based cf, opening up new research possibilities for future developments of neural recommender systems. we present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. we describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. we give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. we experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.
recommender systems have been widely advocated as a way of coping with the problem of information overload for knowledge workers. given this, multiple recommendation methods have been developed. however, it has been shown that no one technique is best for all users in all situations. thus we believe that effective recommender systems should incorporate a wide variety of such techniques and that some form of overarching framework should be put in place to coordinate the various recommendations so that only the best of them (from whatever source) are presented to the user. to this end, we show that a marketplace, in which the various recommendation methods compete to offer their recommendations to the user, can be used in this role. specifically, this article presents the principled design of such a marketplace (including the auction protocol, the reward mechanism, and the bidding strategies of the individual recommendation agents) and evaluates the market's capability to effectively coordinate multiple methods. through analysis and simulation, we show that our market is capable of shortlisting recommendations in decreasing order of user perceived quality and of correlating the individual agent's internal quality rating to the user's perceived quality. we have designed, implemented, deployed and evaluated a large-scale agent-oriented information system that recommends relevant documents to users. our recommender system is now being used across several european institutions. its two key features are a modular design capable of accomodating multiple recommendation methods, and the use of a marketplace to select and rank the best recommendations for the user. as part of our evaluation, we have extensively simulated this marketplace in order to understand its dynamics and validate its suitability for a reeommender system.
traditional machine translation evaluation metrics such as bleu and wer have been widely used, but these metrics have poor correlations with human judgements because they badly represent word similarity and impose strict identity matching. in this paper, we propose some modifications to the traditional measures based on word embeddings for these two metrics. the evaluation results show that our modifications significantly improve their correlation with human judgements. a goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. this is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. we propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. the model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. we report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.
purposeeicosapentaenoic acid (epa) has been reported to augment endothelial function and improve clinical outcomes in patients with coronary artery disease (cad). the purpose of this study was to determine whether epa could improve residual endothelial dysfunction despite adequate lipid-lowering with statin in cad patients.methodseighty patients with established cad, who had been on statin treatment and had serum low-density lipoprotein cholesterol (ldl-c) levels <100 mg/dl, were randomly assigned to receive either 1,800 mg of epa daily plus statin (epa group, n = 40) or statin alone (control group, n = 40). lipid profiles and flow-mediated dilation (fmd) were assessed just before and after more than 3 months of treatment in both groups. only patients who had impaired fmd (<6 %) before randomization were enrolled.resultsafter treatment for 5.2 ± 1.7 months, the epa group showed a significant increase in the serum concentration of epa and epa to arachidonic acid (aa) (epa/aa) ratio (62.5 ± 38.1 to 159.8 ± 53.8 μg/ml, 0.45 ± 0.34 to 1.20 ± 0.55, p < 0.01 for both). in the epa group, serum triglycerides significantly decreased (150.7 ± 92.9 to 119.3 ± 60.7 mg/dl, p = 0.02), whereas no significant change was seen in the control group. fmd, the primary study endpoint, showed a significant improvement in the epa group (2.6 ± 1.6 % to 3.2 ± 1.6 %, p = 0.02), whereas no significant change was observed in the control group (2.7 ± 1.6 % to 2.4 ± 1.7 %, p = 0.29).conclusionsepa improved endothelial function and impaired fmd in patients with established cad who were on optimal statin therapy. endothelial function is thought to be an important factor in the pathogenesis of atherosclerosis, hypertension and heart failure. in the 1990s, high-frequency ultrasonographic imaging of the brachial artery to assess endothelium-dependent flow-mediated vasodilation (fmd) was developed. the technique provokes the release of nitric oxide, resulting in vasodilation that can be quantitated as an index of vasomotor function. the noninvasive nature of the technique allows repeated measurements over time to study the effectiveness of various interventions that may affect vascular health. however, despite its widespread use, there are technical and interpretive limitations of this technique. state-of-the-art information is presented and insights are provided into the strengths and limitations of high-resolution ultrasonography of the brachial artery to evaluate vasomotor function, with guidelines for its research application in the study of endothelial physiology.
under intracellular recording, we studied the effect of atp on nerve cells of the rat intact nodose ganglion. the resting membrane potential of the examined neurons was, on average, –60.3 ± 1.4 mv (n = 84); among such units, 88% were classified as c cells. local application of 2 mm atp to the surface of the ganglion using a modified laminar flow system led to depolarization of neurons by 7.1 ± 0.9 mv, on average (n = 19). a blocker of p2x receptors, ppads (100 μm), suppressed these depolarization responses, decreasing their amplitude, on average, to 16 ± 3% (n = 3) of the initial value. the obtained data indicate that an overwhelming majority of neurons of the intact nodose ganglion possess functional p2x receptors on their membranes. the absence of the corresponding responses in a considerable part of neurons of intact spinal ganglia [13-15] was, apparently, determined by the fact that p2x receptors in the course of the described experiments had enough time to desensitize before atp reached the effective concentration. the effects of divalent cations on responses to 5‐hydroxytryptamine (5‐ht), gamma‐aminobutyric acid (gaba) and 1,1‐dimethyl‐4‐phenyl piperazinium (dmpp) were investigated using a sucrose‐gap method to record population responses. in ca‐free medium responses to 5‐ht were enhanced, those to dmpp depressed and those to gaba unchanged. in mg‐free medium responses to 5‐ht were unchanged, while those to dmpp and gaba were depressed. removal of both ca and mg from the superfusion medium caused a small reduction of gaba responses and a large reduction of dmpp responses. responses to 5‐ht were not only greatly potentiated but were changed in character; the depolarizing phase became sigmoid and the dose dependence between quantity of 5‐ht and response magnitude was lost as if 5‐ht were triggering an all‐or‐nothing phenomenon. dose‐‐response relationships for gaba were normal in the large majority of preparations. in about 10% of preparations, supramaximal amounts of gaba or dmpp evoked large responses of a similar character to those evoked by 5‐ht. the large responses, generated by an unknown mechanism, were termed x responses. further reduction in tissue divalent cations by egta (1 mm) caused x responses to be generated spontaneously. ca, mg, mn or co (1 mm) could suppress x responses. dmpp responses, reduced in ca/mg‐free medium, were largely restored by 1 mm‐ca. depression of gaba responses in ca/mg‐free medium could be entirely attributed to the absence of mg, mn being able to substitute for mg. x responses were generated only after equilibration for 1 h with ca/mg‐free medium. attempts to manipulate [ca]i with dinitrophenol or caffeine did not produce the conditions under which x responses were generated. intracellular records of responses to 5‐ht, gaba or dmpp showed that cells with a fibres responded to gaba but not to 5‐ht or dmpp. fifty‐four out of sixty‐seven cells with c fibre axons (80%) were depolarized by 5‐ht, thirty‐seven out of forty‐nine (76%) by dmpp and forty out of fifty‐seven (70%) by gaba. eighteen out of thirty‐eight (47%) c cells were depolarized by all three agents. some c cells were very sensitive to 5‐ht, 10(‐6) m evoking a substantial response. in most, responses to 10(‐5) m‐5‐ht had a slower rate of rise than responses to 10(‐4) or 10(‐3) m‐gaba or dmpp, yet lower 5‐ht concentrations normally elicited x responses in sucrose‐gap experiments whereas gaba or dmpp normally did not.(abstract truncated at 400 words)
summaryobjectives:this article is the last in a series of four that present data about physical activity in 15 members states of the european union collected by the eurobarometer 58.2. the focus of this article is on the perception of environmental opportunities for physical activity across the european union.  methods:data were collected in 2002 as part of the eurobarometer by face-to-face interviews. a total of 16230 respondents age 15 years and older were interviewed. sample sizes ranged about 1000 respondents in most nations. physical activity was assessed with the last 7-days short version of the international physical activity questionnaire (ipaq).  results:results indicate relationships between the perceptions of environmental opportunities; gross household income and physical activity level (in met-hours/per week) of respondents. respondents who reported lower income and less physical activity had also more negative perceptions of environmental opportunities. across nations, respondents in denmark, the netherlands, luxembourg, and western germany had the highest satisfaction with environmental opportunities for physical activity. in some nations, positive correlations between the perception of environmental opportunities and physical activity levels could be observed.  conclusions:results show variations in the perception of environmental opportunities across the eu. overall, the majority of respondents rated their environmental opportunities for physical activity favourable. physically active lifestyles are regularly associated with improved health and quality of life. differences in lifestyles in society can partly be understood through the differences in the social and physical environment. this study examines the relationships between reported physical activity, and the extent of perceived support for physical activity in the physical and policy environment (e.g. facilities, programmes and other opportunities), and in the social environment. the data for the study come from a cross-cultural health policy study called mareps. in total, 3342 adults, 18 years or older, from six countries (belgium, finland, germany, the netherlands, spain, switzerland) were interviewed via telephone. respondents were categorised as active or inactive according to self-reported physical activity. social environmental factors and physical and policy environmental factors were also assessed. the analysis of the data was informed by social cognitive theory, although the study was not originally designed for this purpose. sixty-eight percent of females and 70% of males were active. the proportions of active and inactive varied by countries to a great extent. the strongest independent predictor of being physically active was social environment. those who perceived low social support from their personal environment (i.e. family, friends, school and workplace) were more than twice as likely to be sedentary compared to those who reported high social support from their personal environment. specific knowledge of the programmes and actions for physical activity and sport was also a strong predictor of being active. a supportive physical and policy environment was not associated with participation in physical activity as strongly as had been anticipated. the variation between countries was stronger predictor of being active than the physical and policy environment variables. this study generates the hypotheses and raises the questions that in a preliminary way, there appears to be some relationships between aspects of physical and social environment and physical activity participation. however, future research is needed to refine and clarify this.
mathematics ability and disability is as heritable as other cognitive abilities and disabilities, however its genetic etiology has received relatively little attention. in our recent genome-wide association study of mathematical ability in 10-year-old children, 10 snp associations were nominated from scans of pooled dna and validated in an individually genotyped sample. in this paper, we use a ‘snp set’ composite of these 10 snps to investigate gene-environment (ge) interaction, examining whether the association between the 10-snp set and mathematical ability differs as a function of ten environmental measures in the home and school in a sample of 1888 children with complete data. we found two significant ge interactions for environmental measures in the home and the school both in the direction of the diathesis-stress type of ge interaction: the 10-snp set was more strongly associated with mathematical ability in chaotic homes and when parents are negative. the twins early development study (teds) focuses on the early development of the three most common psychological problems in childhood: communication disorders, mild mental impairment and behavior problems. the teds twins were assessed longitudinally at 2, 3, 4 and 7 years of age in order to investigate genetic and environmental contributions to change and continuity in language and cognitive development; it is multivariate in order to examine the origins of comorbidity; and it uses a large sample in order to study abnormal development in the context of normal development. the twins were identified from birth records of twins born in the uk in 1994-96. more than 15,000 pairs of twins have been enrolled in teds and the participating families are representative of the uk. the measures at 2, 3 and 4 years are administered by parents. at 7 years, children are assessed for language and cognitive development using telephone testing, parents and children are interviewed about behavior problems, and teachers also assess behavior problems as well as academic achievement. one set of findings is that the same genes largely contribute to both language and cognitive problems and the same genes affect normal and abnormal development, a result that suggests that general impairment may be a better target for genetic research than specific language impairment independent of nonverbal cognitive problems. dna has been obtained so far for more than 4000 pairs and is being used initially in molecular genetic studies of language problems and hyperactivity.
metamorphic testing is a testing technique that can be used to verify the functional correctness of software in the absence of an ideal oracle. this paper extends metamorphic testing into a user-oriented approach to software verification, validation, and quality assessment, and conducts large scale empirical studies with four major web search engines: google, bing, chinese bing, and baidu. these search engines are very difficult to test and assess using conventional approaches owing to the lack of an objective and generally recognized oracle. the results are useful for both search engine developers and users, and demonstrate that our approach can effectively alleviate the oracle problem and challenges surrounding a lack of specifications when verifying, validating, and evaluating large and complex software systems. metamorphic testing (mt) is an effective methodology for testing those so-called ``non-testable'' programs (e.g., scientific programs), where it is sometimes very difficult for testers to know whether the outputs are correct. in metamorphic testing, metamorphic relations (mrs) (which specify how particular changes to the input of the program under test would change the output) play an essential role. however, testers may typically have to obtain mrs manually. in this paper, we propose a search-based approach to automatic inference of polynomial mrs for a program under test. in particular, we use a set of parameters to represent a particular class of mrs, which we refer to as polynomial mrs, and turn the problem of inferring mrs into a problem of searching for suitable values of the parameters. we then dynamically analyze multiple executions of the program, and use particle swarm optimization to solve the search problem. to improve the quality of inferred mrs, we further use mr filtering to remove some inferred mrs. we also conducted three empirical studies to evaluate our approach using four scientific libraries (including 189 scientific functions). from our empirical results, our approach is able to infer many high-quality mrs in acceptable time (i.e., from 9.87 seconds to 1231.16 seconds), which are effective in detecting faults with no false detection.
depression is common, especially in women of child-bearing age; prevalence estimates for this group range from 8% to 12%, and there is robust evidence that maternal depression is associated with mental health problems in offspring. suicidal behaviour is a growing concern amongst young people and those exposed to maternal depression are likely to be especially at high risk. the aim of this study was to utilise a large, prospective population cohort to examine the relationship between depression symptom trajectories in mothers over the first eleven years of their child’s life and subsequent adolescent suicidal ideation. an additional aim was to test if associations were explained by maternal suicide attempt and offspring depressive disorder. data were utilised from a population-based birth cohort: the avon longitudinal study of parents and children. maternal depression symptoms were assessed repeatedly from pregnancy to child age 11 years. offspring suicidal ideation was assessed at age 16 years. using multiple imputation, data for 10,559 families were analysed. using latent class growth analysis, five distinct classes of maternal depression symptoms were identified (minimal, mild, increasing, sub-threshold, chronic-severe). the prevalence of past-year suicidal ideation at age 16 years was 15% (95% ci: 14-17%). compared to offspring of mothers with minimal symptoms, the greatest risk of suicidal ideation was found for offspring of mothers with chronic-severe symptoms [or 3.04 (95% ci 2.19, 4.21)], with evidence for smaller increases in risk of suicidal ideation in offspring of mothers with sub-threshold, increasing and mild symptoms. these associations were not fully accounted for by maternal suicide attempt or offspring depression diagnosis. twenty-six percent of non-depressed offspring of mothers with chronic-severe depression symptoms reported suicidal ideation. risk for suicidal ideation should be considered in young people whose mothers have a history of sustained high levels of depression symptoms, even when the offspring themselves do not have a depression diagnosis. the development of a 10-item self-report scale (epds) to screen for postnatal depression in the community is described. after extensive pilot interviews a validation study was carried out on 84 mothers using the research diagnostic criteria for depressive illness obtained from goldberg's standardised psychiatric interview. the epds was found to have satisfactory sensitivity and specificity, and was also sensitive to change in the severity of depression over time. the scale can be completed in about 5 minutes and has a simple method of scoring. the use of the epds in the secondary prevention of postnatal depression is discussed.
background pharmacological intervention of redox balance in cancer cells often results in oxidative stress-mediated apoptosis, attracting much attention for the development of a new generation of targeted therapy in cancer. however, little is known about mechanisms underlying the conversion from oxidative signaling to downstream activities leading cells to death. methodology/principal findings we here report a systematic detection of transcriptome changes in response to oxidative signals generated in leukemia cells upon fenretinide treatment, implicating the occurrence of numerous stress-responsive events during the fenretinide induced apoptosis, such as redox response, endoplasmic reticulum stress/unfolded protein response, translational repression and proteasome activation. moreover, the configuration of these relevant events is primarily orchestrated by stress responsive transcription factors, as typically highlighted by nf-e2-related factor-2 (nrf2) and heat shock factor 1 (hsf1). several lines of evidence suggest that the coordinated regulation of these transcription factors and thus their downstream genes are involved in converting oxidative signaling into downstream stress-responsive events regulating pro-apoptotic and apoptotic activities at the temporal and spatial levels, typifying oxidative stress-mediated programmed death rather than survival in cancer cells. conclusions/significance this study provides a roadmap for understanding oxidative stress-mediated apoptosis in cancer cells, which may be further developed into more sophisticated therapeutic protocols, as implicated by synergistic induction of cell apoptosis using proteasome inhibitors with fenretinide. we describe a powerful approach, component plane presentation integrated self‐organizing map (som), for the analysis of microarray data. this approach allows the display of multi‐dimensional som outputs of microarray data in multiple sample specific presentations, providing distinct advantages in visual inspection of biological significances of genes clustered in each map unit with respect to each rna sample. beneficial potentials of the approach are highlighted by processing microarray data from yeast cells as well as human breast malignancies.
the purpose of this article is to investigate effective reformism: strategies that innovation networks deploy to create changes in their environment in order to establish a more conducive context for the realization and durable embedding of their innovation projects. using a case study approach, effective reformism efforts are analyzed in a technological innovation trajectory related to the implementation of a new poultry husbandry system and an organizational innovation trajectory concerning new ways of co-operation among individual farms to establish economies of scale. the findings reinforce the idea, emerging from a complexity perspective on agricultural innovation systems, that interaction between innovation networks and their environment is only steerable to a limited extent. nonetheless, innovation networks can enhance effective reformism by creating tangible visions that serve as vehicles to create understanding about the innovation and mobilize support for it, and by employing several kinds of boundary spanning individuals that are able to forge effective connections between innovation networks and their environment. because innovation networks can only partially influence their institutional environment, and because unintended consequences of actions and random events influence the course of the innovation process, innovation network actors need to continuously re-interpret the contexts in which they move. this constant reflection by the innovating actors on their position vis-a-vis their environment needs to be supported by dedicated facilitators and monitoring and evaluation methods aimed at system learning. this implies that agricultural innovation policies should, instead of aiming to fully plan and control innovation, foster the emergence of such flexible support instruments that enable adaptive innovation management. transforum is an innovation program which aims to make a substantial contribution to the transition towards more sustainable development of the dutch agricultural sector. this article describes the scientific foundation and architecture of this program. transforum operates on the basis of five working hypotheses which together constitute one integrated analytical framework. these hypotheses are: (1) sustainable development is a dynamic system property; (2) sustainable development needs system innovation; (3) system innovation is a non-linear learning process; (4) system innovation requires active participation of relevant key players from knowledge institutes, governmental bodies, civil society organisations and the business community; (5) the program requires transdisciplinary collaboration of all players. transforum identifies three new innovation strategies: (1) vital clusters; (2) regional development; (3) international agro-food networks; as alternatives to the current arrangements. innovative projects are organised in these innovation strategies. the aim of the scientific program is threefold: (1) it addresses research questions raised in the innovative projects; (2) it investigates the need for system-innovations and the way in which they can be realized; (3) it designs research projects to test the 5 main working hypotheses of the program. the scientific program is organised in four themes following a cyclic innovation process which is constantly monitored. the cycle starts with people’s preferences and images, followed by studies on which inventions are required to achieve a successful innovation. subsequently, it is investigated how to organize new innovations and transitions and finally, how citizen/consumers behaviour and preferences mobilizes sustainable development, closing the loop.
in this paper, we addressed the named entity recognition (ner) problem for morphologically rich languages by employing a semi-supervised learning approach based on neural networks. we adopted a fast unsupervised method for learning continuous vector representations of words, and used these representations along with language independent features to develop a ner system. we evaluated our system for the highly inflectional turkish and czech languages. we improved the state-of-the-art f-score obtained for turkish without using gazetteers by 2.26% and for czech by 1.53%. unlike the previous state-of-the-art systems developed for these languages, our system does not make use of any language dependent features. therefore, we believe it can easily be applied to other morphologically rich languages. in this paper, we present our effort to consolidate and push further the named entity recognition (ner) research for the czech language. the research in czech is based upon a non-standard basis. some systems are constructed to provide hierarchical outputs whereas the rests give flat entities. direct comparison among these system is therefore impossible. our first goal is to tackle this issue. we build our own ner system based upon conditional random fields (crf) model. it is constructed to output either flat or hierarchical named entities thus enabling an evaluation with all the known systems for czech language. we show a 3.5 – 11% absolute performance increase when compared to previously published results. as a last step we put our system in the context of the research for other languages. we show results for english, spanish and dutch corpora. we can conclude that our system provides solid results when compared to the foreign state of the art.
background there is emerging evidence that adjuvant treatments for breast cancer negatively impact cardiorespiratory fitness (crf) or vo2max, a key predictor of cardiovascular risk. although a number of studies have measured crf in breast cancer patients, there is currently limited data regarding expected crf values in this patient population. given that crf is a poor prognostic sign and recently highlighted as a key measure to standardize by the american heart association, we sought to review the available literature on crf among breast cancer patients. methods and results we identified 27 clinical trials and observational studies measuring vo2max in the pre– and post–adjuvant treatment setting for breast cancer. we compared vo2max before to vo2max after adjuvant therapy and compared vo2max in female breast cancer patients with vo2max in healthy controls. conclusions we found that crf was substantially lower in women with a history of breast cancer compared with healthy women and this was most pronounced among breast cancer patients in the post‐adjuvant setting. we conclude that knowledge of normative crf values is critical to tailor appropriately timed exercise interventions in breast cancer patients susceptible to low crf and subsequent cardiovascular risk. doxorubicin-induced cardiotoxicity was used as a model to prospectively investigate neuroendocrine changes during the development of left ventricular dysfunction. radionuclide ventriculography, frequency domain analysis of heart rate variability (hrv), and plasma noradrenaline and natriuretic peptide measurements were performed in 27 adult lymphoma patients at baseline and after cumulative doxorubicin doses of 200, 400 and 500 mg/m(2). the left ventricular ejection fraction (lvef) decreased from 58.1+/-1.4% to 50.3+/-1.1% (p<0.001) and 49.3+/-1.7% (p<0.001) after cumulative doxorubicin doses of 400 and 500 mg/m(2) respectively. with a doxorubicin dose of up to 400 mg/m(2) there was an increase in sympathetic tone, characterized by a decrease in the normalized high-frequency (hf(nu)) power (p=0.011), and increases in the normalized low-frequency (lf(nu)) power (p=0.011), the lf/hf ratio (p=0.021) and the plasma noradrenaline concentration (p=0.034). the decrease in lvef was correlated with the changes in lf(nu) and hf(nu) power (r=0.540, p=0.012) and lf/hf ratio (r=-0.452, p=0.04). however, after the cumulative doxorubicin dose of 500 mg/m(2) the changes in hrv components and plasma noradrenaline levels returned towards baseline. this was accompanied by increased concentrations of plasma atrial natriuretic peptide (p=0.004) and brain natriuretic peptide (p=0.021). our findings suggest that doxorubicin-induced left ventricular dysfunction is associated with an early change in sympathovagal balance towards sympathetic predominance. along with further progression of left ventricular dysfunction, there is an attenuation of sympathetic tone, which may be attributable to sympatho-adrenal inhibition by increased secretion of natriuretic peptides.
myoendothelial gap junctional signaling mediates pulmonary arterial endothelial cell (paec)-induced activation of latent tgf-β and differentiation of cocultured pulmonary arterial smooth muscle cells (pasmcs), but the nature of the signal passing from paecs to pasmcs through the gap junctions is unknown. because paecs but not pasmcs synthesize serotonin, and serotonin can pass through gap junctions, we hypothesized that the monoamine is the intercellular signal. we aimed to determine whether paec-derived serotonin mediates paec-induced myoendothelial gap junction-dependent activation of tgf-β signaling and differentiation of pasmcs. rat paecs and pasmcs were monocultured or cocultured with (touch) or without (no-touch) direct cell-cell contact. in all cases, tryptophan hydroxylase 1 (tph1) transcripts were expressed predominantly in paecs. serotonin was detected by immunostaining in both paecs and pasmcs in paec/pasmc touch coculture but was not found in pasmcs in either paec/pasmc no-touch coculture or in pasmc/pasmc touch coculture. furthermore, inhibition of gap junctions but not of the serotonin transporter in paec/pasmc touch coculture prevented serotonin transfer from paecs to pasmcs. inhibition of serotonin synthesis pharmacologically or by small interfering rnas to tph1 in paecs inhibited the paec-induced activation of tgf-β signaling and differentiation of pasmcs. we concluded that serotonin synthesized by paecs is transferred through myoendothelial gap junctions into pasmcs, where it activates tgf-β signaling and induces a more differentiated phenotype. this finding suggests a novel role of gap junction-mediated intercellular serotonin signaling in regulation of pasmc phenotype. myoendothelial gap junctions are involved in regulating systemic arterial smooth muscle cell phenotype and function, but their role in the regulation of pulmonary arterial smooth muscle cell (pasmc) phenotype is unknown. we therefore investigated in cocultured pulmonary arterial endothelial cells (paecs) and pasmcs whether myoendothelial gap junctional signaling played a role in paec-dependent regulation of pasmc phenotype. rat paecs and pasmcs were cocultured on opposite sides of a porous transwell membrane that permitted formation of heterotypic cell-cell contacts. immunostaining showed expression of the gap junctional protein connexin 43 (cx43) on projections extending into the membrane from both cell types. dye transfer exhibited functional gap junctional communication from paecs to pasmcs. pasmcs cocultured with paecs had a more contractile-like phenotype (spindle shape and increased expression of the contractile proteins myosin heavy chain, h1-calponin, and α-smooth muscle cell-actin) than pasmcs cocultured with pasmcs or cocultured without direct contact with paecs. transforming growth factor (tgf)-β1 signaling was activated in pasmcs cocultured with paecs, and the pasmc differentiation was inhibited by tgf-β type i receptor blockade. inhibition of gap junctional communication pharmacologically or by knock down of cx43 in paecs blocked tgf-β signaling and pasmc differentiation. these results implicate myoendothelial gap junctions as a gateway for paec-derived signals required for maintaining tgf-β-dependent pasmc differentiation. this study identifies an alternative pathway to paracrine signaling to convey regulatory signals from paecs to pasmcs and raises the possibility that dysregulation of this direct interaction is involved in the pathogenesis of hypertensive pulmonary vascular remodeling.
in this paper, we propose a novel approach based on a single convolutional neural network (cnn) for age estimation. in our proposed network architecture, we first model the randomness of aging with the gaussian distribution which is used to calculate the gaussian integral of an age interval. then, we present a soft softmax regression function used in the network. the new function applies the aging modeling to compute the function loss. compared with the traditional softmax function, the new function considers not only the chronological age but also the interval nearby true age. moreover, owing to the complex of gaussian integral in soft softmax function, a look up table is built to accelerate this process. all the integrals of age values are calculated offline in advance. we evaluate our method on two public datasets: morph ii and cross-age celebrity dataset (cacd), and experimental results have shown that the proposed method has gained superior performances compared to the state of the art. !, model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. it is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. the problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. we argue that a model should only be able to deform in ways characteristic of the class of objects it represents. we describe a method for building models by learning patterns of variability from a training set of correctly annotated images. these models can be used for image search in an iterative refinement algorithm analogous to that employed by active contour models (snakes). the key difference is that our active shape models can only deform to fit the data in ways consistent with the training set. we show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. q 199s a&& prrss, in.
abstract african easterly waves (aews) are identified in numerical model analyses using an objective technique based on the 700-hpa streamfunction field. this method has been developed to (i) reduce the amount of manual data interpretation, (ii) reduce the likelihood of unrelated phenomena being identified as aews, and (iii) facilitate completely objective comparisons between aews with different structures on multiple scales, in order to describe their variability. results show this method performs well when compared to methods of aew identification used in previous studies. the objective technique is used to analyze all aews that originated over tropical north africa during july–september (jas) 2004. results indicate that the “average” aew in this period bears a close resemblance to composite structures from previous research. however, there is marked variability in the characteristics and ultimate fate of aews. most aews of jas 2004 are first identified east of the greenwich meridian and develop as they... abstract the existence of african easterly waves (aews) north of the african easterly jet (aej) core with maximum amplitude at low levels has been confirmed and clarified using radiosonde data and the u.k. meteorological office global model analysis from the hurricane season of 1995. at bamako (12.5°n, 8.0°w) the aews were characterized mainly by maximum amplitudes at the level of the aej (around 700 mb), whereas at dakar (14.7°n, 17.5°w) the waves were characterized by maxima between 850 and 950 mb. the low-level waves to the north of the aej arise in association with baroclinic interactions between the negative meridional potential vorticity (pv) gradients in the jet core and the positive low-level gradient of potential temperature, θ, enhanced by the presence of low-static-stability air north of the aej. these waves follow the positive meridional θ gradients over northern africa in contrast to the jet-level aews that follow the meridional pv gradients at the level of the aej. cross-correlation analysis...
backgroundpatients in intensive care units receive many drugs simultaneously but through limited venous accesses. several intravenous therapies have to be administered through the same catheter, thus increasing the risk of physicochemical incompatibility. the purpose of this work was to assess and to quantify the impact of physical incompatibility on the mass flow rates of drugs infused simultaneously to the patient, through an in vitro study.methodsfurosemide-midazolam incompatibility was used to assess the impact of physical incompatibility on drug mass flow rates. furosemide, midazolam, and saline were simultaneously infused. a filter was added at the end of the infusion line to retain visible particles. two infusion conditions were tested with and without visible particles. a partial least square method on uv spectra was used to determine simultaneously the concentrations of the two drugs at the egress of the terminal extension line. the drug mass flow rate (expressed as mg/h) was calculated as the product of drug concentration versus total flow rate. observed/theoretical mass flow rate ratios for each drug (%) were determined per infusion condition.resultseven in the absence of visible particles, precipitation of furosemide led to a drug loss estimated at between 10% and 15%. furosemide is more impacted by interaction because the ph of the mixture is acid and this form is poorly soluble in an aqueous solution.conclusionsphysical incompatibility between furosemide and midazolam leads to a significant reduction in drug delivered to the patient and may result in treatment failure. background: multiaccess infusion sets allow multiple simultaneous infusions but may induce interference in drug delivery resulting from large variations in the delivery rate of potent drugs. in this study, we sought to understand the influence of multiaccess infusion device properties (dead space volume and antireflux valve [arv]) on drug delivery during multi-infusion therapy. methods: infusion sets differing in length, dead space volume, and presence of an arv were assessed. three drugs were infused simultaneously through different access points, and their concentrations were obtained using uv spectrophotometric analysis of the effluent. different infusion configurations were compared by assessing (1) the amount of drug delivered to the patient per unit of time, (2) the mean amount of drug delivered to the patient per unit of time during the steady-state infusion (mass flow rate plateau), and (3) flow change efficiency calculated from the ratio of the area under the experimental instant mass flow rate curve to the area corresponding to theoretical instant mass flow rate curve. results: infusion sets with lower dead space volumes offered significantly higher flow change efficiency (53.0% ± 15.4% with a dead space volume equal to 0.046 ml 5 min after the start of infusion) than infusion sets with higher dead space volume (5.6% ± 8.2% with a dead space volume equal to 6.16 ml), whatever the flow rate changes. even in case of large dead space volumes, the presence of an arv significantly increased the mass flow rate plateau (from 92.4% to 99.3% of the theoretical plateau without and with the presence of an arv, respectively). conclusions: multi-infusion therapy induces perturbation in drug delivery. these perturbations (lag time, backflow, and bolus) could be reduced by using infusion sets including very low dead space volume and an arv.
cug-bp, elav-like family member 1 (celf1) is a highly conserved rna binding protein that regulates pre-mrna alternative splicing, polyadenylation, mrna stability, and translation. in the heart, celf1 is expressed in the myocardium, where its levels are tightly regulated during development. celf1 levels peak in the heart during embryogenesis, and aberrant up-regulation of celf1 in the adult heart has been implicated in cardiac pathogenesis in myotonic dystrophy type 1, as well as in diabetic cardiomyopathy. either inhibition of celf activity or over-expression of celf1 in heart muscle causes cardiomyopathy in transgenic mice. nonetheless, many of the cardiac targets of celf1 regulation remain unknown. in this study, to identify cardiac targets of celf1 we performed cross-linking immunoprecipitation (clip) for celf1 from embryonic day 8 chicken hearts. we identified a previously unannotated exon in myh7b as a novel target of celf1-mediated regulation. we demonstrated that knockdown of celf1 in primary chicken embryonic cardiomyocytes leads to increased inclusion of this exon and decreased myh7b levels. we also investigated global changes in the transcriptome of primary embryonic cardiomyocytes following celf1 knockdown in a published rna-seq dataset. pathway and network analyses identified strong associations between celf1 and regulation of cell cycle and translation. important regulatory proteins, including both rna binding proteins and a cardiac transcription factor, were affected by loss of celf1. together, these data suggest that celf1 is a key regulator of cardiomyocyte gene expression. microsatellite expansions cause a number of dominantly-inherited neurological diseases. expansions in coding-regions cause protein gain-of-function effects, while non-coding expansions produce toxic rnas that alter rna splicing activities of mbnl and celf proteins. bi-directional expression of the spinocerebellar ataxia type 8 (sca8) ctg cag expansion produces cug expansion rnas (cugexp) from the atxn8os gene and a nearly pure polyglutamine expansion protein encoded by atxn8 cagexp transcripts expressed in the opposite direction. here, we present three lines of evidence that rna gain-of-function plays a significant role in sca8: 1) cugexp transcripts accumulate as ribonuclear inclusions that co-localize with mbnl1 in selected neurons in the brain; 2) loss of mbnl1 enhances motor deficits in sca8 mice; 3) sca8 cugexp transcripts trigger splicing changes and increased expression of the cugbp1-mbnl1 regulated cns target, gaba-a transporter 4 (gat4/gabt4). in vivo optical imaging studies in sca8 mice confirm that gabt4 upregulation is associated with the predicted loss of gabaergic inhibition within the granular cell layer. these data demonstrate that cugexp transcripts dysregulate mbnl/celf regulated pathways in the brain and provide mechanistic insight into the cns effects of other cugexp disorders. moreover, our demonstration that relatively short cugexp transcripts cause rna gain-of-function effects and the growing number of antisense transcripts recently reported in mammalian genomes suggest unrecognized toxic rnas contribute to the pathophysiology of polyglutamine cag ctg disorders.
purposea subset of patients treated for lyme disease report persistent or recurrent symptoms of unknown etiology named post-treatment lyme disease syndrome (ptlds). this study aims to describe a cohort of participants with early, untreated lyme disease, and characterize post-treatment symptomatology and functional impact of ptlds over time.methodssixty-three participants with erythema migrans and systemic symptoms were enrolled in a prospective cohort study. participants underwent physical exams and clinical assessments, and completed the sf-36 (daily life functioning) and the beck depression inventory, second edition (bdi-ii) (depression), at each of five visits over a period of 6 months.resultssigns of lyme disease disappeared post-treatment; however, new-onset patient-reported symptoms increased or plateaued over time. at 6 months, 36% of patients reported new-onset fatigue, 20% widespread pain, and 45% neurocognitive difficulties. however, less than 10% reported greater than “minimal” depression across the entire period. those with ptlds (36%) did not differ significantly from those without with respect to demographics, pre-treatment sf-36, and bdi-ii scores. statistically significant differences were found over time on the role physical, vitality, social functioning, role emotional, and mental health subscales (with a trend toward significance for the remaining three subscales of physical functioning, bodily pain, and general health) of the sf-36 between those with an eventual ptlds diagnosis and those without when measured at 6 months.conclusionsunlike clinical signs of lyme disease, new-onset symptoms are reported by a subset of participants without evidence of depressive symptomatology. patients who developed ptlds had significantly lower life functioning compared to those without ptlds. we propose future avenues for researching infection-triggered symptoms resulting from multiple mechanisms. evidence-based guidelines for the management of patients with lyme disease, human granulocytic anaplasmosis (formerly known as human granulocytic ehrlichiosis), and babesiosis were prepared by an expert panel of the infectious diseases society of america. these updated guidelines replace the previous treatment guidelines published in 2000 (clin infect dis 2000; 31[suppl 1]:1-14). the guidelines are intended for use by health care providers who care for patients who either have these infections or may be at risk for them. for each of these ixodes tickborne infections, information is provided about prevention, epidemiology, clinical manifestations, diagnosis, and treatment. tables list the doses and durations of antimicrobial therapy recommended for treatment and prevention of lyme disease and provide a partial list of therapies to be avoided. a definition of post-lyme disease syndrome is proposed.
absorption of monoclonal antibodies (mabs) after s.c. injection results from the interplay among several kinetic processes. the aims of this study were to investigate the absorption mechanisms of rituximab in rats by using slow s.c. infusion and coadministration with nonspecific igg or hyaluronidase, and to evaluate the predictive performance of the pharmacokinetic model previously developed to describe the nonlinear absorption behavior of mabs. rituximab serum concentrations were measured after s.c. coadministration with nonspecific igg and hyaluronidase to rats. several dose levels and different injection sites were evaluated. for the back site, 6.5- and 2.6-fold decreases in the area under the concentration-time curve were obtained after coadministration with igg for 1 and 10 mg/kg doses compared with administration of rituximab alone. for the abdomen, only a minor reduction in concentrations was observed. hyaluronidase increased the rate of s.c. absorption and the bioavailability (1.9- and 1.6-fold for the back and the abdomen injection of 10 mg/kg). our previously established pharmacokinetic model provided excellent predictions of the effect of nonspecific igg on rituximab absorption. in conclusion, the magnitude of the effect of absorption modifiers is dependent on the site of injection and the dose level of rituximab. pharmacokinetic profiles further support the hypothesis that neonatal fc receptor–mediated transport is a major determinant of s.c. absorption of mabs. the neonatal fc receptor (fcrn) plays an important and well-known role in immunoglobulin g (igg) catabolism; however, its role in the disposition of igg after subcutaneous (sc) administration, including bioavailability, is relatively unknown. to examine the potential effect of fcrn on igg sc bioavailability, we engineered three anti-amyloid β monoclonal antibody (mab) reverse chimeric mouse igg2a (migg2a) fc variants (i253a.h435a, n434h and n434y) with different binding affinities to mouse fcrn (mfcrn) and compared their sc bioavailability to that of the wild-type (wt) mab in mice. our results indicated that the sc bioavailability of migg2a was affected by mfcrn-binding affinity. variant i253a.h435a, which did not bind to mfcrn at either ph 6.0 or ph 7.4, had the lowest bioavailability (41.8%). variant n434y, which had the greatest increase in binding affinity at both ph 6.0 and ph 7.4, had comparable bioavailability to the wt antibody (86.1% vs. 76.3%), whereas variant n434h, which had modestly increased binding affinity at ph 6.0 to mfcrn and affinity comparable to the wt antibody at ph 7.4, had the highest bioavailability (94.7%). a semi-mechanism-based pharmacokinetic model, which described well the observed data with the wt antibody and variant i253a.h435a, is consistent with the hypothesis that the decreased bioavailability of variant i253a.h435a was due to loss of the fcrn-mediated protection from catabolism at the absorption site. together, these data demonstrate that fcrn plays an important role in sc bioavailability of therapeutic igg antibodies.
identifying similar diseases could potentially provide deeper understanding of their underlying causes, and may even hint at possible treatments. for this purpose, it is necessary to have a similarity measure that reflects the underpinning molecular interactions and biological pathways. we have thus devised a network-based measure that can partially fulfill this goal. our method assigns weights to all proteins (and consequently their encoding genes) by using information flow from a disease to the protein interaction network and back. similarity between two diseases is then defined as the cosine of the angle between their corresponding weight vectors. the proposed method also provides a way to suggest disease-pathway associations by using the weights assigned to the genes to perform enrichment analysis for each disease. by calculating pairwise similarities between 2534 diseases, we show that our disease similarity measure is strongly correlated with the probability of finding the diseases in the same disease family and, more importantly, sharing biological pathways. we have also compared our results to those of mimminer, a text-mining method that assigns pairwise similarity scores to diseases. we find the results of the two methods to be complementary. it is also shown that clustering diseases based on their similarities and performing enrichment analysis for the cluster centers significantly increases the term association rate, suggesting that the cluster centers are better representatives for biological pathways than the diseases themselves. this lends support to the view that our similarity measure is a good indicator of relatedness of biological processes involved in causing the diseases. although not needed for understanding this paper, the raw results are available for download for further study at ftp://ftp.ncbi.nlm.nih.gov/pub/qmbpmn/diseaserelations/. in our previous publication, a framework for information flow in interaction networks based on random walks with damping was formulated with two fundamental modes: emitting and absorbing. while many other network analysis methods based on random walks or equivalent notions have been developed before and after our earlier work, one can show that they can all be mapped to one of the two modes. in addition to these two fundamental modes, a major strength of our earlier formalism was its accommodation of context-specific directed information flow that yielded plausible and meaningful biological interpretation of protein functions and pathways. however, the directed flow from origins to destinations was induced via a potential function that was heuristic. here, with a theoretically sound approach called the channel mode, we extend our earlier work for directed information flow. this is achieved by constructing a potential function facilitating a purely probabilistic interpretation of the channel mode. for each network node, the channel mode combines the solutions of emitting and absorbing modes in the same context, producing what we call a channel tensor. the entries of the channel tensor at each node can be interpreted as the amount of flow passing through that node from an origin to a destination. similarly to our earlier model, the channel mode encompasses damping as a free parameter that controls the locality of information flow. through examples involving the yeast pheromone response pathway, we illustrate the versatility and stability of our new framework.
the impacts of exotic plants on the pollination and reproductive success of natives have been widely reported; however, in spite of its importance for the invasive process, the role of native plants in the pollination and reproduction of exotic plants has been less explored. to fill this gap, we compared the patterns of pollination and reproductive success in the invasive herb echium vulgare (boraginaceae) between monospecific patches (only e. vulgare) and mixed patches (sympatry with native herbs schizanthus hookeri and stachys albicaulis) in central chile. using sample quadrats of 1 m × 2 m, we quantified the richness, diversity and visitation rate of flower visitors in 15-min observation intervals. we conducted an assay to assess the effect of the patch types (monospecific and mixed) and the isolation of flowers to visitors on both the fruit set and seed/ovule ratio. we showed that native plants favoured the richness of visitors of e. vulgare; however, they did not lead to increases in visitation rate. the reproductive success of e. vulgare did not show differences between contrasted patches; however, the isolation of visitors decreased the fruit set, although seed production was maintained in the absence of pollinators, presumably by an autogamous mechanism. complementary to our main research focus, we assessed changes in pollination variables and reproductive output in two coflowering native plants that occur with e. vulgare, s. hookeri and s. albicaulis. despite the fact that our correlational study did not allow us to dissect the effects of mixed patches and relative plant abundances on variables measured for natives, we observed an increase in pollinator richness in mixed patches for the two plants studied. these results suggest a potential facilitation for visitor richness of the exotic plant in coexistence with native plants, although this facilitation does not result in changes in the visit rate or on the reproductive success of any of the studied species. this work underlines the need for additional research on community levels that assess reciprocal effects on pollination between coflowering natives and exotics. aims in ecology and conservation biology, the number of species counted in a biodiversity study is a key metric but is usually a biased underestimate of total species richness because many rare species are not detected. moreover, comparing species richness among sites or samples is a statistical challenge because the observed number of species is sensitive to the number of individuals counted or the area sampled. for individual-based data, we treat a single, empirical sample of species abundances from an investigator-defined species assemblage or community as a reference point for two estimation objectives under two sampling models: estimating the expected number of species (and its unconditional variance) in a random sample of (i) a smaller number of individuals (multinomial model) or a smaller area sampled (poisson model) and (ii) a larger number of individuals or a larger area sampled. for sample-based incidence (presence–absence) data, under a bernoulli product model, we treat a single set of species incidence frequencies as the reference point to estimate richness for smaller and larger numbers of sampling units. methods the first objective is a problem in interpolation that we address with classical rarefaction (multinomial model) and coleman rarefaction (poisson model) for individual-based data and with sample-based rarefaction (bernoulli product model) for incidence frequencies. the second is a problem in extrapolation that we address with sampling-theoretic predictors for the number of species in a larger sample (multinomial model), a larger area (poisson model) or a larger number of sampling units (bernoulli product model), based on an estimate of asymptotic species richness. although published methods exist for many of these objectives, we bring them together here with some new estimators under a unified statistical and notational framework. this novel integration of mathematically distinct approaches allowed us to link interpolated (rarefaction) curves and extrapolated curves to plot a unified species accumulation curve for empirical examples. we provide new, unconditional variance estimators for classical, individual-based rarefaction and for coleman rarefaction, long missing from the toolkit of biodiversity measurement. we illustrate these methods with datasets for tropical beetles, tropical trees and tropical ants.
five studies tested the hypothesis that self-regulatory failure is an important predictor of intimate partner violence (ipv) perpetration. study 1 participants were far more likely to experience a violent impulse during conflictual interaction with their romantic partner than they were to enact a violent behavior, suggesting that self-regulatory processes help individuals refrain from perpetrating ipv when they experience a violent impulse. study 2 participants high in dispositional self-control were less likely to perpetrate ipv, in both cross-sectional and residualized-lagged analyses, than were participants low in dispositional self-control. study 3 participants verbalized more ipv-related cognitions if they responded immediately to partner provocations than if they responded after a 10-s delay. study 4 participants whose self-regulatory resources were experimentally depleted were more violent in response to partner provocation (but not when unprovoked) than were nondepleted participants. finally, study 5 participants whose self-regulatory resources were experimentally bolstered via a 2-week training regimen exhibited less violent inclinations than did participants whose self-regulatory resources had not been bolstered. these findings hint at the power of incorporating self-regulation dynamics into predictive models of ipv perpetration. aggressive impulses arise from many factors, but they are usually held in check by social norms for self-control. thus, the proximal cause of aggression is often failure of self-restraint. in five studies, depleted capacity for self-regulation (caused by prior, even irrelevant acts of self-regulation) increased aggressive responding, especially after an insulting provocation. when participants were insulted and their self-regulatory strength was depleted (i.e., after completing previous tasks that required self-regulation), participants were more likely to aggress. when the urge to aggress was relatively weaker (i.e., when participants were not insulted), self-regulatory depletion did not increase aggressive behavior. this effect was moderated by trait self-control: participants low in trait self-control were particularly likely to express intentions of behaving aggressively in response to provocation, whereas participants high in trait self-control did not express intentions of responding aggressively. laboratory, autobiographical memory, and hypothetical responses confirmed the pattern.
although the transition to menopause represents a period of risk for depressive symptoms, there is little research into personality or trait-like factors that may confer vulnerability to depression during the transition to menopause. this study investigated whether the personality trait of self-criticism moderated the effects of irritability on depressive symptoms in women transitioning to menopause and whether these effects were mediated by lower levels of emotional regulation. participants were 376 women, of whom 157 had entered the transition phase to menopause. these women in the transition phase completed measures of self-criticism, irritable mood, emotional regulation, and depressive symptoms. all analyses controlled for attitudes toward menopause and somatic symptoms. moderated mediation regression analyses showed that higher levels of irritability were associated with poorer emotional regulation in highly self-critical women, but not in less self-critical women, and poorer emotional regulation was, in turn, related to higher levels depressive symptoms. findings suggest that the transition to menopause may represent an especially vulnerable period for women with high levels of self-criticism. although irritability is transitory for most women, for women who are highly self-critical, irritability may tax their ability to self-regulate and lead to more encompassing symptoms of depression. a select group of investigators attended a structured workshop, the stages of reproductive aging workshop (straw), at park city, utah, usa, in july 2001, which addressed the need in women for a staging system as well as the confusing nomenclature for the reproductive years.
introductiondelirium is a frequent complication after cardiac surgery. although various risk factors for postoperative delirium have been identified, the relationship between nocturnal breathing disorders and delirium has not yet been elucidated. this study evaluated the relationship between sleep-disordered breathing (sdb) and postoperative delirium in cardiac surgery patients without a previous diagnosis of obstructive sleep apnea.methodsin this prospective cohort study, 92 patients undergoing elective cardiac surgery with extracorporeal circulation were evaluated for both sdb and postoperative delirium. polygraphic recordings were used to calculate the apnea-hypopnea index (ahi; mean number of apneas and hypopneas per hour recorded) of all patients preoperatively. delirium was assessed during the first four postoperative days using the confusion assessment method. clinical differences between individuals with and without postoperative delirium were determined with univariate analysis. the relationship between postoperative delirium and those covariates that were associated with delirium in univariate analysis was determined by a multivariate logistic regression model.resultsthe median overall preoperative ahi was 18.3 (interquartile range, 8.7 to 32.8). delirium was diagnosed in 44 patients. the median ahi differed significantly between patients with and without postoperative delirium (28 versus 13; p = 0.001). a preoperative ahi of 19 or higher was associated with an almost sixfold increased risk of postoperative delirium (odds ratio, 6.4; 95% confidence interval, 2.6 to 15.4; p <0.001). multivariate logistic regression analysis showed that preoperative ahi, age, smoking, and blood transfusion were independently associated with postoperative delirium.conclusionspreoperative sdb (for example, undiagnosed obstructive sleep apnea) were strongly associated with postoperative delirium, and may be a risk factor for postoperative delirium. background and objective:  osa is a common condition associated with cardiovascular (cv) morbidity. it remains underdiagnosed globally in part due to the limited availability and technical requirements of polysomnography (psg). the aim of this study was to test the accuracy of two simple methods for diagnosing osa.
backgroundrna viruses rapidly accumulate genetic variation, which can give rise to synthetic lethal (sl) and deleterious (sd) mutations. synthetic lethal mutations (non-lethal when alone but lethal when combined in one genome) have been studied to develop cancer therapies. this principle can also be used against fast-evolving rna-viruses. indeed, targeting protein sites involved in sd + sl interactions with a drug would render any mutation of such sites, lethal.resultshere, we set up a strategy to detect intragenic pairs of sl and sd at the surface of the protein to predict less escapable drug target sites. for this, we detected sd + sl, studying hiv protease (pr) and reverse transcriptase (rt) sequence alignments from two groups of vih+ individuals: treated with drugs (t) or not (nt). using a series of statistical approaches, we were able to propose bona fide sd + sl couples. when focusing on spatially close co-variant sd + sl couples at the surface of the protein, we found 5 sd + sl groups (2 in the protease and 3 in the reverse transcriptase), which could be good candidates to form pockets to accommodate potential drugs.conclusionsthus, designing drugs targeting these specific sd + sl groups would not allow the virus to mutate any residue involved in such groups without losing an essential function. moreover, we also show that the selection pressure induced by the treatment leads to the appearance of new mutations, which change the mutational landscape of the protein. this drives the existence of differential sd + sl couples between the drug-treated and non-treated groups. thus, new anti-viral drugs should be designed differently to target such groups.reviewersthis article was reviewed by neil greenspan csaba pal and istván simon. l-735,524 is a potent, orally bioavailable inhibitor of human immunodeficiency virus (hiv) protease currently in a phase ii clinical trial. we report here the three-dimensional structure of l-735,524 complexed to hiv-2 protease at 1.9-a resolution, as well as the structure of the native hiv-2 protease at 2.5-a resolution. the structure of hiv-2 protease is found to be essentially identical to that of hiv-1 protease. in the crystal lattice of the hiv-2 protease complexed with l-735,524, the inhibitor is chelated to the active site of the homodimeric enzyme in one orientation. this feature allows an unambiguous assignment of protein-ligand interactions from the electron density map. both fourier and difference fourier maps reveal clearly the closure of the flap domains of the protease upon l-735,524 binding. specific interactions between the enzyme and the inhibitor include the hydroxy group of the hydroxyaminopentane amide moiety of l-735,524 ligating to the carboxyl groups of the essential asp-25 and asp-25' enzymic residues and the amide oxygens of the inhibitor hydrogen bonding to the backbone amide nitrogen of ile-50 and ile-50' via an intervening water molecule. a second bridging water molecule is found between the amide nitrogen n2 of l-735,524 and the carboxyl oxygen of asp-29'. although other hydrogen bonds also add to binding, an equally significant contribution to affinity arises from hydrophobic interactions between the protease and the inhibitor throughout the pseudo-symmetric s1/s1', s2/s2', and s3/s3' regions of the enzyme. except for its pyridine ring, all lipophilic moieties (t-butyl, indanyl, benzyl, and piperidyl) of l-735,524 are rigidly defined in the active site.
a two-stage pretreatment approach, employing steam followed by organosolv treatment, was assessed for its ability to fractionate and recover most of the hemicellulose, lignin and cellulose components of poplar wood chips. a mild steaming stage was initially used to maximise hemicellulose sugar recovery, with 63% of the original xylan solubilised and recovered after this stage and close to 90% recovered in total. rather than hindering subsequent organosolv delignification, the prior steam treatment enhanced lignin solubilisation with more than 66% of the original lignin removed after the two-stage pretreatment. the extracted lignin contained at least equal or greater amounts of functional groups as compared to the lignin solubilised after a single-stage organosolv pretreatment. more than 98% of the original cellulose was recovered after the two-stage pretreatment and 88% of the cellulose could be hydrolysed to glucose at enzyme loading of 5fpu/g cellulose after 72h. an organosolv process involving extraction with hot aqueous ethanol has been evaluated for bioconversion of hybrid poplar to ethanol. the process resulted in fractionation of poplar chips into a cellulose‐rich solids fraction, an ethanol organosolv lignin (eol) fraction, and a water‐soluble fraction containing hemicellulosic sugars, sugar breakdown products, degraded lignin, and other components. the influence of four independent process variables (temperature, time, catalyst dose, and ethanol concentration) on product yields was analyzed over a broad range using a small composite design and response surface methodology. center point conditions for the composite design (180°c, 60 min, 1.25% h2so4, and 60% ethanol), yielded a solids fraction containing ∼88% of the cellulose present in the untreated poplar. approximately 82% of the total cellulose in the untreated poplar was recovered as monomeric glucose after hydrolysis of the solids fraction for 24 h using a low enzyme loading (20 filter paper units of cellulase/g cellulose); ∼85% was recovered after 48 h hydrolysis. total recovery of xylose (soluble and insoluble) was equivalent to ∼72% of the xylose present in untreated wood. approximately 74% of the lignin in untreated wood was recovered as eol. other cooking conditions resulted in either similar or inferior product yields although the distribution of components between the various fractions differed markedly. data analysis generated regression models that describe process responses for any combination of the four variables. © 2006 wiley periodicals, inc.
this paper seeks to fill a gap in the literature by analyzing inflation in poland, one of only two transition economies that have adopted a strict inflation-targeting policy. the paper also introduces a new method for selecting inflation indicators. consistent with the earlier literature, empirical results find a strong link between the producer price index and consumer price index in poland. this shows the importance of the manufacturing sector in determining the price level in the country. overall, wages, broad money supply and the exchange rate are good indicators of inflation. the modified yule-walker technique of arma spectral estimation is shown to be a special case of the instrumental variable method of system identification. several recursive instrumental variable algorithms are proposed for adaptive spectral estimation. an efficient lattice algorithm is presented for solving the modified yule-walker equations in the overdetermined case.
introduction: our aim in this study was to examine whether the muscle fiber type proportions in different muscles from the same individual are interrelated. methods: samples were excised from five skeletal muscles in each of 12 human autopsy cases, and the fiber type proportions were determined by immunohistochemistry. we further examined the intermuscular relationship in fiber type proportion by reanalyzing three previously published data sets involving other muscles. results: subjects demonstrated a predominantly high or low proportion of type 1 fibers in all examined muscles, and the overall difference between individuals was statistically significant (p < 0.001). accordingly, the type 1 fiber proportions in most muscles were positively correlated (median r = 0.42, range −0.03–0.80). similar results were also obtained from the three reanalyzed data sets. conclusions: we suggest the existence of an across‐muscle phenotype with respect to fiber type proportions; some individuals display generally faster muscles and some individuals slower muscles when compared with others. muscle nerve, 2012 biopsies of ventral neck muscles (sternocleidomastoid, omohyoid, and longus colli) and dorsal neck muscles (rectus capitis posterior major, obliquus capitis inferior, splenius capitis, and trapezius) were taken from 64 patients who underwent spondylodesis for cervical dysfunction of different etiologies. the muscle fibers were classified histochemically as type i, iia, iib, or iic (transitional or intermediate fibers) according to the ph lability of their myofibrillar atpase. signs of muscle fiber transformations were observed in all muscles investigated, as evidenced by an increased relative amount of type‐iic fibers. the transformations occurred independently of (a) the type of muscle (i.e., more “postural” or more “phasic”), (b) the sex and age of the patient, (c) the type of condition, and (d) the presence of additional neurological deficits. thus, the same pattern of muscular reaction was found in patients with rheumatoid arthritis as in patients with soft‐tissue injuries of the neck (e.g., “whiplash injury”). in the ventral muscles and the obliquus capitis inferior, the occurrence of transformations correlated strongly with the duration of symptoms; in the ventral muscles the vast majority of transformations were encountered in patients with a shorter history of symptoms, whereas in the obliquus capitis inferior the reverse occurred. in the other dorsal muscles, no correlation with the duration of symptoms was found. muscles in which transformations had ceased displayed, on average, a significantly higher percentage of fast type‐iib fibers than were found in muscles with ongoing transformations. this strongly indicates that the transformations proceeded in the direction from “slow oxidative” to “fast glycolytic”.
in the present work we investigate how the state of credit markets affects the impact of fiscal policies. we estimate a threshold vector autoregression (tvar) model on u.s quarterly data for the period 1984-2010. we employ the spread between baarated corporate bond yield and 10-year treasury constant maturity rate as a proxy for credit conditions. we find that the response of output to fiscal policy shocks is stronger and more persistent when the economy is in the “tight” credit regime. fiscal multipliers are significantly different in the two regimes: they are abundantly and persistently higher than one when firms face increasing financing costs, whereas they are feebler and often lower than one in the “normal” credit regime. the results appear to be robust to different model specifications, fiscal foresight, alternative threshold variables, different measure of variables and sample periods. jel codes: j32, e32, e44, e62 the problem of testing for linearity and the number of regimes in the context of self-exciting threshold autoregressive (setar) models is reviewed. we describe least-squares methods of estimation and inference. the primary complication is that the testing problem is non-standard, due to the presence of parameters which are only defined under the alternative, so the asymptotic distribution of the test statistics is non-standard. simulation methods to calculate asymptotic and bootstrap distributions are presented. as the sampling distributions are quite sensitive to conditional heteroskedasticity in the error, careful modeling of the conditional variance is necessary for accurate inference on the conditional mean. we illustrate these methods with two applications--annual sunspot means and monthly u.s. industrial production. we find that annual sunspots and monthly industrial production are setar(2) processes. copyright 1999 by blackwell publishers ltd
callogenesis, somatic embryogenesis, and regeneration were obtained from tissues of unfertilized ovaries of sweet orange (citrus sinensis osbeck.) cv. tobias. the influence of two modified basal media, woody plant medium (wpm) and n6 medium, to induce callus formation from pistils was determined. overall, high frequencies of callogenesis were observed when either medium was used. however, initial culture of explants in wpm medium followed by transfer of callus to n6 medium resulted in higher frequency of callus induction (of 2.30 callus per explant that were larger than 0.5 cm in size), and of subsequent development of embryogenic callus (10%). a total of 125 somatic embryos were obtained. after 6 months of culture, 72% of somatic embryos germinated into plantlets. these plantlets were subsequently micrografted in vitro, and then acclimatized. ploidy of these plants were determined using flow cytometry and traps molecular markers were used to confirm their maternal origin. an improvement of the protocol for haploid induction through anther culture of citrus clementina hort. ex tan. cv. nules was achieved following the evaluation of a number of the factors affecting androgenesis. the influence of thidiazuron (tdz) and three temperature pre-treatments (4°c, 25°c, 32°c) on the floral buds with respect to anther culture of c. clementina hort. ex tan., cv. nules was investigated. an increased embryoid production was induced in the medium supplemented with tdz. pre-treatment temperatures of 4°c and 25°c were more favorable for embryo production than 32°c. regeneration of androgenic haploid plantlets from cv. sra 63 of c. clementina is reported here for the first time.
mangroves are traditionally considered to provide important nutrition to tropical estuarine consumers. however, there is still controversy about this, and the extent and importance of these inputs are largely unquantified. in particular, there is no information for food webs of small estuaries that dominate wet–dry tropical coasts, where freshwater inflow is intermittent, leading to highly seasonal inputs of nutrients from terrestrial systems. since the relative importance of the different sources depends on the type and extent of different habitats and on hydrological and topographic conditions, results from other regions/type of systems cannot be extrapolated to these estuaries. here, δ13c is used to determine the importance of mangrove-derived carbon for penaeus merguiensis (detritivore; shrimp), ambassis vachellii (planktivore; fish), and leiognathus equulus (benthivore; fish) from six small wet–dry tropical estuaries that differ in mangrove (c3) cover and in type of terrestrial vegetation adjacent to the estuary. bayesian mixing models confirmed that mangrove material was important to consumers in all estuaries. there was a gradient in this importance that agreed with the extent of mangrove forests in the estuaries, as c3 sources were the most important contributors to animals from the three estuaries with the greatest (>40 %) mangrove cover. there was also evidence of incorporation of c3 material for the three estuaries with lower (<30 %) mangrove cover. since these latter estuaries had no adjacent terrestrial c3 forests, the detected c3 influence can only be of mangrove origin. this shows that mangroves are important contributors to these food webs, underlining the importance of mangroves in supporting estuarine nursery ground value and fisheries productivity. background stable isotope analysis is increasingly being utilised across broad areas of ecology and biology. key to much of this work is the use of mixing models to estimate the proportion of sources contributing to a mixture such as in diet estimation. methodology by accurately reflecting natural variation and uncertainty to generate robust probability estimates of source proportions, the application of bayesian methods to stable isotope mixing models promises to enable researchers to address an array of new questions, and approach current questions with greater insight and honesty. conclusions we outline a framework that builds on recently published bayesian isotopic mixing models and present a new open source r package, siar. the formulation in r will allow for continued and rapid development of this core model into an all-encompassing single analysis suite for stable isotope research.
abstract in this paper we address the problem of optimizing the time window controller (tw-controller). this controller was first introduced in 2001 as a supervising mechanism for distributed scheduling of multiclass queuing networks with the objective of stabilizing those networks. it was then also shown that the tw-controller possesses the ability to improve performance of stable networks. we revise the controller and present a series of formal results concerning its main properties and features. then, we propose to use simulated annealing on a simulation-based optimization approach and present numerical results that demonstrate the controller's ability to improve performance over any given scheduling policy. introduction to discrete event systems is a comprehensive introduction to the field of discrete event systems, offering a breadth of coverage that makes the material accessible to readers of varied backgrounds. the book emphasizes a unified modeling framework that transcends specific application areas, linking the following topics in a coherent manner: language and automata theory, supervisory control, petri net theory, markov chains and queuing theory, discrete-event simulation, and concurrent estimation techniques. this edition includes recent research results pertaining to the diagnosis of discrete event systems, decentralized supervisory control, and interval-based timed automata and hybrid automata models.
unlabelled the purpose of the present study was to investigate whether the link that has been established between stuttering and linguistic stress in adolescents and adults (the so-called stress effect) can also be observed in childhood stuttering. to account for confounding variables, both within-word position and grammatical class were measured, because these factors covary with linguistic stress. speech samples of 22 preschool children (mean time of 9 months since onset of stuttering) were analyzed. the relative stress of each syllable was rated and syllables were categorized into long and short stressed, unstressed, and intermediately stressed syllables. results showed that 97.8% of stuttering events occurred on first syllables of words and 76.5% on the first sound of syllables, that means a clear word-initial effect. stuttering frequency on first syllables of function words was 16.9% and significantly higher than the frequency of stuttered first syllables of content words (11.5%). in function words short stressed syllables and intermediately stressed syllables were stuttered more often than unstressed syllables. the analysis for individual disfluency types revealed that, for function words, stuttering on short stressed syllables was associated with prolongations and syllable repetitions. however, in intermediately stressed syllables stuttering coincided most often with one-syllable word repetitions. this differentiation of the stress effect may suggest different causal mechanisms underlying these disfluency types.   educational objectives the reader will learn about and be able to: (1) describe how within-word position, grammatical class, and linguistic stress effect stuttering frequency in preschool children who stutter; (2) explain how the occurrence of individual disfluency types depends on linguistic stress; (3) discuss how patterns of adults and preschool children who stutter differ in regard to these aspects. thirteen invited papers from a two-day discussion session held in september 1999 are collected in this issue of philosophical transactions of the royal society. all the papers have been revised and edited, and the discussion following the presentation of each paper has been transcribed and appended. in addition, the editors have contributed a paper-length introduction. the contents are as follows:
planar cell polarity (pcp) is a ubiquitous property of animal tissues and is essential for morphogenesis and homeostasis. in most cases, this fundamental property is governed by a deeply conserved set of ‘core pcp’ proteins, which includes the transmembrane proteins van gogh-like (vangl) and frizzled (fzd), as well as the cytoplasmic effectors prickle (pk) and dishevelled (dvl). asymmetric localization of these proteins is thought to be central to their function, and understanding the dynamics of these proteins is an important challenge in developmental biology. among the processes that are organized by the core pcp proteins is the directional beating of cilia, such as those in the vertebrate node, airway and brain. here, we exploit the live imaging capabilities of xenopus to chart the progressive asymmetric localization of fluorescent reporters of dvl1, pk2 and vangl1 in a planar polarized ciliated epithelium. using this system, we also characterize the influence of pk2 on the asymmetric dynamics of vangl1 at the cell cortex, and we define regions of pk2 that control its own localization and those impacting vangl1. finally, our data reveal a striking uncoupling of vangl1 and dvl1 asymmetry. this study advances our understanding of conserved pcp protein functions and also establishes a rapid, tractable platform to facilitate future in vivo studies of vertebrate pcp protein dynamics. summary: live imaging in xenopus reveals that pk2, a cytoplasmic effector of the pcp pathway, controls the directional ciliary beating in multiciliated cells by regulating vangl1 dynamics at the cell cortex. planar polarity decisions in the wing of drosophila involve the assembly of asymmetric protein complexes containing the conserved receptor frizzled. in this study, we analyse the role of the van gogh/strabismus gene in the formation of these complexes and cell polarisation. we find that the strabismus protein becomes asymmetrically localised to the proximal edge of cells. in the absence of strabismus activity, the planar polarity proteins dishevelled and prickle are mislocalised in the cell. we show that strabismus binds directly to dishevelled and prickle and is able to recruit them to membranes. furthermore, we demonstrate that the putative pdz-binding motif at the c terminus of strabismus is not required for its function. we propose a two-step model for assembly of frizzledcontaining asymmetric protein complexes at cell boundaries. first, strabismus acts together with frizzled and the atypical cadherin flamingo to mediate apicolateral recruitment of planar polarity proteins including dishevelled and prickle. in the second phase, dishevelled and prickle are required for these proteins to become asymmetrically distributed on the proximodistal axis.
the regular monitoring of physical fitness and sport-specific performance is important in elite sports to increase the likelihood of success in competition. this study aimed to systematically review and to critically appraise the methodological quality, validation data, and feasibility of the sport-specific performance assessment in olympic combat sports like amateur boxing, fencing, judo, karate, taekwondo, and wrestling. a systematic search was conducted in the electronic databases pubmed, google-scholar, and science-direct up to october 2017. studies in combat sports were included that reported validation data (e.g., reliability, validity, sensitivity) of sport-specific tests. overall, 39 studies were eligible for inclusion in this review. the majority of studies (74%) contained sample sizes <30 subjects. nearly, 1/3 of the reviewed studies lacked a sufficient description (e.g., anthropometrics, age, expertise level) of the included participants. seventy-two percent of studies did not sufficiently report inclusion/exclusion criteria of their participants. in 62% of the included studies, the description and/or inclusion of a familiarization session (s) was either incomplete or not existent. sixty-percent of studies did not report any details about the stability of testing conditions. approximately half of the studies examined reliability measures of the included sport-specific tests (intraclass correlation coefficient [icc] = 0.43–1.00). content validity was addressed in all included studies, criterion validity (only the concurrent aspect of it) in approximately half of the studies with correlation coefficients ranging from r = −0.41 to 0.90. construct validity was reported in 31% of the included studies and predictive validity in only one. test sensitivity was addressed in 13% of the included studies. the majority of studies (64%) ignored and/or provided incomplete information on test feasibility and methodological limitations of the sport-specific test. in 28% of the included studies, insufficient information or a complete lack of information was provided in the respective field of the test application. several methodological gaps exist in studies that used sport-specific performance tests in olympic combat sports. additional research should adopt more rigorous validation procedures in the application and description of sport-specific performance tests in olympic combat sports. performance testing is one of the most common and important measures used in sports science and physiology. performance tests allow for a controlled simulation of sports and exercise performance for research or applied science purposes. there are three factors that contribute to a good performance test: (i) validity; (ii) reliability; and (iii) sensitivity. a valid protocol is one that resembles the performance that is being simulated as closely as possible. when investigating race-type events, the two most common protocols are time to exhaustion and time trials. time trials have greater validity than time to exhaustion because they provide a good physiological simulation of actual performance and correlate with actual performance. sports such as soccer are more difficult to simulate. while shuttle-running protocols such as the loughborough intermittent shuttle test may simulate physiology of soccer using time to exhaustion or distance covered, it is not a valid measure of soccer performance. there is a need to include measures of skill in such protocols. reliability is the variation of a protocol. research has shown that time-to-exhaustion protocols have a coefficient of variation (cv) of >10%, whereas time trials are more reliable as they have been shown to have a cv of <5%. a sensitive protocol is one that is able to detect small, but important, changes in performance. the difference between finishing first and second in a sporting event is <1%. therefore, it is important to be able to detect small changes with performance protocols. a quantitative value of sensitivity may be accomplished through the signal : noise ratio, where the signal is the percentage improvement in performance and the noise is the cv.
a variety of nervous system components such as medulla, pons, midbrain, cerebellum, basal ganglia, parietal, frontal and occipital lobes have role in eye movement desensitization and reprocessing (emdr) processes. the eye movement is done simultaneously for attracting client's attention to an external stimulus while concentrating on a certain internal subject. eye movement guided by therapist is the most common attention stimulus. the role of eye movement has been documented previously in relation with cognitive processing mechanisms. a series of systemic experiments have shown that the eyes’ spontaneous movement is associated with emotional and cognitive changes and results in decreased excitement, flexibility in attention, memory processing, and enhanced semantic recalling. eye movement also decreases the memory's image clarity and the accompanying excitement. by using emdr, we can reach some parts of memory which were inaccessible before and also emotionally intolerable. various researches emphasize on the effectiveness of emdr in treating and curing phobias, pains, and dependent personality disorders. consequently, due to the involvement of multiple neural system components, this palliative method of treatment can also help to rehabilitate the neuro-cognitive system. the effects of saccadic bilateral (horizontal) eye movements on memory for a visual event narrative were investigated. in the study phase, participants were exposed to a set of pictures accompanied by a verbal commentary describing the events depicted in the pictures. next, the participants were asked either misleading or control questions about the depicted event and were then asked to engage in 30s of bilateral vs. vertical vs. no eye movements. finally, recognition memory was tested using the remember-know procedure. it was found that bilateral eye movements increased true memory for the event, increased recollection, and decreased the magnitude of the misinformation effect. the findings are discussed in terms of source monitoring, dual-process theories of memory and the potential neural foundations of such effects.
in this work we analyze the distribution of the number of edges spanned by a single set and between two disjoint sets of vertices in the random regular graph model gn,d. we show it to be very similar to that of the binomial random graph model, g(n, p) with p = d n . as a direct consequence of our analysis, we show that the second eigenvalue of a d-regular graph where d = o( √ n) is w.h.p. at most o( √ d log d) by applying a recent result of bilu and linial [5]. next, using our results on the distribution of edges spanned by a single set of vertices, we show that for every fixed > 0 and d = o(n1/5), the chromatic number of gn,d is concentrated in two consecutive values with probability at least 1− for large enough values of n. we prove that for every constant δ>0 the chromatic number of the random graphg(n, p) withp=n−1/2−δ is asymptotically almost surely concentrated in two consecutive values. this implies that for any β<1/2 and any integer valued functionr(n)≤o(nβ) there exists a functionp(n) such that the chromatic number ofg(n,p(n)) is preciselyr(n) asymptotically almost surely.
developing seeds are expected to be strongly defended against microbial attack. in keeping with this, only 26% of seeds of centaurea stoebe from its native and invaded ranges in eurasia and north america were infected with fungi, and 92.2% of those were infected with a single fungus per seed. even when developing seeds in flower heads were inoculated under conducive conditions for infection with 14 of these seed-infecting fungi, re-isolation of inoculants was only 16% overall, and again limited to the particular inoculant. environmental fungi (i.e. those not isolated from seed of c. stoebe) were present in control flower heads under conditions conducive to infection but they were never re-isolated from fully developed seeds in any experiments. when two or three seed isolates were co-inoculated to compete in flower heads, only one inoculant, and always the same one, was re-isolated from all matured seeds, regardless of maternal plant genotype. pcr-based detection methods confirmed that these fungal interactions were exclusionary rather than suppressive. in these strongly defended, developing seeds, we had expected the plant to control not only the overall level of infection but also the outcome of co-inoculations. consequences for the next plant generation of this exclusionary competition among seed-infecting fungi included effects on seedling emergence, growth and fecundity. fungal endophytes are important in plant ecology and common in plants. we attempted to test cointroduction and host-jumping hypotheses on a community basis by comparing endophytes isolated from invasive spotted knapweed (centaurea stoebe, asteraceae) in its native and invaded ranges. of 92 combined, sequence-based haplotypes representing eight classes of fungi, 78 occurred in only one of the two ranges. in the native range of c. stoebe, one haplotype of alternaria alternata was clearly dominant, whereas in the invaded range, no haplotype was dominant. many haplotypes were closely related to one another and novel. for example, six putative, new species of botrytis were discovered as endophytes of c. stoebe, which has never been reported to have botrytis spp.. apparent differences between the two communities of endophytes were significant according to an analysis of similarity, but phylogenetic community structure did not differ significantly between the ranges. both host-jumping and cointroduction of fungal endophytes likely took place during the spotted knapweed invasion.
brain-derived neurotrophic factor (bdnf), via activation of trkb receptors, mediates vital physiological functions in the brain, ranging from neuronal survival to synaptic plasticity, and has been implicated in the pathophysiology of neurodegenerative disorders. although transcriptional regulation of the bdnf gene (bdnf) has been extensively studied, much remains to be understood. we discovered a sequence within bdnf promoter 4 that binds the basic helix-loop-helix protein bhlhb2 and is a target for bhlhb2-mediated transcriptional repression. nmda receptor activation de-repressed promoter 4-mediated transcription and correlated with reduced occupancy of the promoter by bhlhb2 in cultured hippocampal neurons. bhlhb2 gene −/− mice showed increased hippocampal exon 4-specific bdnf mrna levels compared with +/+ littermates under basal and activity-dependent conditions. bhlhb2 knock-out mice also showed increased status epilepticus susceptibility, suggesting that bhlhb2 alters neuronal excitability. together, these results support a role for bhlhb2 as a new modulator of bdnf transcription and neuronal excitability. drugs of abuse cause activation of the cyclic amp response element binding protein (creb) in the nucleus accumbens (nac). expression of active creb in rat nac medium spiny neurons (msns) increased their excitability, whereas dominant-negative creb had the opposite effect. decreasing excitability of nac msns in vivo by overexpression of potassium channels enhanced locomotor responses to cocaine, suggesting that the increased nac msn excitability caused by creb helped to limit behavioral sensitivity to cocaine.
objectivethe plan of information on acute respiratory infections in catalonia (pidirac) included the surveillance of severe hospitalized cases of laboratory-confirmed influenza (shclci) in 2009. the objective of this study was to determine the clinical, epidemiological and virological features of shclci recorded in 12 sentinel hospitals during five influenza seasons.resultsfrom a sample of shclci recorded during the 5 influenza epidemics seasons from 2010–2011 to 2014–2015, cases were confirmed by pcr and/or viral isolation in cell cultures from respiratory samples. a total of 1400 shclci were recorded, 33% required icu admission and 12% died. the median age of cases was 61 years (range 0–101 years); 70.5% were unvaccinated; 80.4% received antiviral treatment (in 79.6 and 24% of cases within 48 h after hospital admission and the onset of symptoms, respectively); influenza virus a [37.9% a (h1n1)pdm09, 29.3% a (h3n2)] was identified in 87.7% of cases. surveillance of shclci provides an estimate of the severity of seasonal influenza epidemics and the identification and characterization of at-risk groups in order to facilitate preventive measures such as vaccination and early antiviral treatment. background the global burden of disease attributable to seasonal influenza virus in children is unknown. we aimed to estimate the global incidence of and mortality from lower respiratory infections associated with influenza in children younger than 5 years.   methods we estimated the incidence of influenza episodes, influenza-associated acute lower respiratory infections (alri), and influenza-associated severe alri in children younger than 5 years, stratified by age, with data from a systematic review of studies published between jan 1, 1995, and oct 31, 2010, and 16 unpublished population-based studies. we applied these incidence estimates to global population estimates for 2008 to calculate estimates for that year. we estimated possible bounds for influenza-associated alri mortality by combining incidence estimates with case fatality ratios from hospital-based reports and identifying studies with population-based data for influenza seasonality and monthly alri mortality.   findings we identified 43 suitable studies, with data for around 8 million children. we estimated that, in 2008, 90 million (95% ci 49-162 million) new cases of influenza (data from nine studies), 20 million (13-32 million) cases of influenza-associated alri (13% of all cases of paediatric alri; data from six studies), and 1 million (1-2 million) cases of influenza-associated severe alri (7% of cases of all severe paediatric alri; data from 39 studies) occurred worldwide in children younger than 5 years. we estimated there were 28,000-111,500 deaths in children younger than 5 years attributable to influenza-associated alri in 2008, with 99% of these deaths occurring in developing countries. incidence and mortality varied substantially from year to year in any one setting.   interpretation influenza is a common pathogen identified in children with alri and results in a substantial burden on health services worldwide. sufficient data to precisely estimate the role of influenza in childhood mortality from alri are not available.   funding who; bill & melinda gates foundation.
habitat-based surrogates are a low cost alternative to intensive biodiversity surveys, though they have been poorly investigated in semi-arid ecosystem compared to others such as temperate woodlands. in this study we tested potential habitat-based surrogates of invertebrate richness in a semi-arid rangeland in northwest australia. potential surrogates were: distance from artificial watering-point; soil hardness; habitat complexity; and individual complexity components. generalised additive models (gams) were used to relate abundance and richness of selected invertebrates with environmental factors and cluster analysis was used to examine similarity in species composition. the most frequently selected factor was soil hardness, but taxa varied as to whether biodiversity was higher in soft or hard soils. where distance from watering-point was an important predictor, there were generally higher abundances and richness closer to watering-points than further away. abundance and species richness could be partially explained using individual complexity components, but relationships were weak and there were no consistent trends among taxa. therefore, although habitat complexity has been correlated with species richness under some circumstances, our results cast doubt on the generality of this relationship. there are also dangers in assuming that all taxa respond in a manner similar to indicator taxa, as we observed that different taxa had higher richness at opposite extremes of some environmental gradients. grazing may have a negative impact on biodiversity in some environments, but in regions where water is limiting, the net effect may be positive due to the creation of waterholes. a procedure for the implementation of quality control for laboratorysorting and identification of invertebrate specimens collected in biodiversityresearch is described. the procedure is based on process control sampling, aconcept of statistical process control (spc) used widely in the manufacturingand information technology industries, and adapted to suit the tasks andproducts of biodiversity sorting procedures. the major advantages of processcontrol over other quality control mechanisms are that it is more stringent, andcontinuous. hence, errors are detected and corrected as they occur, avoidingproliferation in the data set. the procedure is also highly interactive,offering the technicians the opportunity to learn as they work. protocols havebeen developed while sorting material collected as part of a study into theimpacts associated with invasion of a habitat (coastal heath) by an exotic weed(bitou bush – chrysanthemoides monilifera) on thecentral coast of new south wales, australia. major findings from the analysis ofmaterial processed include: that errors may have a variety of causes andsubsequent implications for data quality, levels of identification errors can besignificant even at higher taxonomic levels (e.g. sorting insects to order),initial training periods on their own are insufficient to ensure errorminimisation, and even with stringent protocols the ratio of technician tospecialist effort can be maintained at a level of around 5:1. the need forincorporating effective quality control procedures into invertebratebiodiversity data compilations is emphasised.
this study examined whether symptoms (motor, cognitive, vision, sleepiness, depression) of parkinson’s disease (pd) were associated with restricted driving practices. to quantify driving practices, electronic devices were installed in the vehicles of 27 drivers with pd (78 % men; m = 71.6, sd = 6.6; unified parkinson’s disease rating scale (updrs) motor score m = 30.1, sd = 8.6; disease duration m = 3.9, sd = 2.8 years) and 20 controls (80 % men; m = 70.6, sd = 7.9) for 2 weeks. participants completed measures of sleepiness, depression, quality of life, and assessments of motor, cognitive and visual functions. the pd group had significantly slower brake response times (p < 0.05), poorer cognitive and quality of life scores (p < 0.01) and greater depression (p < 0.05) compared to controls. slower reaction time was significantly related to reduced driving; specifically, fewer trips (r = −0.46; p < 0.05), distance (r = −0.54, p < 0.01) and duration at night (r = −0.58, p < 0.01). better cognitive scores were associated with driving less often in difficult situations such as bad weather and rush hour (p < 0.05), as well as reduced speed on city streets, but only for the control group. while most drivers with pd rated their overall health as good or excellent, the five pd drivers who rated their health more poorly had significantly worse clinical symptoms (updrs motor scores, contrast sensitivity, depression, brake response time) and more restricted driving patterns. these findings show that drivers with pd who perceive their health poorly have greater symptomatology and were more likely to restrict their driving, possibly due to noticeable declines in multiple driving-related abilities. cognitive impairment is common in parkinson's disease (pd) and can occur early in the disease course. no effective screening test exists for detection of early or mild cognitive impairment in pd. we examined the montreal cognitive assessment (moca) as a screening tool for cognitive dysfunction in pd. the test–retest intraclass correlation coefficient was 0.79 and the interrater intraclass correlation coefficient was 0.81. the correlation coefficient between the moca and a neuropsychologic battery was 0.72. the moca is reliable and valid in the pd population and warrants further study as a screening tool for cognitive dysfunction. © 2008 movement disorder society
climate change can impact the pattern of marine biodiversity through changes in species’ distributions. however, global studies on climate change impacts on ocean biodiversity have not been performed so far. our paper aims to investigate the global patterns of such impacts by projecting the distributional ranges of a sample of 1066 exploited marine fish and invertebrates for 2050 using a newly developed dynamic bioclimate envelope model. our projections show that climate change may lead to numerous local extinction in the sub-polar regions, the tropics and semi-enclosed seas. simultaneously, species invasion is projected to be most intense in the arctic and the southern ocean. together, they result in dramatic species turnovers of over 60% of the present biodiversity, implying ecological disturbances that potentially disrupt ecosystem services. our projections can be viewed as a set of hypothesis for future analytical and empirical studies. global climate change is recognized as an important determining factor for the future distributions of marine organisms, notably fishes and invertebrates. shifting of distribution range may affect global marine fisheries and have large socio-economic implications. however, globalscale evaluation of the impact of climate change on marine species is lacking. in this paper, we develop a dynamic bioclimate envelope model to predict the effect of climate change on the distributions of marine species with emphasis on commercially exploited fishes and invertebrates. first, the model infers, for various species, bioclimate envelopes based on their current distribution. bioclimate envelopes are defined by sea water temperature, bathymetry, habitats and distance from sea ice. secondly, the model predicts the shifting of the bioclimate envelopes induced by changes in climate variables. simultaneously, following the shifting of the bioclimate envelopes, the model simulates movement of relative abundance through changes in population growth, mortality, larval dispersal and adult movement. we test the model with several commercially exploited fish species with widely different biogeography. the model provides reasonable and robust predictions of future distribution ranges of the four species under different scenarios of sea water warming. moreover, the predictions are robust to major model assumptions and parameter uncertainty. using realistic climate change predictions from the noaa/gfdl coupled model, this model will be used to evaluate impacts of climate change on global marine fisheries. introduction there is ample evidence from empirical observations and climate models indicating that mean global temperatures have been increasing over the last 100 years (ipcc 2007). global temperature has increased by over 0.6 oc since 1900 and it may continue to increase at a rate of around 0.2 oc per decade (ipcc 2007). biological responses to this change have been observed in both terrestrial and marine biomes (murawski 1993; hughes 2000; mccarty 2001; parmesan & yohe 2003; perry et al. 2005; hobday et al. 2006). the responses include changes in physiology (e.g. productivity), geographic range and phenology at population, species, community and ecosystem levels (hughes 2000; mccarty 2001). for instance, nearly two-thirds of marine fishes in the north sea shifted in mean latitude or depth or both over 25 years as sea temperature increased (perry et al. 2005). during the last century, annual growth rates for the juveniles of eight long-lived fish species in the southwest pacific increased in shallow waters and decreased in deep waters where ocean warming and cooling occurred, respectively (thresher et al 2007). this agrees with the quantitative model of fish physiology, which predicts increasing growth performance and fecundity in higher latitude and the converse in lower latitude as sea 1 cited as: cheung, w.w.l., lam, v.w.y., pauly, d. 2008. dynamic bioclimate envelope model to predict climate-induced changes in distribution of marine fishes and invertebrates, p. 5-50. in: cheung, w.w.l, lam, v.w.y., pauly, d. (eds.) modelling present and climate-shifted distribution of marine fishes and invertebrates. fisheries centre research report 16(3). fisheries centre, university of british columbia [issn 1198-6727].
backgroundaccurate and efficient rna secondary structure prediction remains an important open problem in computational molecular biology. historically, advances in computing technology have enabled faster and more accurate rna secondary structure predictions. previous parallelized prediction programs achieved significant improvements in runtime, but their implementations were not portable from niche high-performance computers or easily accessible to most rna researchers. with the increasing prevalence of multi-core desktop machines, a new parallel prediction program is needed to take full advantage of today’s computing technology.findingswe present here the first implementation of rna secondary structure prediction by thermodynamic optimization for modern multi-core computers. we show that gtfold predicts secondary structure in less time than unafold and rnafold, without sacrificing accuracy, on machines with four or more cores.conclusionsgtfold supports advances in rna structural biology by reducing the timescales for secondary structure prediction. the difference will be particularly valuable to researchers working with lengthy rna sequences, such as rna viral genomes. a dynamic programming algorithm for prediction of rna secondary structure has been revised to accommodate folding constraints determined by chemical modification and to include free energy increments for coaxial stacking of helices when they are either adjacent or separated by a single mismatch. furthermore, free energy parameters are revised to account for recent experimental results for terminal mismatches and hairpin, bulge, internal, and multibranch loops. to demonstrate the applicability of this method, in vivo modification was performed on 5s rrna in both escherichia coli and candida albicans with 1-cyclohexyl-3-(2-morpholinoethyl) carbodiimide metho-p-toluene sulfonate, dimethyl sulfate, and kethoxal. the percentage of known base pairs in the predicted structure increased from 26.3% to 86.8% for the e. coli sequence by using modification constraints. for c. albicans, the accuracy remained 87.5% both with and without modification data. on average, for these sequences and a set of 14 sequences with known secondary structure and chemical modification data taken from the literature, accuracy improves from 67% to 76%. this enhancement primarily reflects improvement for three sequences that are predicted with <40% accuracy on the basis of energetics alone. for these sequences, inclusion of chemical modification constraints improves the average accuracy from 28% to 78%. for the 11 sequences with <6% pseudoknotted base pairs, structures predicted with constraints from chemical modification contain on average 84% of known canonical base pairs.
the 5′ untranslated regions (utr) of chloroplast mrnas often contain regulatory sequences that control rna stability and/or translation. the petd chloroplast mrna in chlamydomonas reinhardtii has three such essential regulatory elements in its 362-nt long 5′ utr. to further analyze these elements, we compared 5′ utr sequences from four chlamydomonas species (c. reinhardtii, c. incerta, c. moewusii and c. eugametos) and five independent strains of c. reinhardtii. overall, these petd 5′ utrs have relatively low sequence conservation across these species. in contrast, sequences of the three regulatory elements and their relative positions appear partially conserved. functionality of the 5′ utrs was tested in c. reinhardtii chloroplasts using β-glucuronidase reporter genes, and the nearly identical c. incerta petd functioned for mrna stability and translation in c. reinhardtii chloroplasts while the more divergent c. eugametos petd did not. this identified what may be key features in these elements. we conclude that these petd regulatory elements, and possibly the corresponding trans-acting factors, function via mechanisms highly specific and surprisingly sensitive to minor sequence changes. this provides a new and broader perspective of these important regulatory sequences that affect photosynthesis in these algae. in the green unicellular alga chlamydomonas eugametos, cellular division is readily synchronized by light/dark cycles. under these conditions, light initiates photosynthetic growth in daughter cells and begins the g1 phase. genes whose expression is regulated upon illumination are likely to be important mechanisms controlling cell proliferation. to identify some of those genes, two cdna libraries were prepared with poly(a)+ extracted from cells either stimulated with light for 1 h or held in darkness (quiescent cells) during the same period. to restrict our analysis to those genes that are part of the primary response, cells were incubated in presence of cycloheximide. differential screening of approximately 40 000 clones in each library revealed 44 clones which hybridize preferentially with a [32p] cdna probe derived from rna of light-stimulated cells and 15 clones which react selectively with a [32p] cdna probe synthesized from poly(a)+ rna of quiescent cells. cross-hybridization of these clones identified 4 independent sequences in the light-induced (li) collection and 2 in the uninduced (lr) library. four of these cdnas correspond to mrnas that are positively or negatively regulated upon activation of photosynthesis. one clone represents a mrna that accumulates transitorily at both transitions. finally, li818 cdna identifies a new chlorophyll a/b-binding (cab) gene family whose mrna accumulation is controlled by light and a circadian oscillator. the endogenous timing system controls li818 mrna accumulation so that it precedes the onset of illumination by a few hours. on the other hand, light affects li818 mrna levels independently of active photosynthesis.
parkinson's disease (pd) is characterized by a selective degeneration of nigrostriatal dopaminergic pathway. epidemiological studies revealed a male predominance of the disease that has been attributed to the female steroid hormones, mainly the estrogen. estrogen neuroprotective effects have been shown in several studies, however the mechanisms responsible by these effects are still unclear. previous data from our group revealed that glial cell line-derived neurotrophic factor (gdnf) is crucial to the dopaminergic protection provided by 17β-estradiol, and also suggest that the intracellular estrogen receptors (ers) are not required for that neuroprotective effects. the present study aimed to investigate the contribution of the g protein-coupled er (gper) activation in estrogen-mediated dopaminergic neuroprotection against an insult induced by 1-methyl-4-phenylpyridinium (mpp(+)), and whether gper neuroprotective effects involve the regulation of gdnf expression. using primary mesencephalic cultures, we found that gper activation protects dopaminergic neurons from mpp(+) toxicity in an extent similar to the promoted by a 17β-estradiol. moreover, gper activation promotes an increase in gdnf levels. both, gdnf antibody neutralization or rna interference-mediated gdnf knockdown prevented the gper-mediated dopaminergic protection verified in mesencephalic cultures challenged with mpp(+). overall, these results revealed that g1, a selective agonist of gper, is able to protect dopaminergic neurons and that gdnf overexpression is a key feature to gper induced the neuroprotective effects. parkinson’s disease (pd) is characterised by the preferential loss of dopaminergic neurones from the substantia nigra (sn) that leads to the hallmark motor disturbances. animal and human studies suggest a beneficial effect of oestrogen to the nigrostriatal system, and the regulation of neurotrophic factor expression by oestrogens has been suggested as a possible mechanism contributing to that neuroprotective effect. the present study was designed to investigate whether the neuroprotection exerted by 17β‐oestradiol on nigrostriatal dopaminergic neurones is mediated through the regulation of glial cell line‐derived neurotrophic factor (gdnf) expression. using an in vivo rat model of pd, we were able to confirm the relevance of 17β‐oestradiol in defending dopaminergic neurones against 6‐hydroxydopamine (6‐ohda) toxicity. 17β‐oestradiol, released by micro‐osmotic pumps, implanted 10 days before intrastriatal 6‐ohda injection, prevented the loss of dopaminergic neurones induced by 6‐ohda. 17β‐oestradiol treatment also promoted an increase in gdnf protein levels both in the sn and striatum. to explore the relevance of gdnf increases to 17β‐oestradiol neuroprotection, we analysed, in sn neurone‐glia cultures, the effect of gdnf antibody neutralisation and rna interference‐mediated gdnf knockdown. the results showed that both gdnf neutralisation and gdnf silencing abolished the dopaminergic protection provided by 17β‐oestradiol against 6‐ohda toxicity. taken together, these results strongly identify gdnf as an important player in 17β‐oestradiol‐mediated dopaminergic neuroprotection.
in mucopolysaccharidosis-i (mps-i), alpha-l-iduronidase deficiency leads to progressive heparan sulfate (hs) and dermatan sulfate (ds) glycosaminoglycan (gag) accumulation. the functional consequences of these accumulated molecules are unknown. hs critically influences tissue morphogenesis by binding to and modulating the activity of several cytokines (eg, fibroblast growth factors [fgfs]) involved in developmental patterning. we recently isolated a multipotent progenitor cell from postnatal human bone marrow, which differentiates into cells of all 3 embryonic lineages. the availability of multipotent progenitor cells from healthy volunteers and patients with mps-i (hurler syndrome) provides a unique opportunity to directly examine the functional effects of abnormal hs on cytokine-mediated stem-cell proliferation and survival. we demonstrate here that abnormally sulfated hs in hurler multipotent progenitor cells perturb critical fgf-2-fgfr1-hs interactions, resulting in defective fgf-2-induced proliferation and survival of hurler multipotent progenitor cells. both the mitogenic and survival-promoting activities of fgf-2 were restored by substitution of hurler hs by normal hs. this perturbation of critical hs-cytokine receptor interactions may represent a mechanism by which accumulated hs contributes to the developmental pathophysiology of hurler syndrome. similar mechanisms may operate in the pathogenesis of other diseases where structurally abnormal gags accumulate. stem cell localization, conservation, and differentiation is believed to occur in niches in the marrow stromal microenvironment. our recent observation that long-term in vitro human hematopoiesis requires a stromal heparan sulfate proteoglycan (hspg) led us to hypothesize that such hspg may orchestrate the formation of the stem cell niche. we compared the structure and function of hs from m2-10b4, a hematopoiesis-supportive cell line, with hs from a nonsupportive cell line, fhs-173-we. long-term culture-initiating cell (ltc-ic) maintenance was enhanced by pg from supportive cells but not by pg from nonsupportive cells (p <.005). the supportive hs were significantly larger and more highly sulfated than the nonsupportive hs. specifically, supportive hs contained higher 6-o-sulfation on the glucosamine residues. in agreement with these observations, purified 6-o-sulfated heparin and highly 6-o-sulfated bovine kidney hs similarly maintained ltc-ic. in contrast, completely desulfated heparin, n-sulfated heparin, and unmodified heparin did not support ltc-ic maintenance. moreover, the supportive hs promoted ltc-ic maintenance but not differentiation of cd34(+)/hla-dr- cells into colony-forming cells (cfcs) and mature blood cells. the supportive hs but not the nonsupportive hs bound both cytokines and matrix components critical for hematopoiesis, including interleukin-3 (il-3), macrophage inflammatory protein-1 (mip-1), and thrombospondin (tsp). significantly more cd34(+) cells adhered directly to immobilized o-sulfated heparin than to n-sulfated or desulfated heparin. thus, hematopoiesis-supportive stromal hspg possessing large, highly 6-o-sulfated hs mediate the juxtaposition of hematopoietic progenitors with stromal cells, specific growth-promoting (il-3) and growth-inhibitory (mip-1 and platelet factor 4 [pf4]) cytokines, and extracellular matrix (ecm) proteins such as tsp. we conclude that the structural specificity of stromal hspg that determines the selective colocalization of cytokines and ecm components leads to the formation of discrete niches, thereby orchestrating the controlled growth and differentiation of stem cells. these findings may have important implications for ex vivo expansion of and gene transfer into primitive hematopoietic progenitors.
we introduce a multi-distance, frequency-domain, near-infrared spectroscopy (nirs) method to measure the optical coefficients of two-layered media and the thickness of the top layer from diffuse reflectance measurements. this method features a direct solution based on diffusion theory and an inversion procedure based on the levenberg-marquardt algorithm. we have validated our method through monte carlo simulations, experiments on tissue-like phantoms, and measurements on the forehead of three human subjects. the monte carlo simulations and phantom measurements have shown that, in ideal two-layered samples, our method accurately recovers the top layer thickness (l), the absorption coefficient (µa) and the reduced scattering coefficient (µ′s) of both layers with deviations that are typically less than 10% for all parameters. our method is aimed at absolute measurements of hemoglobin concentration and saturation in cerebral and extracerebral tissue of adult human subjects, where the top layer (layer 1) represents extracerebral tissue (scalp, skull, dura mater, subarachnoid space, etc.) and the bottom layer (layer 2) represents cerebral tissue. human subject measurements have shown a significantly greater total hemoglobin concentration in cerebral tissue (82±14 µm) with respect to extracerebral tissue (30±7 µm). by contrast, there was no significant difference between the hemoglobin saturation measured in cerebral tissue (56%±10%) and extracerebral tissue (62%±6%). to our knowledge, this is the first time that an inversion procedure in the frequency domain with six unknown parameters with no other prior knowledge is used for the retrieval of the optical coefficients and top layer thickness with high accuracy on two-layered media. our absolute measurements of cerebral hemoglobin concentration and saturation are based on the discrimination of extracerebral and cerebral tissue layers, and they can enhance the impact of nirs for cerebral hemodynamics and oxygenation assessment both in the research arena and clinical practice. we present near-infrared spectroscopy measurement of absolute cerebral hemoglobin concentration and saturation in a large sample of 36 healthy elderly (mean age, 85 ± 6 years) and 19 young adults (mean age, 28 ± 4 years). non-invasive measurements were obtained on the forehead using a commercially available multi-distance frequency-domain system and analyzed using a diffusion theory model for a semi-infinite, homogeneous medium with semi-infinite boundary conditions. our study included repeat measurements, taken five months apart, on 16 elderly volunteers that demonstrate intra-subject reproducibility of the absolute measurements with cross-correlation coefficients of 0.9 for absorption coefficient (μa), oxy-hemoglobin concentration ([hbo2]), and total hemoglobin concentration ([hbt]), 0.7 for deoxy-hemoglobin concentration ([hb]), 0.8 for hemoglobin oxygen saturation (sto2), and 0.7 for reduced scattering coefficient (μ's). we found significant differences between the two age groups. compared to young subjects, elderly subjects had lower cerebral [hbo2], [hb], [hbt], and sto2 by 10 ± 4 μm, 4 ± 3 μm, 14 ± 5 μm, and 6%±5%, respectively. our results demonstrate the reliability and robustness of multi-distance near-infrared spectroscopy measurements based on a homogeneous model in the human forehead on a large sample of human subjects. absolute, non-invasive optical measurements on the brain, such as those presented here, can significantly advance the development of nirs technology as a tool for monitoring resting/basal cerebral perfusion, hemodynamics, oxygenation, and metabolism.
holospora obtusa is a macronucleus-specific endosymbiotic bacterium of the ciliate paramecium caudatum. we report the secretion of a 63-kda periplasmic protein of an infectious form of the bacterium into the macronucleus of its host. indirect immunofluorescence microscopy with five monoclonal antibodies against the 63-kda protein demonstrated that, soon after the bacterial invasion into the host macronucleus, the protein was detected in the infected macronucleus and that levels of the protein increased dramatically within one day of infection. the use of inhibitors for host and bacterial protein synthesis illustrated that, in early infection of h. obtusa, not only the pre-existing but also a newly synthesized 63-kda protein was secreted into the host macronucleus. a partial amino acid sequence of the protein was determined, and a gene encoding the 63-kda protein was cloned. the deduced amino acid sequence shows that this protein is a novel protein. the symbiotic bacterium holospora obtusa infects the macronucleus of the ciliate paramecium caudatum. after ingestion by its host, an infectious form of holospora with an electron-translucent tip passes through the host digestive vacuole and penetrates the macronuclear envelope with this tip. to investigate the underlying molecular mechanism of this process, we raised a monoclonal antibody against the tip-specific 89-kda protein, sequenced this partially, and identified the corresponding complete gene. the deduced protein sequence carries two actin-binding motifs. indirect immunofluorescence microscopy shows that during escape from the host digestive vacuole, the 89-kda proteins translocates from the inside to the outside of the tip. when the bacterium invades the macronucleus, the 89-kda protein is left behind at the entry point of the nuclear envelope. transmission electron microscopy shows the formation of fine fibrous structures that co-localize with the antibody-labeled regions of the bacterium. our findings suggest that the 89-kda protein plays a role in holospora's escape from the host digestive vacuole, the migration through the host cytoplasm, and the invasion into the macronucleus.
omnigraph, a novel representation to support a range of nlp classification tasks, integrates lexical items, syntactic dependencies and frame semantic parses into graphs. feature engineering is folded into the learning through convolution graph kernel learning to explore different extents of the graph. a high-dimensional space of features includes individual nodes to complex networks. in experiments on a text-forecasting problem that predicts stock price change from news for company mentions, omnigraph beats several benchmarks based on bag-of-words, syntactic dependencies, and semantic trees. the highly expressive features omnigraph discovers provide insights into the semantics across distinct market sectors. to demonstrate the method’s generality, we also report its high performance results on a fine-grained sentiment corpus. after presenting a novel o(n3) parsing algorithm for dependency grammar, we develop three contrasting ways to stochasticize it. we propose (a) a lexical affinity model where words struggle to modify each other, (b) a sense tagging model where words fluctuate randomly in their selectional preferences, and (c) a generative model where the speaker fleshes out each word's syntactic and conceptual structure without regard to the implications for the hearer. we also give preliminary empirical results from evaluating the three models' parsing performance on annotated wall street journal training text (derived from the penn treebank). in these results, the generative model performs significantly better than the others, and does about equally well at assigning part-of-speech tags.
many real world optimization problems are dynamic in which the fitness landscape is time dependent and the optima change over time. such problems challenge traditional optimization algorithms. for such problems, optimization algorithms not only have to find the global optimum but also need to closely track its trajectory. in this paper, a new hybrid algorithm integrating a differential evolution (de) and a particle swarm optimization (pso) is proposed for dynamic optimization problems. multi-population strategy is adopted to enhance the diversity and try to keep each subpopulation on a different peak in the fitness landscape. a hybrid operator combining de and pso is designed, in which each individual is sequentially carried out de and pso operations. an exclusion scheme is proposed that integrates the distance based exclusion scheme with the hill-valley function to track the adjacent peaks. the algorithm is applied to the set of benchmark functions used in cec 2009 competition for dynamic environment. experimental results show that it is more effective in terms of overall performance than other comparative algorithms. evolutionary algorithms (eas) are widely used to deal with optimization problems in dynamic environments (de) [3]. when using eas to solve de problems, we are usually interested in the algorithm's ability to adapt and recover from the changes. one of the main problems facing an evolutionary method when solving de problems is the loss of genetic diversity.in this paper, we investigate the use of evolutionary multi-objective optimization methods (emos) for single-objective de problems. for that purpose, we introduce an artificial second objective with the aim to maintain useful diversity in the population. six different artificial objectives are examined and compared.all the results will be compared against a traditional ga and the random immigrants algorithm[4]. nsga2 is employed as the evolutionary multi-objective technique.
1. abstract organizations often use standardized practices as a means to improve knowledge management. we suggest that the use of standardization for km efforts can take on two different forms. in one form, standardization explicates tacit knowledge in order to more effectively transfer knowledge within the organization. in the second form, standardization provides a tool to evaluate and capture knowledge. the type of employee, the impact on the organization and the measurement of system effectiveness are contingent upon the form of standardization employed. this paper summarizes our preliminary findings from a case study exploring an implementation of a standardized project management methodology at a multinational technology services company. if research is like a football game, then the first thing new players can expect to do is to learn some of the rules of the game and then to become skilled in playing the game according to these rules. a well-defined set of rules is a great advantage to novices and to seasoned players. in doing quantitative research, the rules are clear. to researchers trained in these methods, it may therefore come as a surprise to find that there exists a variation of the research game in which there are no fixed rules but only general principles. the position of the goal posts, for example, may be different for different games and may even be moved in the course of a game. some novices may see this as presenting the opportunity for a glorious free-for-all, releasing them from the constraints of the quantitative research game. in the midst of their new-found freedom, they may then find themselves accosted by experienced players who seem to have, after all, a definite set of rules. on being challenged, experienced players may then explain that, while there are only general principles, these are interpreted in a quite specific way depending on the particular context within which the game is being played. 'context' becomes the bugbear for the novice. the novice may even have to learn that, before booting the ball through the goal posts, the player has to take account of where the ball is coming from, where it wants to go and what meaning it, the ball, attaches to the experience of being kicked! freedom readily gives way to frustration and incomprehension. happily, there are some brave researchers who set about the task of making the rules of qualitative research explicit to novices and to experienced players. the three books reviewed here fall into that category. they all take on a different task. the collection of articles brought together in one edition by janice morse is not about the rules but about some exciting games that have been played. together the articles demonstrate not only the pleasures of the qualitative research game, but also its contribution to a fine, detailed understanding of important health prob-
dehydrins (dhns) define a complex group of stress inducible proteins characterized by the presence of one or more lysine-rich motifs. dhns are present in multiple copies in the genome of plant species. although genome-wide analysis of dhns composition and chromosomal distribution has been conducted in herbaceous species, it remains unexplored in woody plants. here, we report on the identification of ten genes encoding eleven putative dhn polypeptides in populus. we document that dhn genes occur as duplicated blocks distributed over seven of the 19 poplar chromosomes likely as a result of segmental and tandem duplication events. based on conserved motifs, poplar dhns were assigned to four subgroups with the kn subgroup being the most frequent. one putative dhn polypeptide (ptrdhn-10) with a sks arrangement could originate from a recombination between skn and kns genes. in silico analysis of microarray data showed that in unstressed poplar, dhn genes are expressed in all vegetative tissues except for mature leaves. this exhaustive survey of dhn genes in poplar provides important information that will assist future studies on their functional role in poplar. the algorithm described in this paper discovers one or more motifs in a collection of dna or protein sequences by using the technique of expectation maximization to fit a two-component finite mixture model to the set of sequences. multiple motifs are found by fitting a mixture model to the data, probabilistically erasing the occurrences of the motif thus found, and repeating the process to find successive motifs. the algorithm requires only a set of unaligned sequences and a number specifying the width of the motifs as input. it returns a model of each motif and a threshold which together can be used as a bayes-optimal classifier for searching for occurrences of the motif in other databases. the algorithm estimates how many times each motif occurs in each sequence in the dataset and outputs an alignment of the occurrences of the motif. the algorithm is capable of discovering several different motifs with differing numbers of occurrences in a single dataset.
we investigate the benefit of combining both cluster assumption and manifold assumption underlying most of the semi-supervised algorithms using the flexibility and the efficiency of multi-kernel learning. the multiple kernel version of transductive svm (a cluster assumption based approach) is proposed and it is solved based on dc (difference of convex functions) programming. promising results on benchmark data sets suggesting the effectiveness of proposed work. multiple kernel learning aims at simultaneously learning a kernel and the associated predictor in supervised learning settings. for the support vector machine, an efficient and general multiple kernel learning (mkl) algorithm, based on semi-infinite linear progamming, has been recently proposed. this approach has opened new perspectives since it makes the mkl approach tractable for large-scale problems, by iteratively using existing support vector machine code. however, it turns out that this iterative algorithm needs numerous iterations for converging towards a reasonable solution. in this paper, we address the mkl problem through an adaptive 2-norm regularization formulation that encourages sparse kernel combinations. apart from learning the combination, we solve a standard svm optimization problem, where the kernel is defined as a linear combination of multiple kernels. we propose an algorithm, named simplemkl, for solving this mkl problem and provide a new insight on mkl algorithms based on mixed-norm regularization by showing that the two approaches are equivalent. furthermore, we show how simplemkl can be applied beyond binary classification, for problems like regression, clustering (one-class classification) or multiclass classification. experimental results show that the proposed algorithm converges rapidly and that its efficiency compares favorably to other mkl algorithms. finally, we illustrate the usefulness of mkl for some regressors based on wavelet kernels and on some model selection problems related to multiclass classification problems. a simplemkl toolbox is available at http://asi.insa-rouen.fr/enseignants/~arakotom/code/mklindex.html 1 ha l-0 02 18 33 8, v er si on 1 26 j an 2 00 8
multiple variants of the amber all-atom force field were quantitatively evaluated with respect to their ability to accurately characterize helix-coil equilibria in explicit solvent simulations. using a global distributed computing network, absolute conformational convergence was achieved for large ensembles of the capped a21 and fs helical peptides. further assessment of these amber variants was conducted via simulations of a flexible 164-residue five-helix-bundle protein, apolipophorin-iii, on the 100 ns timescale. of the contemporary potentials that had not been assessed previously, the amber-99sb force field showed significant helix-destabilizing tendencies, with beta bridge formation occurring in helical peptides, and unfolding of apolipophorin-iii occurring on the tens of nanoseconds timescale. the amber-03 force field, while showing adequate helical propensities for both peptides and stabilizing apolipophorin-iii, (i) predicts an unexpected decrease in helicity with ala→arg+ substitution, (ii) lacks experimentally observed 310 helical content, and (iii) deviates strongly from average apolipophorin-iii nmr structural properties. as is observed for amber-99sb, amber-03 significantly overweighs the contribution of extended and polyproline backbone configurations to the conformational equilibrium. in contrast, the amber-99φ force field, which was previously shown to best reproduce experimental measurements of the helix-coil transition in model helical peptides, adequately stabilizes apolipophorin-iii and yields both an average gyration radius and polar solvent exposed surface area that are in excellent agreement with the nmr ensemble. we study atomic models of the thermodynamics of the structural transition of peptides that form α-helices. the effect of sequence variation on α-helix formation for alanine-rich peptides, ac-ala21- methyl amide (a21) and ac-a5 (aaara)3a-methyl amide (fs peptide), is investigated by atomic simulation studies of the thermodynamics of the helix-coil transition in explicit water. the simulations show that the guanidinium group in the arg side chains in the fs peptide interacts with the carbonyl group four amino acids upstream in the chain and desolvates backbone hydrogen bonds. this desolvation can be directly correlated with a higher probability of hydrogen bond formation. we find that fs has higher helical content than a21 at all temperatures. a small modification in the amber force field reproduces the experimental helical content and helix-coil transition temperatures for the fs peptide.
photoinduced cu(ii)-mediated reversible deactivation radical polymerization (rdrp) was employed to synthesize poly(vinylidene fluoride-co-chlorotrifluoroethylene)-graft-polyacrylonitrile (p(vdf-co-ctfe)-g-pan). the concentration of copper catalyst (cucl2) loading was as low as 1/64 equivalent to chlorine atom in the presence of me6-tren under uv irradiation. the light-responsive nature of graft polymerization was confirmed by “off-on” impulsive irradiation experiments. temporal control of the polymerization process and varied graft contents were achieved via this photoinduced cu(ii)-mediated rdrp. an environmentally friendly and controllable p(vdf-co-ctfe) hydrogenation route involving the transition-metal complex mediated radical chain transfer reaction is successfully developed to synthesize p(vdf-co-ctfe-co-trfe). the typical transition metal catalysts of atrp reaction could be applied in this process.
real-time three-dimensional (rt3d) echocardiography is a new image acquisition technique that allows instantaneous acquisition of volumetric images for quantitative assessment of cardiac morphology and function. to quantify many important diagnostic parameters, such as ventricular volume, ejection fraction, and cardiac output, an automatic algorithm to delineate the left ventricle (lv) from rt3d echocardiographic images is essential. while a number of efforts have been made towards segmentation of the lv endocardial (endo) boundaries, the segmentation of epicardial (epi) boundaries remains problematic. in this paper, we present a coupled deformable model that addresses this problem. the idea behind our method is that the volume of the myocardium is close to being constant during a cardiac cycle and our model uses this coupling as an important constraint. we employ two surfaces, each driven by the image-derived information that takes into account ultrasound physics by modeling the speckle statistics using the nakagami distribution while maintaining the coupling. by simultaneously evolving two surfaces, the final segmentation of the myocardium is thus achieved. results from 80 sets of synthetic data and 286 sets of real canine data were evaluated against the ground truth and against outlines from three independent observers, respectively. we show that results obtained with our incompressibility constraint were more accurate than those obtained without constraint or with a wall thickness constraint, and were comparable to those from manual segmentation. this study investigated the use of artificial neural networks (ann) for image segmentation and spatial temporal contour linking for the detection of endocardial contours on echocardiographic images. using a backpropagation network, the system was trained with 279 sample regions obtained from eight training images to segment images into either tissue or blood pool region. the ann system was then applied to parasternal short axis images of 38 patients. spatial temporal contour linking was performed on the segmented images to extract endocardial boarders. left ventricular areas (end-systolic and end-diastolic) determined with the automated system were calculated and compared to results obtained by manual contour tracing performed by two independent investigators. in addition, ejection fractions (ef) were derived using the area-length method and compared with radionuclide ventriculography. image quality was classified as good in 12 (32%), moderate in 13 (34%) and poor in 13 (34%) patients. the ann system provided estimates of end-diastolic and end-systolic areas in 36 (89%) of echocardiograms, which correlated well with those obtained by manual tracing (r = 0.99, see = 1.44). a good agreement was also found for the comparison of ef between the ann system and tc-radionuclide ventriculography (rnv, r = 0.93, see = 6.36). the ann system also performed well in the subset of patients with poor image quality. endocardial contour detection using artificial neural networks and spatial temporal contour linking allows accurate calculations of ventricular areas from transthoracic echocardiograms and performs well even in images with poor quality. this system could greatly enhance the feasibility, accuracy and reproducibility of calculating cardiac areas to derive left ventricular volumes and ejection fractions.
convolutional sparse coding (csc) has been popularly used for the learning of shift-invariant dictionaries in image and signal processing. however, existing methods have limited scalability. in this paper, instead of convolving with a dictionary shared by all samples, we propose the use of a sample-dependent dictionary in which filters are obtained as linear combinations of a small set of base filters learned from the data. this added flexibility allows a large number of sample-dependent patterns to be captured, while the resultant model can still be efficiently learned by online learning. extensive experimental results show that the proposed method outperforms existing csc algorithms with significantly reduced time and space requirements. in recent years there has been a growing interest in the study of sparse representation of signals. using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. recent activity in this field concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. designing dictionaries to better fit the above model can be done by either selecting one from a pre-specified set of linear transforms, or by adapting the dictionary to a set of training signals. both these techniques have been considered, but this topic is largely still open. in this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. we present a new method – the k-svd algorithm – generalizing the k-means clustering process. k-svd is an iterative method that alternates between sparse coding of the examples based on the current dictionary, and a process of updating the dictionary atoms to better fit the data. the update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. the k-svd algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, focuss, or matching pursuit). we analyze this algorithm and demonstrate its results on both synthetic tests and in applications on real image data.
immunosuppressive therapy is a therapeutic option for selected low-risk myelodysplastic syndromes (mds) patients. besides standard treatment protocols that include atg and csa, the humanized cd52 antibody alemtuzumab has been shown to have efficacy in mds treatment. we report our experience with alemtuzumab in nine mds rcmd patients. all patients had a hypocellular bone marrow with a blast count <5 % and were classified as intermediate-1 according to the ipss. we found a response in five patients (60 %); three patients achieved a complete remission 3 and 6 months after the treatment with alemtuzumab, and two patients showed a haematological improvement. alemtuzumab was administered in a 10-mg dosage for 10 days. treatment was well tolerated, and no severe side effects were observed. we could confirm the finding that the alemtuzumab is effective and save selected mds patients. due to the promising results, further studies, especially with regard to long-term survival and risk of leucemic progression should be initiated. immunosuppressive therapy has been shown to induce sustained hematological responses in a subset of patients with myelodysplastic syndromes (mds). in particular, antithymocyte globulin (atg), a polyclonal immunoglobulin induces hematological responses in up to 60% of mds patients. we report herein on the results of a retrospective multicenter study on the use of atg in the treatment of 96 patients with mds. patients were evaluated for duration of response to atg, as well as survival after administration of atg. the median age of the cohort was 54.7 years (range: 19–75 years), with a median follow-up of 33.8 months (range: 0.8–133 months). a total of 40 patients (42%) achieved a hematological response, of which 30 patients (75%) had a durable hematological response lasting a median duration of 31.5 months (range: 6–92 months). on multivariate analysis, both low international prognostic scoring system (ipss) and bone marrow (bm) hypocellularity were independent predictive factors for improved response to atg (ipss int-2/high: odds ratio (or) 0.08, p=0.018 and bm normo/hypercellularity: or 0.49, p=0.012). in addition, ipss was the sole predictor of overall survival, with int-2/high risk patients having a significantly poorer survival outcome (or 0.08, p<0.01). in conclusion, this study identifies bm hypocellularity and a low ipss as important factors predicting response to atg.
the number of copies of rrna (rrn) operons in a bacterial genome differs greatly among bacterial species. here we examined the phenotypic effects of variations in the number of copies of rrna genes in the genome of bacillus subtilis by analysis of eight mutant strains constructed to carry from two to nine copies of the rrn operon. we found that a decrease in the number of copies from ten to one increased the doubling time, and decreased the sporulation frequency and motility. the maximum levels for transformation activity were similar among the strains, although the competence development was significantly delayed in the strain with a single rrn operon. normal sporulation only occurred if more than four copies of the rrn operon were present, although ten copies were needed for vegetative growth after germination of the spores. this behaviour was seen even though the intracellular level of ribosomes was similar among strains with four to ten copies of the rrn operon. furthermore, ten copies of the rrn operon were needed for the highest swarming activity. we also constructed 21 strains that carried all possible combinations of two copies of the rrn operons, and found that these showed a range of growth rates and sporulation frequencies that all fell between those recorded for strains with one or three copies of the rrn operon. the results suggested that the copy number of the rrn operon has a major influence on cellular processes such as growth rate and sporulation frequency. rna was extracted from dormant and germinating bacillus subtilis 168 spores (intact spores and chemically decoated spores) by using rapid rupture followed by acid–phenol extraction. spore germination progress was monitored by assaying colony forming ability before and after heat shock and by reading the optical density at 600 nm. the purity, yield, and composition of the extracted rna were determined spectrophotometrically from the ratio of absorption at 260 nm to that at 280 nm; in a 2100 bioanalyzer, giving the rna yield/108 spores or cells and the distribution pattern of rrna components. the method reported here for the extraction of rna from dormant spores, as well as during different phases of germination and outgrowth, has proven to be fast, efficient and simple to handle. rna of a high purity was obtained from dormant spores and during all phases of germination and growth. there was a significant increase in rna yield during the transition from dormant spores to germination and subsequent outgrowth. chemically decoated spores were retarded in germination and outgrowth compared with intact spores, and less rna was extracted; however, the differences were not significant. this method for rna isolation of dormant, germinating, and outgrowing bacterial endospores is a valuable prerequisite for gene expression studies, especially in studies on the responses of spores to hostile environmental conditions.
we present a novel adaptive clustering model for coreference resolution in which the expert rules of a state of the art deterministic system are used as features over pairs of clusters. a significant advantage of the new approach is that the expert rules can be easily augmented with new semantic features. we demonstrate this advantage by incorporating semantic compatibility features for neutral pronouns computed from web n-gram statistics. experimental results show that the combination of the new features with the expert rules in the adaptive clustering approach results in an overall performance improvement, and over 5% improvement in f1 measure for the target pronouns when evaluated on the ace 2004 newswire corpus. most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features. this approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones. to overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision. each tier builds on the previous tier's entity cluster output. further, our model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster. this cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time. the framework is highly modular: new coreference modules can be plugged in without any change to the other modules. in spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora. this suggests that sieve-based approaches could be applied to other nlp tasks.
image instance retrieval is the problem of retrieving images from a database which contain the same object. convolutional neural network (cnn) based descriptors are becoming the dominant approach for generating global image descriptors for the instance retrieval problem. one major drawback of cnn-based global descriptors is that uncompressed deep neural network models require hundreds of megabytes of storage making them inconvenient to deploy in mobile applications or in custom hardware. in this work, we study the problem of neural network model compression focusing on the image instance retrieval task. we study quantization, coding, pruning and weight sharing techniques for reducing model size for the instance retrieval problem. we provide extensive experimental results on the trade-off between retrieval performance and model size for different types of networks on several data sets providing the most comprehensive study on this topic. we compress models to the order of a few mbs: two orders of magnitude smaller than the uncompressed models while achieving negligible loss in retrieval performance1. evidence is mounting that convnets are the best representation learning method for recognition. in the common scenario, a convnet is trained on a large labeled dataset and the feed-forward units activation, at a certain layer of the network, is used as a generic representation of an input image. recent studies have shown this form of representation to be astoundingly effective for a wide range of recognition tasks. this paper thoroughly investigates the transferability of such representations w.r.t. several factors. it includes parameters for training the network such as its architecture and parameters of feature extraction. we further show that different visual recognition tasks can be categorically ordered based on their distance from the source task. we then show interesting results indicating a clear correlation between the performance of tasks and their distance from the source task conditioned on proposed factors. furthermore, by optimizing these factors, we achieve state-of-the-art performances on 16 visual recognition tasks.
we propose a data structure obtained by hierarchically pooling bag-of-words (bow) descriptors during a sequence of views that achieves average speedups in large-scale loop closure applications ranging from 2 to 20 times on benchmark datasets. although simple, the method works as well as sophisticated agglomerative schemes at a fraction of the cost with minimal loss of performance. this paper presents a mathematical definition of the "probability-weighted amount of information" (pwi), a measure of specificity of terms in documents that is based on an information-theoretic view of retrieval events. the proposed pwi is expressed as a product of the occurrence probabilities of terms and their amounts of information, and corresponds well with the conventional term frequency-inverse document frequency measures that are commonly used in today's information retrieval systems. the mathematical definition of the pwi is shown, together with some illustrative examples of the calculation.
the order-preserving submatrices (opsms) are employed to discover significant biological associations between genes and experiment conditions. herein, we propose a new relaxed opsm model by considering the linearity relaxation, which is called the bucket opsm (bopsm) model. an efficient method called apribopsm is developed to exhaustively mine such bopsm patterns. we further generalize the bopsm model by incorporating the similarity relaxation strategy. we develop a generalized bopsm model called gebopsm and adopt a pattern growing method called seedgrowth to mine gebopsm patterns. informally, the seedgrowth algorithm adopts two different growing strategies on rows and columns in order to expand a seed bopsm into a maximal gebopsm pattern. we conduct a series of experiments using both synthetic and biological datasets to study the effectiveness of our proposed relaxed models and the efficiency of the relevant mining methods. the bopsm model is shown to be able to capture the characteristics of noisy opsm patterns, and is superior to the strict counterparts. apribopsm is also significantly more efficient than opc-tree, which is the state-of-the-art opsm mining method. compared to all the current relaxed opsm models, the gebopsm model achieves the best performance in terms of the number of mined quality patterns. subspace clustering has attracted great attention due to its capability of finding salient patterns in high dimensional data. order preserving subspace clusters have been proven to be important in high throughput gene expression analysis, since functionally related genes are often co-expressed under a set of experimental conditions. such co-expression patterns can be represented by consistent orderings of attributes. existing order preserving cluster models require all objects in a cluster have identical attribute order without deviation. however, real data are noisy due to measurement technology limitation and experimental variability which prohibits these strict models from revealing true clusters corrupted by noise. in this paper, we study the problem of revealing the order preserving clusters in the presence of noise. we propose a noise-tolerant model called approximate order preserving cluster (aopc). instead of requiring all objects in a cluster have identical attribute order, we require that (1) at least a certain fraction of the objects have identical attribute order; (2) other objects in the cluster may deviate from the consensus order by up to a certain fraction of attributes. we also propose an algorithm to mine aopc. experiments on gene expression data demonstrate the efficiency and effectiveness of our algorithm.
arachidonic acid at micromolar concentrations produced a drastic increase of the generation of reactive oxygen species (ros) in rat hepatoma as-30d cells cultivated in vitro along with an increase in the incidence of apoptotic cell death. both processes were prevented by trolox, a water-soluble tocopherol derivative, and tempol, a known antioxidative agent. a synthetic hybrid of lipoic acid and trolox or preincubation with n-acetylcysteine were less effective. preincubation of the cells with etomoxir, a known highly specific irreversible inhibitor of carnitine-palmitoyltransferase i, partly decreased the ros formation induced by arachidonic acid but it did not affect the increase in apoptosis. cumulatively, these results indicate that apoptosis induced in hepatoma cells by arachidonic acid is mediated by ros. they also suggest that this effect is due to arachidonic acid as such and not to its mitochondrial oxidative metabolites. arachidonic acid and, to a smaller extent, oleic acid at micromolar concentrations decreased the mitochondrial membrane potential within as-30d rat hepatoma cells cultivated in vitro and increased cell respiration. the uncoupling effect of both fatty acids on cell respiration was partly prevented by cyclosporin a, blocker of the mitochondrial permeability transition pore. arachidonic acid increased the rate of reactive oxygen species (ros) production, while oleic acid decreased it. both fatty acids induced apoptotic cell death of as-30d cells, accompanied by the release of cytochrome c from mitochondria to the cytosol, activation of caspase-3 and association of proapoptotic bax protein with mitochondria; arachidonic acid being a more potent inducer than oleic acid. trolox, a potent antioxidant, prevented ros increase induced by arachidonic acid and protected the cells against apoptosis produced by this fatty acid. it is concluded that arachidonic and oleic acids induce apoptosis of as-30d hepatoma cells by the mitochondrial pathway but differ in the mechanism of their action: arachidonic acid induces apoptosis mainly by stimulating ros production, whereas oleic acid may contribute to programmed cell death by activation of the mitochondrial permeability transition pore.
kawahara i, kuniyasu h, matsuyoshi h, goto k, obata k, misawa h, fujii h, takaki m. comparison of effects of a selective 5-ht reuptake inhibitor versus a 5-ht4 receptor agonist on in vivo neurogenesis at the rectal anastomosis in rats. am j physiol gastrointest liver physiol 302: g588–g597, 2012. first published december 22, 2011; doi:10.1152/ajpgi.00284.2011.—it was recently reported that activation of enteric neural 5-ht4 receptors (sr4) promotes reconstruction of enteric neural circuit injury in distal gut of guinea pigs and that this reconstruction involves neural stem cells. we aimed to explore a novel approach using a selective serotonin reuptake inhibitor (ssri), which increases endogenous 5-ht, to repair enteric nerve fiber injury in the rat distal gut. enteric nerve fiber injury was performed by rectal transection and subsequent end-to-end one-layer anastomosis. the ssri fluvoxamine maleate (100 mol/l) was applied locally at the anastomotic site to compare with the 5-ht4 agonist mosapride citrate (100 mol/l) (applied for patent) applied locally and orally. unlike mosapride, fluvoxamine failed to promote the regeneration of the nerve fiber tract across the anastomosis. furthermore, fluvoxamine did not generate antidistal-less homeobox 2 (dlx2)and anti-sr4-positive cells (neural stem cells) and/or anti-neurofilament (nf)-positive cells (neural cells) in newly formed granulation tissue at the anastomosis, whereas these cell types were observed in mosapride-treated preparations. in contrast to its effects in guinea pigs, mosapride generated 5-bromo-2=-deoxyuridine (brdu)-positive neural cells in ganglia sites 3 mm oral and anal from the anastomosis 2 wk after nerve fiber injury. all actions of mosapride were observed after local and or oral applications. these findings indicate that local ssri treatment does not induce in vivo nerve fiber tract growth across the anastomosis in the rat distal gut. mosapride induces nerve fiber tract growth across the anastomosis, mediated through enteric neural stem cells possibly from neural crest-derived stem cells or mesenchymal stem cells in the bone marrow. moderate rectal distension elicits recto-rectal reflex contractions and simultaneous recto-internal anal sphincter reflex relaxations that together comprise the defecation reflex. both reflexes are controlled by 1) pelvic nerves, 2) lumbar colonic nerves, and 3) enteric nervous system. the aim of the present study was to explore a novel approach to repairing the defecation reflex dysfunction by using the plasticity of enteric nervous pathways. experiments were performed in anesthetized guinea pigs with ethyl carbamate. the rectum 30 mm oral from the anal verge was transected without damage to extrinsic nerves, and subsequent end-to-end one-layer anastomosis was performed. recovery of the defecation reflex and associated reflex pathways were evaluated. eight weeks after sectioning of intrinsic reflex nerve pathways in the rectum, the defecation reflex recovered to the control level, accompanied with regeneration of reflex pathways. the 5-ht(4)-receptor agonist mosapride (0.5 and 1.0 mg/kg) significantly (p < 0.01) enhanced the recovered defecation reflex 8 wk after surgery. two weeks after local treatment with brain-derived neurotrophic factor (bdnf: 10(-6) g/ml) at the rectal anastomotic site, the recto-internal anal sphincter reflex relaxations recovered and some bundles of fine nerve fibers were shown to interconnect the oral and anal ends of the myenteric plexus. these results suggested a possibility for repairing the anal dysfunction by promoting regeneration of the reflex pathways in the enteric nervous system with local application of bdnf.
supervised 3d reconstruction has witnessed a significant progress through the use of deep neural networks. however, this increase in performance requires large scale annotations of 2d/3d data. in this paper, we explore inexpensive 2d supervision as an alternative for expensive 3d cad annotation. specifically, we use foreground masks as weak supervision through a raytrace pooling layer that enables perspective projection and backpropagation. additionally, since the 3d reconstruction from masks is an ill posed problem, we propose to constrain the 3d reconstruction to the manifold of unlabeled realistic 3d shapes that match mask observations. we demonstrate that learning a log-barrier solution to this constrained optimization problem resembles the gan objective, enabling the use of existing tools for training gans. we evaluate and analyze the manifold constrained reconstruction on various datasets for single and multi-view reconstruction of both synthetic and real images. inspired by the recent success of methods that employ shape priors to achieve robust 3d reconstructions, we propose a novel recurrent neural network architecture that we call the 3d recurrent reconstruction neural network (3d-r2n2). the network learns a mapping from images of objects to their underlying 3d shapes from a large collection of synthetic data [13]. our network takes in one or more images of an object instance from arbitrary viewpoints and outputs a reconstruction of the object in the form of a 3d occupancy grid. unlike most of the previous works, our network does not require any image annotations or object class labels for training or testing. our extensive experimental analysis shows that our reconstruction framework (i) outperforms the state-of-the-art methods for single view reconstruction, and (ii) enables the 3d reconstruction of objects in situations when traditional sfm/slam methods fail (because of lack of texture and/or wide baseline).
dendritic cell (dc)-based vaccinations represent a promising approach for the immunotherapy of cancer and infectious diseases as dcs play an essential role in initiating cellular immune responses. a number of clinical trials using ex vivo-generated dcs have been performed so far and only minor toxicity has been reported. both the induction of antigen-specific t cells and clinical responses have been observed in vaccinated cancer patients. nevertheless, dc-based immunotherapy is still in its infancy and there are many issues to be addressed such as antigen loading procedures, dc source and maturational state, migration properties, route, frequency, and dosage of dc vaccination. the increasing knowledge of dc biology should be used to improve the efficacy of this new therapy. immunotherapies for human autoimmune and immune-mediated diseases are proliferating rapidly, and with these changes comes the opportunity to monitor patients for immune responses to therapy based on early surrogate markers for clinical responses. class ii tetramers have the potential to serve as these sorts of markers for immune monitoring, and thereby assist with patient management, therapy selection, and improved outcomes. however, important issues of tcr avidity require resolution, because much is still unknown regarding location, quantitation, and characterization of the human t cell response. opportunities for application of tetramer technologies in the near future will enable both clinical progress and the development of new insights into human cd4+ t cell biology in vivo.
community health workers (chws) have gained national recognition for their role in addressing health disparities and are increasingly integrated into the health care delivery system. there is a lack of consensus, however, regarding empirical evidence on the impact of chw interventions on health outcomes. in this paper, we present results from the 2010 national community health worker advocacy survey (nchwas) in an effort to strengthen a generalized understanding of the chw profession that can be integrated into ongoing efforts to improve the health care delivery system. results indicate that regardless of geographical location, work setting, and demographic characteristics, chws generally share similar professional characteristics, training preparation, and job activities. chws are likely to be female, representative of the community they serve, and to work in community health centers, clinics, community-based organizations, and health departments. the most common type of training is on-the-job and conference training. most chws work with clients, groups, other chws and less frequently community leaders to address health issues, the most common of which are chronic disease, prevention and health care access. descriptions of chw activities documented in the survey demonstrate that chws apply core competencies in a synergistic manner in an effort to assure that their clients get the services they need. nchwas findings suggest that over the past 50 years, the chw field has become standardized in response to the unmet needs of their communities. in research and practice, the field would benefit from being considered a health profession rather than an intervention. the community health worker model is recognized nationally as a means to address glaring inequities in the burden of adverse health conditions that exist among specific population groups in the united states. this study explored arizona chw involvement in advocacy beyond the individual patient level into the realm of advocating for community level change as a mechanism to reduce the structural underpinnings of health disparities. a survey of chws in arizona found that chws advocate at local, state and federal political levels as well as within health and social service agencies and business. characteristics significantly associated with advocacy include employment in a not for profit organization, previous leadership training, and a work environment that allows flexible work hours and the autonomy to start new projects at work. intrinsic characteristics of chws associated with advocacy include their belief that they can influence community decisions, self perception that they are leaders in the community, and knowledge of who to talk to in their community to make change. community-level advocacy has been identified as a core chw function and has the potential to address structural issues such as poverty, employment, housing, and discrimination. agencies utilizing the chw model could encourage community advocacy by providing a flexible working environment, ongoing leadership training, and opportunities to collaborate with both veteran chws and local community leaders. further research is needed to understand the nature and impact of chw community advocacy activities on both systems change and health outcomes.
the mass shooting at sandy hook elementary school on december 14, 2012 catalyzed a year of active debate and legislation on gun control in the united states. social media hosted an active public discussion where people expressed their support and opposition to a variety of issues surrounding gun legislation. in this paper, we show how a content-based analysis of twitter data can provide insights and understanding into this debate. we estimate the relative support and opposition to gun control measures, along with a topic analysis of each camp by analyzing over 70 million gun-related tweets from 2013. we focus on spikes in conversation surrounding major events related to guns throughout the year. our general approach can be applied to other important public health and political issues to analyze the prevalence and nature of public opinion. this paper describes our approach for the detecting stance in tweets task (semeval-2016 task 6). we utilized recent advances in short text categorization using deep learning to create word-level and character-level models. the choice between word-level and character-level models in each particular case was informed through validation performance. our final system is a combination of classifiers using word-level or character-level models. we also employed novel data augmentation techniques to expand and diversify our training dataset, thus making our system more robust. our system achieved a macro-average precision, recall and f1-scores of 0.67, 0.61 and 0.635 respectively.
in rheumatoid arthritis (ra), the patient global assessment (pga) has been strongly associated with pain severity, but less often with other measures, including disease activity measures. we tested whether ra activity and psychological measures had direct associations with the pga or indirect associations that were mediated by pain. we also tested whether the correlates of the pga differed with the degree of ra activity. a structure for representation of patient outcome is presented, together with a method for outcome measurement and validation of the technique in rheumatoid arthritis. the paradigm represents outcome by five separate dimensions: death, discomfort, disability, drug (therapeutic) toxicity, and dollar cost. each dimension represents an outcome directly related to patient welfare. quantitation of these outcome dimensions may be performed at interview or by patient questionnaire. with standardized, validated questions, similar scores are achieved by both methods. the questionnaire technique is preferred since it is inexpensive and does not require interobserver validation. these techniques appear extremely useful for evaluation of long term outcome of patients with rheumatic diseases.
providing learning materials and support services that are adapted to the needs of individuals has the potential to enable learners to obtain maximal benefit from university level studies. this paper describes eu4all project which has been exploring how to present customized learning materials and services for people with disabilities. a number of the technical components of the eu4all framework are described. this is followed with a brief description of prototype implementations. this is then followed by a discussion of a number of research directions that may enhance the adaptability, usability and accessibility of information and support systems can be used and consumed by a diverse user population. uned uses dotlrn learning management system (lms) in two different scopes i) exploitation and ii) research due to the integration capabilities, adaptivity, reusability and accessibility support. the paper introduces the main features of openacs/dotlrn architecture and provides an historical overview of the usage of dotlrn in innova (exploitation) and adenu (research) groups. it details the reasons why openacs/dotlrn was chosen in both groups and presents a comparison among dotlrn and other lms, with special emphasis on moodle (the most commonly used open source lms) to show their pros and cons. the paper describes how it is being used in each group and what contributions have been done to the community so far.
background a vaccine for chlamydia trachomatis is of urgent medical need. we explored bioinformatic approaches to generate an immunogen against c. trachomatis that would induce cross-serovar t-cell responses as (i) cd4+ t cells have been shown in animal models and human studies to be important in chlamydial protection and (ii) antibody responses may be restrictive and serovar specific. methods a consensus antigen based on over 1,500 major outer membrane protein (momp) sequences provided high epitope coverage against the most prevalent c. trachomatis strains in silico. having designed the t-cell immunogen, we assessed it for immunogenicity in prime-boost regimens. this consensus momp transgene was delivered using plasmid dna, human adenovirus 5 (huad5) or modified vaccinia ankara (mva) vectors with or without mf59® adjuvanted recombinant momp protein. results different regimens induced distinct immune profiles. the dna-huad5-mva-protein vaccine regimen induced a cellular response with a th1-biased serum antibody response, alongside high serum and vaginal momp-specific antibodies. this regimen significantly enhanced clearance against intravaginal c. trachomatis serovar d infection in both balb/c and b6c3f1 mouse strains. this enhanced clearance was shown to be cd4+ t-cell dependent. future studies will need to confirm the specificity and precise mechanisms of protection. conclusion a c. trachomatis vaccine needs to induce a robust cellular response with broad cross-serovar coverage and a heterologous prime-boost regimen may be an approach to achieve this. the majority of vaccine candidates in clinical development are highly purified proteins and peptides relying on adjuvants to enhance and/or direct immune responses. despite the acknowledged need for novel adjuvants, there are still very few adjuvants in licensed human vaccines. a vast number of adjuvants have been tested pre-clinically using different experimental conditions, rendering it impossible to directly compare their activity. we performed a head-to-head comparison of five different adjuvants alum, mf59®, gla-se, ic31® and caf01 in mice and combined these with antigens from m. tuberculosis, influenza, and chlamydia to test immune-profiles and efficacy in infection models using standardized protocols. regardless of antigen, each adjuvant had a unique immunological signature suggesting that the adjuvants have potential for different disease targets. alum increased antibody titers; mf59® induced strong antibody and il-5 responses; gla-se induced antibodies and th1; caf01 showed a mixed th1/th17 profile and ic31® induced strong th1 responses. mf59® and gla-se were strong inducers of influenza hi titers while caf01, gla-se and ic31® enhanced protection to tb and chlamydia. importantly, this is the first extensive attempt to categorize clinical-grade adjuvants based on their immune profiles and protective efficacy to inform a rational development of next generation vaccines for human use.
polo-like kinase-1 (plk1) is activated before mitosis by aurora a and its cofactor bora. in mitosis, bora is degraded in a manner dependent on plk1 kinase activity and the e3 ubiquitin ligase scf-βtrcp. here, we show that plk1 is also required for the timely destruction of its activator aurora a in late anaphase. it has been shown that aurora a destruction is controlled by the auxiliary subunit cdh1 of the anaphase-promoting complex/cyclosome (apc/c). remarkably, we found that plk1-depletion prevented the efficient dephosphorylation of cdh1 during mitotic exit. plk1 mediated its effect on cdh1, at least in part, through direct phosphorylation of the human phosphatase cdc14a, controlling the phosphorylation state of cdh1. we conclude that plk1 facilitates efficient aurora a degradation through apc/c-cdh1 activation after mitosis, with a potential role for hcdc14a. we show that human cdc14a phosphatase interacts with interphase centrosomes, and that this interaction is independent of microtubules and cdc14a phosphatase activity, but requires active nuclear export. disrupting the nuclear export signal (nes) led to cdc14a being localized in nucleoli, which in unperturbed cells selectively contain cdc14b (ref. 1). conditional overproduction of cdc14a, but not its phosphatase-dead or nes-deficient mutants, or cdc14b, resulted in premature centrosome splitting and formation of supernumerary mitotic spindles. in contrast, downregulation of endogenous cdc14a by short inhibitory rna duplexes (sirna) induced mitotic defects including impaired centrosome separation and failure to undergo productive cytokinesis. consequently, both overexpression and downregulation of cdc14a caused aberrant chromosome partitioning into daughter cells. these results indicate that cdc14a is a physiological regulator of the centrosome duplication cycle, which, when disrupted, can lead to genomic instability in mammalian cells.
candida albicans is a common opportunistic fungal pathogen, causing both superficial candidiasis and life-threatening systemic infections in immune-compromised individuals. calcium signaling is responsible for this pathogen in responding to several stresses, such as antifungal drugs, alkaline ph and membrane-perturbing agents. our recent study revealed that it is also involved in oxidative stress response. in this study, we investigated the effect of verapamil, an l-type voltage-gated calcium channel blocker, on oxidative stress response in this fungus. the addition of verapamil resulted in increased sensitivity to the oxidative agent h2o2, which is associated with a decrease of calcium fluctuation under the stress. moreover, this agent caused enhanced oxidative stress, with increased levels of ros and enhanced dysfunction of the mitochondria under the oxidative stress. further investigations in sod activity, gsh contents and expression of oxidative stress response-related genes indicated that the effect of verapamil is related to the repression of oxidative stress response. our findings demonstrated that verapamil has an inhibitory effect on oxidative stress response, confirming the relationship between calcium signaling and oxidative stress in c. albicans. therefore, calcium channels may be potential targets for therapy to enhance the efficacy of oxidative stress against c. albicans-related infections. abstract the ability of the major systemic fungal pathogen of humans, candida albicans, to sense and respond to reactive oxygen species (ros), such as h2o2 generated by the host immune system, is required for survival in the host. however, the intracellular signaling mechanisms underlying such responses are poorly understood. here, we show that thioredoxin (trx1), in addition to its antioxidant activity, plays a central role in coordinating the response of c. albicans to ros by regulating multiple pathways. in particular, trx1 function is important for h2o2-induced phosphorylation of the hog1 stress-activated protein kinase and to reverse h2o2-induced oxidation and activation of the ap-1 like transcription factor cap1. furthermore, trx1 regulates h2o2-induced hyperpolarized bud growth in a mechanism that involves activation of the rad53 checkpoint kinase. consistent with its key roles in responses to ros, cells lacking trx1 displayed significantly attenuated virulence in a murine model of c. albicans systemic infection. collectively, our data indicate that trx1 has a multifaceted role in h2o2 signaling and promotes c. albicans survival in the host.
we propose a new built-in self-test (bist) method based on a combination of a pseudo-random test method with a deterministic test. this enables us to reach a high fault coverage in a short test time and with a l ow area overhead. the main feature of the method is that there are no memory elements to store the deterministic test patterns; the test pat terns are being produced by a transformation of the non-testing pseudo-random patterns. this transformation is being done by a purely combinational block, while we try to keep this block as small as possible. our method can be apprehended as a generalization of a bit-fixing method. we synthesize the transformation logic by a slightly modified column-matching algorithm proposed before. a new design methodology for a pattern generator is proposed, formulated in the context of on-chip bist. the design methodology is circuit-specific and uses synthesis techniques to design bist generators. the pattern generator consists of two components: a pseudorandom pattern generator (like an lfsr or, preferably, a glfsr) and a combinational logic to map the outputs of the pseudorandom pattern generator. this combinational logic is synthesized to produce a given set of target patterns by mapping the outputs of the pseudorandom pattern generator. it is shown that, for a particular cut, an area-efficient combinational logic block can be designed/synthesized to achieve 100 (or almost 100) percent single stuck-at fault coverage using a small number of test the this method is significantly different from weighted pattern generation and can guarantee testing of all hard-to-detect faults without expensive test point insertion. experimental results on common benchmark netlists demonstrate that the fault coverage of the proposed pattern generator is significantly higher compared to conventional pattern generation techniques. the design technique for the logic mapper is unique and can be used effectively to improve existing pattern generators for combinational logic and scan-based bist structures.
repair of full thickness defects of articular cartilage in the knee is difficult but important to prevent progression to osteoarthritis. the purpose of this retrospective study was to evaluate the clinical results of osteochondral autograft transplant system (oats) treatment for articular defects of the knee. between 1999 and 2005, 15 knees (14 patients) were treated by the oats technique. age ranged from 27 to 52 years. cartilage defects were up to 3.75 cm2. the mean follow-up was 42 months. knee function was assessed by the lysholmscore and international knee documentation committee (ikdc) subjective knee form. six patients scored good or excellent. no patient had knee instability. twelve of 13 patients returned to sports at an intermediate or high level. the subjective assessment score (0-10) changed from 4.7 before operation to 7.2 afterward (p=0.007). the oats-technique resulted in a decrease in symptoms in patients with localized articular cartilage defects. we consider the oats technique to be an appropriate treatment for cartilage defects to prevent progression of symptoms. purpose the purpose of this study was to compare the outcomes of mosaic-type osteochondral autologous transplantation (oat) and microfracture (mf) procedures for the treatment of the articular cartilage defects of the knee joint in young active athletes.   type of study prospective randomized clinical study.   methods between 1998 and 2002, a total of 60 athletes with a mean age of 24.3 years (range, 15 to 40 years) and with a symptomatic lesion of the articular cartilage in the knee were randomized to undergo either an oat or an mf procedure. only those athletes playing in competitive sports at regional or national levels were included in the study. fifty-seven athletes (95%) were available for a follow-up. there were 28 athletes in the oat group and 29 athletes in the mf group. the mean duration of symptoms was 21.32 +/- 5.57 months and the mean follow-up was 37.1 months (range, 36 to 38 months), and none of the athletes had prior surgical interventions to the affected knee. patients were evaluated using modified hospital for special surgery (hss) and international cartilage repair society (icrs) scores, radiograph, magnetic resonance imaging (mri), and clinical assessment. an independent observer performed a follow-up examination after 6, 12, 24, and 36 months. at 12.4 months postoperatively, arthroscopy with biopsy for histologic evaluation was carried out. a radiologist and a pathologist, both of whom were blinded to each patient's treatment, did the radiologic and histologic evaluations.   results after 37.1 months, both groups had significant clinical improvement (p < .05). according to the modified hss and icrs scores, functional and objective assessment showed that 96% had excellent or good results after oat compared with 52% for the mf procedure (p < .001). at 12, 24, and 36 months after surgery, the hss and icrs showed statistically significantly better results in the oat group (p = .03; p = .006; p = .006). younger athletes did better in both groups. no serious complications were reported. there was 1 failure in the oat group and 9 in the mf group. the icrs cartilage repair assessment for macroscopic evaluation during arthroscopy at 12.4 months showed excellent or good repairs in 84% after oat and in 57% after mf. biopsy specimens were obtained from 58% of the patients and histologic evaluation of repair showed better scores (according to icrs) for the oat group (p < .05). mri evaluation showed excellent or good repairs in 94% after oat compared with 49% after mf. twenty-six (93%) oat patients and 15 (52%) mf patients returned to sports activities at the preinjury level at an average of 6.5 months (range, 4 to 8 months). others showed a decline in sports activity level.   conclusions at an average of 37.1 months (range, 36 to 38 months) follow-up, our prospective, randomized, clinical study in young active athletes under the age of 40 has shown significant superiority of oat over mf for the repair of articular cartilage defects in the knee. we found that only 52% of mf athletes could return to sports at the preinjury level. limitations of our study included a small number of athletes and a relatively short (3-year) follow-up. a long-term follow-up is needed to assess the durability of articular cartilage repair using these methods in young active athletes.   level of evidence level i, therapeutic study, randomized controlled trial, significant difference (a).
medical devices, such as infusion pumps that deliver life-critical medication, are frequently used at home by patient's themselves as a cost saving measure. as individuals age, many are impacted by cognitive decline such that the proper sequencing of steps of a task is forgotten. since the danger of making an error can be quite high. so, to detect errors when patients operate a home medical device, we observe them with multiple cameras and record pump sensor information. we then use a robust approach to recognize actions based on explicitly encoding motion information using mosift, which detects interest points and encodes not only their local appearance but also explicitly models local motion. our goal is to see if the patient has correctly performed the required actions in the prescribed sequence for the device. thus, firstly, we will evaluate how to group the requiring 22 operation steps. secondly, we will analysis the duration of actions, and consider the user adaption. thirdly, the order of actions is introduced, and hmm is used in our algorithm. fourthly, as some actions are very difficult to recognize by computer vision, so the physical sensor information is borrowed in our system. subsequently, we also consider how to fuse the results from different cameras. finally, we also evaluate the performances when we add different numbers of videos from test subjects. from the experiments, we can see that the improvement of our system performance changes from 49% to over 80%. and if we can obtain 6-7 videos from the patients, and add them into the training dataset, the performance of our system with our simplest way can be 83.7%. the aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. this challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. our first contribution is to address this limitation and to investigate the use of movie scripts for automatic annotation of human actions in videos. we evaluate alternative methods for action retrieval from scripts and show benefits of a text-based classifier. using the retrieved action samples for visual learning, we next turn to the problem of action classification in video. we present a new method for video classification that builds upon and extends several recent ideas including local space-time features, space-time pyramids and multi-channel non-linear svms. the method is shown to improve state-of-the-art results on the standard kth action dataset by achieving 91.8% accuracy. given the inherent problem of noisy labels in automatic annotation, we particularly investigate and show high tolerance of our method to annotation errors in the training set. we finally apply the method to learning and classifying challenging action classes in movies and show promising results.
the initiation of drug therapy results in a reduction in the human immunodeficiency virus type 1 (hiv-1) population, which represents a potential genetic bottleneck. the effect of this drug-induced genetic bottleneck on the population dynamics of the envelope (env) regions has been addressed in several in vivo studies. however, it is difficult to investigate the effect on the env gene of the genetic bottleneck induced not only by entry inhibitors but also by non-entry inhibitors, particularly in vivo. therefore, this study used an in vitro selection system using unique bulk primary isolates established in the laboratory to observe the effects of the antiretroviral drug-induced bottleneck on the integrase and env genes. env diversity was decreased significantly in one primary isolate [kp-1, harbouring both cxcr4 (x4)- and ccr5 (r5)-tropic variants] when passaged in the presence or absence of raltegravir (ral) during in vitro selection. furthermore, the ral-selected kp-1 variant had a completely different env sequence from that in the passage control (particularly evident in the gp120, v1/v2 and v4-loop regions), and a different number of potential n-glycosylation sites. a similar pattern was also observed in other primary isolates when using different classes of drugs. this is the first study to explore the influence of anti-hiv drugs on bottlenecks in bulk primary hiv isolates with highly diverse env sequences using in vitro selection. it has been reported that the addition of a potential n-linked glycosylation site (pngs) to the gp120 human immunodeficiency virus type 1 (hiv-1) envelope glycoprotein provides protection against neutralizing antibodies (nabs) by acting as a 'glycan shield'. in this study, we induced insertion of a pngs into the v2 region of hiv-1(bal) with the kd-247 anti-v3 neutralizing monoclonal antibody. in the presence of kd-247 (200 microg ml(-1)) at passage five, viruses with 3 aa mutations in the c2 (t240s and i283t) and v3 (t319a) regions expanded from pre-existing variants. after six passages with kd-247 (>300 microg ml(-1)), a pngs emerged in the v2 region in addition to c2 (t240s) and v3 mutations (r315k and f317l). a variant with a pngs insertion in v2, but no v3 mutations was sensitive to kd-247, whereas a clone with a v2 pngs insertion and mutations in v3 demonstrated a high level of resistance to kd-247. replication kinetic analysis revealed that the f317l mutation in v3 played a compensatory role for fitness-loss caused by the pngs insertion in v2. the evading hiv-1 variant did not revert back to the wild-type virus after 14 passages without kd-247. these findings demonstrate that the virus with fitness-loss mutations can replicate equally as well as the wild-type virus to acquire some key mutations in the v3 stem and the c2 region, and the compensated variants containing pngs do not revert back to the ancestral virus even in the absence of nab.
repeat unit length variation and internal transcribed spacer (its) sequences of nuclear ribosomal dna were used to assess genetic diversity, and phylogenetic relationships in chickpea (c. arietinum) cultivars, and its related wild species. total genomic dnas of 76 accessions of 10 cicer species, belonging to three sections of the genus, were restricted with seven enzymes and the restriction fragments were hybridized to heterologous ribosomal clones of wheat pta71 and vicia faba probes ver 6-5 and ver18-6. a single repeat unit length class of 11.4 kb or 10.5 kb was recognized across cicer accessions with pta71. the intraspecific variation was negligible in those species where more than one accession was studied, except the four c. judaicum accessions, which were different from the rest. ecori and drai digests gave two and one-two fragments, respectively. all the accessions produced three and three-five bands with bamhi and saci, respectively. both the accessions of c. yamashitae differed in their rdna repeat unit length as well as restriction site variation. maximum likelihood tree with rdna rflp recognized five clades which were more or less congruent with the previous data. length of its-1 region was more variable (235–239 bp) than the its-2 region (212–213 bp). cladistic analysis of its data revealed two major clades, clade i consisting of c. arietinum, c. reticulatum and c. echinospermum, and clade ii comprised of c. judaicum, c. chorassanicum, c. bijugum and c. cuneatum. c. microphyllum grouped with the above four species. c. pinnatifidum was present as a separate branch. c. yamashitae emerged as the most distinct species. molecular phylogeny based on internal transcribed spacer (its) sequences was studied to resolve the taxonomic contradiction in vigna and its relation to phaseolus. the its region of the 18s-26s nuclear ribosomal dna repeat was sequenced for 29 vigna species, selected from five of the nine subgenera, and 9 species of phaseolus. the length of its-1 ranged from 187 to 243 bp and 217 to 290 bp, and that of its-2 from 187 to 219 bp and 225 to 243 bp, within vigna and phaseolus species, respectively. phylogenies derived from its sequences based on maximum-parsimony and neighbor-joining methods gave trees essentially of similar topology. the its phylogeny was generally congruent with recent classifications based largely on morphological, biochemical, cytogenetical, and palynological features, except that subgenus plectotropis of neotropical origin was revealed to be closely related to subgenus vigna instead of forming a link between african (subgenus vigna) and asiatic (subgenus ceratotropis) vignas, and subgenus sigmoidotropis, featuring morphological characters of both vigna and phaseolus, was placed as the sister group to the phaseolus taxa. the its sequences were shown to be useful for identifying wild progenitors of v. mungo, v. radiata, v. umbellata, and v. unguiculata and for clarifying taxonomy-related problems in many previously controversial cases. this study also affirms that v. umbellata and v. angularis are the diploid progenitors of the only tetraploid species (v. glabrescens) known in the genus.
we applied an extensive data set from 211 locations along austrian rivers to assess community structure and the ratios of functional feeding groups of benthic macroinvertebrates. a total of 569 taxa have been identified. at the catchment scale, the enns, salzach, and traun rivers exhibited the highest taxa richness whereas the inn river showed the lowest richness. beta-diversity was highest along the impounded and fragmented enns and drau rivers. consequently, high corridor diversity corresponded to a low degree of nestedness. overall, scrapers and gathering-collectors dominated the benthic community. further, the relationship between habitat conditions and metrics based on functional feeding groups were statistically analyzed to validate the potential of these metrics as indicators of ecosystem attributes. we examined four major ecosystem attributes: species diversity, material cycling, longitudinal material transport, and lateral material input. multiple regression analyses for midorder rivers demonstrated that metrics were significantly related to habitat conditions. for example, the metric set indicating primary production was positively correlated with periphyton cover, dissolved oxygen, dominant sediment size, and average annual discharge. overall, most metrics exhibited unique responses to habitat conditions, implying that they are useful proxies of ecosystem attributes. thus, a function-based approach based on macroinvertebrates has the potential to become an effective tool for the assessment of river ecosystems. an exact expression is given for the jackknife estimate of the number of species in a community and for the variance of this number when quadrat sampling procedures are used. the jackknife estimate is a function of the number of species that occur in one and only one quadrat. the variance of the number of species can be constructed, as can approximate two-sided confidence intervals. the behavior of the jackknife estimate, as affected by quadrat size, sample size and sampling area, is investigated by simulation.
developing seeds are expected to be strongly defended against microbial attack. in keeping with this, only 26% of seeds of centaurea stoebe from its native and invaded ranges in eurasia and north america were infected with fungi, and 92.2% of those were infected with a single fungus per seed. even when developing seeds in flower heads were inoculated under conducive conditions for infection with 14 of these seed-infecting fungi, re-isolation of inoculants was only 16% overall, and again limited to the particular inoculant. environmental fungi (i.e. those not isolated from seed of c. stoebe) were present in control flower heads under conditions conducive to infection but they were never re-isolated from fully developed seeds in any experiments. when two or three seed isolates were co-inoculated to compete in flower heads, only one inoculant, and always the same one, was re-isolated from all matured seeds, regardless of maternal plant genotype. pcr-based detection methods confirmed that these fungal interactions were exclusionary rather than suppressive. in these strongly defended, developing seeds, we had expected the plant to control not only the overall level of infection but also the outcome of co-inoculations. consequences for the next plant generation of this exclusionary competition among seed-infecting fungi included effects on seedling emergence, growth and fecundity. fungal endophytes are important in plant ecology and common in plants. we attempted to test cointroduction and host-jumping hypotheses on a community basis by comparing endophytes isolated from invasive spotted knapweed (centaurea stoebe, asteraceae) in its native and invaded ranges. of 92 combined, sequence-based haplotypes representing eight classes of fungi, 78 occurred in only one of the two ranges. in the native range of c. stoebe, one haplotype of alternaria alternata was clearly dominant, whereas in the invaded range, no haplotype was dominant. many haplotypes were closely related to one another and novel. for example, six putative, new species of botrytis were discovered as endophytes of c. stoebe, which has never been reported to have botrytis spp.. apparent differences between the two communities of endophytes were significant according to an analysis of similarity, but phylogenetic community structure did not differ significantly between the ranges. both host-jumping and cointroduction of fungal endophytes likely took place during the spotted knapweed invasion.
purpose:castration therapy adjuvant to radiotherapy can significantly improve overall survival compared with radiotherapy alone in patients with locally advanced prostate cancer. although many of the adverse effects of castration therapy are manageable, they can have a detrimental effect on quality of life. here we evaluate the efficacy and tolerability of the non-castration-based therapy bicalutamide (‘casodex’) 150 mg adjuvant to radiotherapy in patients with t1-4, m0, any n prostate cancer.methods:the subset of patients within the early prostate cancer (epc) program who received radiotherapy with curative intent (n = 1,370) were included in the analysis. these patients were randomized to receive oral bicalutamide 150 mg once daily (n = 699) or placebo (n = 671).results:the median follow-up for patients included in this analysis was 7.2 years. in patients with locally advanced disease (n = 305), bicalutamide adjuvant to radiotherapy significantly improved: progression-free survival (pfs), reducing the risk of objective progression by 44% compared with radiotherapy alone [hazard ratio (hr) 0.56; 95% confidence interval (ci) 0.40, 0.78; p < 0.001). prostate-specific antigen (psa)–pfs, reducing the risk of psa progression by 59% compared with radiotherapy alone (hr 0.41; 95% ci 0.30, 0.55; p < 0.001). overall survival, reducing the risk of death by 35% compared with radiotherapy alone (hr 0.65; 95% ci 0.44, 0.95; p = 0.03). this significant overall survival benefit for bicalutamide was driven by a lower risk of prostate cancer-related deaths (16.1 vs 24.3%, respectively). there was no significant difference in pfs or overall survival in patients with localized disease (n = 1,065).conclusions:in patients with locally advanced disease, bicalutamide 150 mg adjuvant to radiotherapy demonstrates significant clinical benefits in terms of overall survival, pfs and psa–pfs compared with radiotherapy alone. the overall survival benefit in these patients is consistent with prior studies evaluating castration-based therapies adjuvant to radiotherapy (bolla et al. in lancet 360:103–108, 2002; pilepich et al. in int j radiat oncol biol phys 61:1285–1290, 2005). in addition, the clinical benefit of bicalutamide 150 mg in locally advanced patients, but not in those with localized disease, is consistent with the overall results from the epc program (mcleod et al. bju int 97:247–254, 2006). given the quality-of-life advantages of bicalutamide relative to castration, bicalutamide 150 mg adjuvant to radiotherapy is an attractive alternative for men with locally advanced prostate cancer. to evaluate, in the ongoing early prostate cancer (epc) trial programme, the efficacy and tolerability of bicalutamide 150 mg once daily in addition to standard care for localized or locally advanced, nonmetastatic prostate cancer.
worldwide more than 400 plant species are now known that hyperaccumulate various trace metals (cd, co, cu, mn, ni, and zn), metalloids (as) and nonmetals (se) in their shoots. of these, almost one-quarter are brassicaceae family members, including numerous thlaspi species that hyperaccumulate ni up to 3% of there shoot dry weight. we observed that concentrations of glutathione, cys, and o-acetyl-l-serine (oas), in shoot tissue, are strongly correlated with the ability to hyperaccumulate ni in various thlaspi hyperaccumulators collected from serpentine soils, including thlaspi goesingense, t. oxyceras, and t. rosulare, and nonaccumulator relatives, including t. perfoliatum, t. arvense, and arabidopsis thaliana. further analysis of the austrian ni hyperaccumulator t. goesingense revealed that the high concentrations of oas, cys, and gsh observed in this hyperaccumulator coincide with constitutively high activity of both serine acetyltransferase (sat) and glutathione reductase. sat catalyzes the acetylation of l-ser to produce oas, which acts as both a key positive regulator of sulfur assimilation and forms the carbon skeleton for cys biosynthesis. these changes in cys and gsh metabolism also coincide with the ability of t. goesingense to both hyperaccumulate ni and resist its damaging oxidative effects. overproduction of t. goesingense sat in the nonaccumulator brassicaceae family member arabidopsis was found to cause accumulation of oas, cys, and glutathione, mimicking the biochemical changes observed in the ni hyperaccumulators. in these transgenic arabidopsis, glutathione concentrations strongly correlate with increased resistance to both the growth inhibitory and oxidative stress induced effects of ni. taken together, such evidence supports our conclusion that elevated gsh concentrations, driven by constitutively elevated sat activity, are involved in conferring tolerance to ni-induced oxidative stress in thlaspi ni hyperaccumulators. copper tolerance among arabidopsis ecotypes is inversely correlated with long-term k(+) leakage and positively correlated with short-term k(+) leakage (a. murphy, l. taiz [1997] new phytol 136: 211-222). to probe the mechanism of the early phase of k(+) efflux, we tested various channel blockers on copper and peroxide-induced k(+) efflux from seedling roots. the k(+) channel blockers tetraethyl ammonium chloride and 4-aminopyridine (4-ap) both inhibited short-term copper-induced k(+) efflux. in contrast, peroxide-induced k(+) efflux was insensitive to both tetraethyl ammonium chloride and 4-ap. copper-induced lipid peroxidation exhibited a lag time of 4 h, while peroxide-induced lipid peroxidation began immediately. these results suggest that short-term copper-induced k(+) efflux is mediated by channels, while peroxide-induced k(+) efflux represents leakage through nonspecific lesions in the lipid bilayer. tracer studies with (86)rb(+) confirmed that copper promotes k(+) efflux rather than inhibiting k(+) uptake. short-term k(+) release is electroneutral, since electrophysiological measurements indicated that copper does not cause membrane depolarization. short-term k(+) efflux was accompanied by citrate release, and copper increased total citrate levels. since citrate efflux was blocked by 4-ap, k(+) appears to serve as a counterion during copper-induced citrate efflux. as copper but not aluminum selectively induces citrate production and release, it is proposed that copper may inhibit a cytosolic form of aconitase.
supervised machine learning is a branch of artificial intelligence concerned with learning computer programs to automatically improve with experience through knowledge extraction from examples. it builds predictive models from labeled data. such learning approaches are useful for many interesting real-world applications, but are particularly useful for tasks involving the automatic categorization, retrieval and extraction of knowledge from large collections of data such as text, images and videos. in traditional supervised learning, one uses ”labeled” data to build a model. however, labeling the training data for real-world applications is difficult, expensive, or time consuming, as it requires the effort of human annotators sometimes with specific domain experience and training. there are implicit costs associated with obtaining these labels from domain experts, such as limited time and financial resources. this is especially true for applications that involve learning with large number of class labels and sometimes with similarities among them. semi-supervised learning (ssl) addresses this inherent bottleneck by allowing the model to integrate part or all of the available unlabeled data in its supervised learning. the goal is to maximize the learning performance of the model through such newly-labeled examples while minimizing the work required of human annotators. exploiting unlabeled data to help improve the learning performance has become a hot topic during the last decade and it is divided into four main directions: ssl with graphs, ssl with generative models, semi-supervised support vector machines and ssl by disagreement (ssl with committees). it is interesting to see that semi-supervised learning and ensemble learning are two important paradigms that were developed almost in parallel and with different philosophies. semi-supervised learning tries to improve generalization performance by exploiting unlabeled data, while ensemble learning tries to achieve the same objective by using multiple predictors. in this thesis, i concentrate on ssl by disagreement and especially on cotraining style algorithms. co-training is a popular ssl algorithm introduced by this paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents. this is important because in many text classification problems obtaining training labels is expensive, while large quantities of unlabeled documents are readily available.we introduce an algorithm for learning from labeled and unlabeled documents based on the combination of expectation-maximization (em) and a naive bayes classifier. the algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents. it then trains a new classifier using the labels for all the documents, and iterates to convergence. this basic em procedure works well when the data conform to the generative assumptions of the model. however these assumptions are often violated in practice, and poor performance can result. we present two extensions to the algorithm that improve classification accuracy under these conditions: (1) a weighting factor to modulate the contribution of the unlabeled data, and (2) the use of multiple mixture components per class. experimental results, obtained using text from three different real-world tasks, show that the use of unlabeled data reduces classification error by up to 30%.
we present an approach to feature weight optimization for document-level decoding. this is an essential task for enabling future development of discourse-level statistical machine translation, as it allows easy integration of discourse features in the decoding process. we extend the framework of sentence-level feature weight optimization to the document-level. we show experimentally that we can get competitive and relatively stable results when using a standard set of features, and that this framework also allows us to optimize documentlevel features, which can be used to model discourse phenomena. we collected a corpus of parallel text in 11 languages from the proceedings of the european parliament, which are published on the web1. this corpus has found widespread use in the nlp community. here, we focus on its acquisition and its application as training data for statistical machine translation (smt). we trained smt systems for 110 language pairs, which reveal interesting clues into the challenges ahead.
alpha-synuclein gene (snca) polymorphisms have been associated with the common sporadic form of parkinson’s disease (pd). we searched for dna variants at the snca 3′ utr through single strand conformation analysis and direct sequencing in a cohort of spanish pd patients and controls. we have genotyped the rs356165 snca 3′ utr polymorphism in a total of 1,135 pd patients and 772 healthy controls from two spanish cohorts (asturias and navarre). we identified six snca 3′ utr variants. single nucleotide polymorphism (snp) rs356165 was significantly associated with pd risk in the spanish cohort (p = 0.0001; odd ratio = 1.37, 95%ci = 1.19–1.58). this snp was also significantly associated with early age at onset of pd. our work highlights rs356165 as an important determinant of the risk of developing pd and early age at onset and encourages future research to identify a functional effect on snca expression. few detailed clinico-pathological correlations of parkinson's disease have been published. the pathological findings in 100 patients diagnosed prospectively by a group of consultant neurologists as having idiopathic parkinson's disease are reported. seventy six had nigral lewy bodies, and in all of these lewy bodies were also found in the cerebral cortex. in 24 cases without lewy bodies, diagnoses included progressive supranuclear palsy, multiple system atrophy, alzheimer's disease, alzheimer-type pathology, and basal ganglia vascular disease. the retrospective application of recommended diagnostic criteria improved the diagnostic accuracy to 82%. these observations call into question current concepts of parkinson's disease as a single distinct morbid entity.
background their large scaffold diversity and properties, such as structural complexity and drug similarity, form the basis of claims that natural products are ideal starting points for drug design and development. consequently, there has been great interest in determining whether such molecules show biological activity toward protein targets of pharmacological relevance. one target of particular interest is hikk-2, a serine-threonine protein kinase belonging to the ikk complex that is the primary component responsible for activating nf-κb in response to various inflammatory stimuli. indeed, this has led to the development of synthetic atp-competitive inhibitors for hikk-2. therefore, the main goals of this study were (a) to use virtual screening to identify potential hikk-2 inhibitors of natural origin that compete with atp and (b) to evaluate the reliability of our virtual-screening protocol by experimentally testing the in vitro activity of selected natural-product hits. methodology/principal findings we thus predicted that 1,061 out of the 89,425 natural products present in the studied database would inhibit hikk-2 with good admet properties. notably, when these 1,061 molecules were merged with the 98 synthetic hikk-2 inhibitors used in this study and the resulting set was classified into ten clusters according to chemical similarity, there were three clusters that contained only natural products. five molecules from these three clusters (for which no anti-inflammatory activity has been previously described) were then selected for in vitro activity testing, in which three out of the five molecules were shown to inhibit hikk-2. conclusions/significance we demonstrated that our virtual-screening protocol was successful in identifying lead compounds for developing new inhibitors for hikk-2, a target of great interest in medicinal chemistry. additionally, all the tools developed during the current study (i.e., the homology model for the hikk-2 kinase domain and the pharmacophore) will be made available to interested readers upon request. we have recently identified bms-345541 (1) as a highly selective and potent inhibitor of ikk-2 (ic50 = 0.30 microm), which however was considerably less potent against ikk-1 (ic50 = 4.0 microm). in order to further explore the sar around the imidazoquinoxaline tricyclic structure of 1, we prepared a series of tetracyclic analogues (7, 13, and 18). the synthesis and biological activities of these potent ikk inhibitors are described.
the enormous services obtainable by bank and postal systems are not 100 % guaranteed due to variability of handwriting styles. various methods based on neural networks have been suggested to address this issue. unfortunately, they often fall into local optima that arises from the use of old learning methods. global optimization methods provided new directions for neural networks evolution that may be useful in recognition. this paper develops efficient algorithms that compute globally optimal solutions by exploiting the benefits of both swarm intelligence and neuro-evolution in a way to improve the overall performance of a character recognition system. various adaptations implied to both mlp and rbf networks have been suggested namely: particle swarm optimization (pso) and the bees algorithm (ba) for characters classification, mlp training or rbf design by co-evolution and effective combinations of mlps, rbfs or svms as an attempt to overcome the drawbacks of old recognition methods. results proved that networks combination proposals ensure the highest improvement compared to either standard mlp and rbf networks, the co-evolutionary alternatives or other classifiers combination based on common combination rules namely majority voting, the fusion rules of min, max, sum, average, product and bayes, decision template and the behavior knowledge space (bks). in this paper, we analyze the performance of a classifier ensemble consisting of small-sized neural networks for accurate and fast learning. to this end, three topologies of neural networks are evaluated: the multilayer perceptron with two different configurations in the hidden layer, and the modular neural network. the experiments here carried out illustrate the effectiveness of the ensembles of neural networks in terms of average predictive accuracy and processing time, as compared to the single classifiers.
dichloromethane (dcm) dehalogenase converts dcm to formaldehyde via the formation of glutathione metabolites and generates 2 mol hcl per mol dcm metabolized. growth of escherichia coli expressing dcm dehalogenase was immediately and severely inhibited during conversion of 0.3 mm dcm. intracellular ph (ph(i)) rapidly decreased and chloride ions were steadily released into the medium. bacterial growth resumed after completion of dcm conversion and cell viability was unaffected. at 0.6 mm dcm there was no recovery from growth inhibition in liquid culture due to the build-up of inhibitory concentrations of formaldehyde. dcm turnover stimulated potassium efflux from cells, which was suppressed by glucose. the potassium efflux, therefore, did not contribute to growth inhibition. it was concluded that initial growth inhibition results from lowering of the cytoplasmic ph, but severity of growth inhibition was greater than expected for the change in ph(i). possible contributors to growth inhibition are discussed. abstract the kinetic properties of bacterial and rat liver glutathione s-transferases (gst) active with dichloromethane (dcm) were compared. the theta class glutathione s-transferase (rgstt1-1) from rat liver had an affinity for dihalomethanes lower by three orders of magnitude (kapp > 50 mm) than the bacterial dcm dehalogenase/gst from methylophilus sp. dm11. unlike the bacterial dcm dehalogenase, the rat enzyme was unable to support growth of the dehalogenase minus methylobacterium sp. dm4-2cr mutant with dcm. moreover, the presence of dcm inhibited growth with methanol of the dm4-2cr transconjugant expressing the rat liver gstt1-1. in salmonella typhimurium ta1535, expression of rat and bacterial dcm-active gst from a plasmid in the presence of dcm yielded up to 5.3 times more reversions to histidine prototrophy in the transconjugant expressing the rat enzyme. under the same conditions, however, gst-mediated conversion of dcm to formaldehyde was lower in cell-free extracts of the transconjugant expressing the rat gstt1 than in the corresponding strain expressing the bacterial dcm dehalogenase. this provided new evidence that formaldehyde was not the main toxicant associated with gst-mediated dcm conversion, and indicated that an intermediate in the transformation of dcm by gst, presumably s-chloromethylglutathione, was responsible for the observed effects. the marked differences in substrate affinity of rat and bacterial dcm-active gst, as well as in the toxicity and genotoxicity associated with expression of these enzymes in bacteria, suggest that bacterial dcm dehalogenases/gst have evolved to minimise the toxic effects associated with glutathione-mediated catalysis of dcm conversion.
pancreatic adenocarcinoma is the fourth leading cause of cancer death in the united states. it is identified by its rapid, invasive progression with a profound resistance to treatments such as chemotherapy. unfortunately, there is a lack of information on how to effectively inhibit and control the rapid growth of pancreatic tumors, as well as limited information for diagnostics. with current methods, pancreatic cancer will continue to prevail as a leading cause of cancer death. we propose to study the complexity of pancreatic tumors with a systematic and analytical approach. cancer is an abnormal growth of tissue caused by uncontrolled cell division. observing the growth of these cells would prove to have a good basis to monitor the growth of a tumor. here we create a 3-d simulation of tumor growth through mathematical modeling, using data from pancreatic cells grown in vitro. using 3-d models will help to understand pancreatic tumors at cellular and molecular levels. the project aims to observe realistic growth of the tumor, accomplished from growing tumor cells on a monolayer in order to find parameters for our 3d mathematical model. this method will prove more beneficial than testing only on a monolayer cell line. although cell death and the toxicity of drug dosage can be tested using a cell monolayer alone, it does not meet the demands of testing drug delivery in a realistic tumor environment that the mathematical model would provide. the monolayer lacks the dimensions that the drug would have to travel if it were delivered to a real in vivo tumor. a possible continuation of this project in the future could be to utilize the mathematical based approach to predict optimal therapy for the pancreatic tumor in order to develop models that can better test patient care for tumors. computer modeling, another stepping stone through mathematical modeling, will possibly lead to testing the toxic effects of drugs on a 3-d model through computer modeling will aid in understanding the delivery of drugs throughout the tumor in vivo. abstract we study solid tumor (carcinoma) growth in the nonlinear regime using boundary-integral simulations. the tumor core is nonnecrotic and no inhibitor chemical species are present. a new formulation of the classical models [18,24,8,3] is developed and it is demonstrated that tumor evolution is described by a reduced set of two dimensionless parameters and is qualitatively unaffected by the number of spatial dimensions. one parameter describes the relative rate of mitosis to the relaxation mechanisms (cell mobility and cell-to-cell adhesion). the other describes the balance between apoptosis (programmed cell-death) and mitosis. both parameters also include the effect of vascularization. our analysis and nonlinear simulations reveal that the two new dimensionless groups uniquely subdivide tumor growth into three regimes associated with increasing degrees of vascularization: low (diffusion dominated, e.g., in vitro), moderate and high vascularization, that correspond to the regimes observed in vivo. we demonstrate that critical conditions exist for which the tumor evolves to nontrivial dormant states or grows self-similarly (i.e., shape invariant) in the first two regimes. this leads to the possibility of shape control and of controlling the release of tumor angiogenic factors by restricting the tumor volume-to-surface-area ratio. away from these critical conditions, evolution may be unstable leading to invasive fingering into the external tissues and to topological transitions such as tumor breakup and reconnection. interestingly we find that for highly vascularized tumors, while they grow unbounded, their shape always stays compact and invasive fingering does not occur. this is in agreement with recent experimental observations [30] of in vivo tumor growth, and suggests that the invasive growth of highly-vascularized tumors is associated to vascular and elastic anisotropies, which are not included in the model studied here.
reordering models are one of essential components of statistical machine translation. in this paper, we propose a topic-based reordering model to predict orders for neighboring blocks by capturing topic-sensitive reordering patterns. we automatically learn reordering examples from bilingual training data, which are associated with document-level and word-level topic information induced by lda topic model. these learned reordering examples are used as evidences to train a topic-based reordering model that is built on a maximum entropy (maxent) classifier. we conduct large-scale experiments to validate the effectiveness of the proposed topic-based reordering model on the nist chinese-to-english translation task. experimental results show that our topic-based reordering model achieves significant performance improvement over the conventional reordering model using only lexical information. statistical machine translation systems are usually trained on a large amount of bilingual sentence pairs and translate one sentence at a time, ignoring document-level information. in this paper, we propose a cache-based approach to document-level translation. since caches mainly depend on relevant data to supervise subsequent decisions, it is critical to fill the caches with highly-relevant data of a reasonable size. in this paper, we present three kinds of caches to store relevant document-level information: 1) a dynamic cache, which stores bilingual phrase pairs from the best translation hypotheses of previous sentences in the test document; 2) a static cache, which stores relevant bilingual phrase pairs extracted from similar bilingual document pairs (i.e. source documents similar to the test document and their corresponding target documents) in the training parallel corpus; 3) a topic cache, which stores the target-side topic words related with the test document in the source-side. in particular, three new features are designed to explore various kinds of document-level information in above three kinds of caches. evaluation shows the effectiveness of our cache-based approach to document-level translation with the performance improvement of 0.81 in blue score over moses. especially, detailed analysis and discussion are presented to give new insights to document-level translation.
several features of bird basilar papilla morphology were quantitatively studied in the starling and the pigeon in order to attempt a structure-function correlation. we confirmed and quantified several findings from earlier studies, but also obtained results contradictory to previous reports. the greatest discrepancies concerned the pattern of hair cell orientation. by including the results from other investigations, we describe a 'typical' avian basilar papilla and on this basis the specializations within individual species. these morphological specializations are discussed in the context of the available physiological data. the basilar papilla of the barn owl's (tyto alba) cochlea was found to be 9.5-11.5 mm long. histological examination revealed that the sensory hair cells had a characteristic distribution: the proximal half contained mostly typical short cells; tall hair cells were present only on the distal half along with many short cells. lenticular short cells occupied the proximal tip of the papilla. another unusual feature of the proximal part was a dense fibrous mass in the basilar membrane. this was absent from the distal one-fourth.
chromatin immunoprecipitation coupled with massive parallel sequencing (chip-seq) is a powerful technology to identify the genome-wide locations of dna binding proteins such as transcription factors or modified histones. as more and more experimental laboratories are adopting chip-seq to unravel the transcriptional and epigenetic regulatory mechanisms, computational analyses of chip-seq also become increasingly comprehensive and sophisticated. in this article, we review current computational methodology for chip-seq analysis, recommend useful algorithms and workflows, and introduce quality control measures at different analytical steps. we also discuss how chip-seq could be integrated with other types of genomic assays, such as gene expression profiling and genome-wide association studies, to provide a more comprehensive view of gene regulatory mechanisms in important physiological and pathological processes. recent progress in massively parallel sequencing platforms has enabled genome-wide characterization of dna-associated proteins using the combination of chromatin immunoprecipitation and sequencing (chip-seq). although a variety of methods exist for analysis of the established alternative chip microarray (chip-chip), few approaches have been described for processing chip-seq data. to fill this gap, we propose an analysis pipeline specifically designed to detect protein-binding positions with high accuracy. using previously reported data sets for three transcription factors, we illustrate methods for improving tag alignment and correcting for background signals. we compare the sensitivity and spatial precision of three peak detection algorithms with published methods, demonstrating gains in spatial precision when an asymmetric distribution of tags on positive and negative strands is considered. we also analyze the relationship between the depth of sequencing and characteristics of the detected binding positions, and provide a method for estimating the sequencing depth necessary for a desired coverage of protein binding sites.
backgroundprevious studies have reported that selective serotonin reuptake inhibitors (ssris) might improve sleep-related breathing disorders (srbds). however, the effects of ssris on breathing are not evaluated in subjects without moderate-to-severe srbds. further, many symptoms of depression and srbds overlap, and so, it is interesting whether there are interactions between breathing and psychopathologic symptoms during ssri treatment for depression.methodsdata were taken from an open-label 8-week trial of sertraline in depressed patients with insomnia (n = 31). the depressed patients were administered 50 mg sertraline at 8 am on the first day, and the dosage was subsequently titrated up to a maximum of 200 mg/day during the 8-week trial. all the patients were tested by repeated polysomnography (psg) (baseline, 1st day, 14th day, 28th day, and 56th day). sleep-disordered breathing events were categorized as apneas, hypopneas, and respiratory event-related arousals (reras).resultsthe clinical responses and psg characteristics improved continuously during the 8-week trial. from the 14th day on, the rera index during all-night and non-rapid eye movement (nrem) sleep became stable and significantly higher than baseline and the first day (rera index 7.3 ± 2.2 at baseline, 7.3 ± 2.5 on the 1st day, 4.4 ± 1.9 on the 14th day, 3.9 ± 1.3 on the 28th day, 4.2 ± 2.0 on the 56th day, f = 5.71, p = 0.02; nrem-rera index 6.2 ± 2.0 at baseline, 6.3 ± 2.3 on the 1st day, 3.2 ± 1.5 on the 14th day, 3.5 ± 0.9 on the 28th day, 3.2 ± 1.7 on the 56th day, f = 4.92, p = 0.03). additionally, the nrem-apnea index showed a similar pattern to that of the rera index and reached a significant difference between baseline (1.0 ± 0.5) and the 14th day (0.5 ± 0.4) (kw = 4.28, p = 0.047). compared to the no-improvement group, the improvement group with a decreasing score rate of the respiratory disturbance index (rdi) greater than or equal to −50 % had a more positive decreasing score rate of slow wave sleep (sws) (439.0 ± 78.2 vs 373.2 ± 77.9 %, t = 3.46, p = 0.04) and a more negative decreasing score rate on the arousal index (−43.7 ± 16.7 vs −26.6 ± 9.7 %, t = 9.16, p = 0.01), pittsburgh sleep quality index (psqi) scores (−65.1 ± 33.7 vs −49.6 ± 21.4 %, t = 4.74, p = 0.05), and epworth sleepiness scale (ess) scores (−55.7 ± 21.3 vs −36.4 ± 17.5 %, t = 6.44, p = 0.02).discussionthis research indicates that srbds could be improved to some extent by sertraline treatment, which might be more common in patients with relatively more severe sleep-disordered breathing (e.g., rdi ≥ 10 in the current study). although the sertraline-induced srbd improvement seems not to have a significant clinical effect, the srbd improvement group with decreasing score rate of rdi greater than or equal to −50 % has better subjective and objective sleep aspects than the no-improvement group. thus, the fact that the srbds’ improvement was related to ssris might have a potential clinical benefit in the antidepressant treatment. background previous studies have reported that selective serotonin reuptake inhibitors (ssris) might induce or exacerbate periodic limb movements during sleep (plms). however, most of these studies were retrospective and cross-sectional studies with small sample sizes on a selective ssri, fluoxetine. because different ssris have different pharmacologic profiles, it was not certain if other ssris also might lead to plms.   methods data were taken from an open-label 8-week trial of sertraline in depressive patients with insomnia (n=31). depressed patients were administered sertraline 50mg at 8:00am on the first day, and the dosage was subsequently titrated up to a maximum of 200mg daily during the 8-week trial. all participants were tested by repeated polysomnography (psg) (baseline, first day, 14th day, 28th day, and 56th day). periodic leg movements (plm) were visually counted and the plm index (plmi) was calculated. plms was defined as plmi ⩾5, and significant plms was defined as plmi ⩾15.   results compared with baseline (plmi, 3.6±1.5), all plmi indices increased on the immediate administration of sertraline on the first day (plmi, 5.1±3.9). from the 14th day onward, plmi became stable and significantly higher than baseline and the first day (8.7±3.1 on the 14th day, 8.3±3.7 on the 28th day, and 8.5±3.6 on the 56th day; f[11.81]; p=.003). the clinical responses and psg characteristics continuously improved during the 8-week trial. the plms group (plmi ⩾5) had a higher arousal index (ai) than the non-plms group on the 14th day (9.4±5.5 vs 5.2±3.7; t test, 4.22; p=.03) and the 56th day (8.1±5.5 vs 4.3±3.7; z score, 3.11; p=.04); albeit, there was no significant clinical disturbances in the plms group.   conclusions plms were increased during sertraline treatment, but only a few of the plms reached the significant level. this effect of sertraline on plms might be dosage dependent. although the sertraline-induced plms did not seem to cause significant clinical disturbance, the plms group (plmi ⩾5) had a higher ai than the non-plms group. thus clinicians should pay more attention to plms during ssri antidepressant treatment.
we quantified the potential effects of physiologic artifact on the estimation of eeg band power in a cohort of typically developing children in order to guide artifact rejection methods in quantitative eeg data analysis in developmental populations. high density eeg was recorded for 2 min while children, ages 2–6, watched a video of bubbles. segments of data were categorized as blinks, saccades, emg or artifact-free, and both absolute and relative power in the theta (4–7 hz), alpha (8–12 hz), beta (13–30 hz) and gamma (35–45 hz) bands were calculated in 9 regions for each category. using a linear mixed model approach with artifact type, region and their interaction as predictors, we compared mean band power between clean data and each type of artifact. we found significant differences in mean relative and absolute power between artifacts and artifact-free segments in all frequency bands. the magnitude and direction of the differences varied based on power type, region, and frequency band. the most significant differences in mean band power were found in the gamma band for emg artifact and the theta band for ocular artifacts. artifact detection strategies need to be sensitive to the oscillations of interest for a given analysis, with the most conservative approach being the removal of all emg and ocular artifact from eeg data. quantitative eeg holds considerable promise as a clinical biomarker of both typical and atypical development. however, there needs to be transparency in the choice of power type, regions of interest, and frequency band, as each of these variables are differentially vulnerable to noise, and therefore, their interpretation depends on the methods used to identify and remove artifacts. evoked potentials and eegs record punctate electrical activity at electrode sites. to represent the overall potential distribution on the entire scalp it is necessary to interpolate between these sampled values. surface splines are mathematical tools for interpolating functions of two variables. in comparison to the classical methods of interpolation, based on linear combination of the potentials of the 4 nearest electrodes, spline methods are smoother, give more precisely located extrema and converge faster toward the 'true' potential surface when the number of recording electrodes is increased. these advantages are at the expense of lengthier computation time.
background airway microbiota composition has been clearly correlated with many pulmonary diseases, and notably with cystic fibrosis (cf), an autosomal genetic disorder caused by mutation in the cf transmembrane conductance regulator (cftr). recently, a new molecule, ivacaftor, has been shown to re-establish the functionality of the g551d-mutated cftr, allowing significant improvement in lung function. objective and methods the purpose of this study was to follow the evolution of the airway microbiota in cf patients treated with ivacaftor, using quantitative pcr and pyrosequencing of 16s rrna amplicons, in order to identify quantitative and qualitative changes in bacterial communities. three g551d children were followed up longitudinally over a mean period of more than one year covering several months before and after initiation of ivacaftor treatment. results 129 operational taxonomy units (otus), representing 64 genera, were identified. there was no significant difference in total bacterial load before and after treatment. comparison of global community composition found no significant changes in microbiota. two otus, however, showed contrasting dynamics: after initiation of ivacaftor, the relative abundance of the anaerobe porphyromonas 1 increased (p<0.01) and that of streptococcus 1 (s. mitis group) decreased (p<0.05), possibly in relation to the anti-gram-positive properties of ivacaftor. the anaerobe prevotella 2 correlated positively with the pulmonary function test fev-1 (r=0.73, p<0.05). the study confirmed the presumed positive role of anaerobes in lung function. conclusion several airway microbiota components, notably anaerobes (obligate or facultative anaerobes), could be valuable biomarkers of lung function improvement under ivacaftor, and could shed light on the pathophysiology of lung disease in cf patients. summary the common approach to the multiplicity problem calls for controlling the familywise error rate (fwer). this approach, though, has faults, and we point out a few. a different approach to problems of multiple significance testing is presented. it calls for controlling the expected proportion of falsely rejected hypotheses -the false discovery rate. this error rate is equivalent to the fwer when all hypotheses are true but is smaller otherwise. therefore, in problems where the control of the false discovery rate rather than that of the fwer is desired, there is potential for a gain in power. a simple sequential bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. the use of the new procedure and the appropriateness of the criterion are illustrated with examples.
abstract the edinburgh cognitive and behavioural als screen (ecas) has been developed to assess cognition and behaviour in patients with amyotrophic lateral sclerosis (als). cognitive impairments of als-specific and als-non-specific functions can be determined using cut-off scores based on performance of healthy subjects. however, detailed analyses show that older healthy subjects perform worse than younger ones, whereas highly-educated individuals perform better than those with lower education levels. as a consequence, this study presents new age and education matched cut-off scores for the revised german/swiss-german version of the ecas based on the performance of 86 healthy subjects. abstract this study presents the edinburgh cognitive and behavioural als screen (ecas), developed for als patients with physical disability for use by health care professionals. the screen is designed to detect the specific profile of cognition and behaviour changes in als and to differentiate it from other disorders. forty-eight als patients (none with evident dementia), 40 healthy controls and 20 carers were recruited. the ecas, a 15–20-min screen, includes an als-specific score (executive functions and social cognition; fluency; language); an als non-specific score (memory; visuospatial functions); and a carer behaviour screen of five domains characteristic of frontotemporal dementia (ftd). data from healthy controls produced abnormality cut-offs of 77/100 als-specific score; 24/36 als non-specific score; 105/136 ecas total. twenty-nine percent of patients showed abnormal als-specific scores, and 6% also showed abnormal als non-specific scores. the most prevalent deficit occurred in language functions (35%) followed by executive functions and fluency (23% each). forty percent of carers reported behaviour change in at least one domain, while 15% met criteria for possible ftd. in conclusion, the ecas is an effective within-clinic assessment for als that determines the presence, severity and type of cognitive and/or behavioural changes, an essential first step to managing these symptoms.
it is difficult to measure rotational eye movement constantly from "almost black eyeball image" acquired under the condition that the brightness of an image content being watched by a user is very low or the condition that almost no light is irradiated from its surrounding environment. to solve this problem, the authors developed a new method for measuring rotational eye movement at high accuracy by enhancing the contrast in the image of the vessels on the white of the eyeball, with small blue led light irradiation as auxiliary light. in our evaluation experiment, the images of rotational eye movements were captured, and data on the vessel positions were obtained by both visual measurement and this system to evaluate the estimated error and processing speed. the result suggests that our proposed system is capable of measuring rotational eye movement with an average of estimated errors equal to or lower than 0.24 degrees, even with almost black eyeball image. algorithms developed by the author for recognizing persons by their iris patterns have now been tested in many field and laboratory trials, producing no false matches in several million comparison tests. the recognition principle is the failure of a test of statistical independence on iris phase structure encoded by multi-scale quadrature wavelets. the combinatorial complexity of this phase information across different persons spans about 249 degrees of freedom and generates a discrimination entropy of about 3.2 b/mm/sup 2/ over the iris, enabling real-time decisions about personal identity with extremely high confidence. the high confidence levels are important because they allow very large databases to be searched exhaustively (one-to-many "identification mode") without making false matches, despite so many chances. biometrics that lack this property can only survive one-to-one ("verification") or few comparisons. the paper explains the iris recognition algorithms and presents results of 9.1 million comparisons among eye images from trials in britain, the usa, japan, and korea.
recombination rates vary in intensity and location at the species, individual, sex and chromosome levels. despite the fundamental biological importance of this process, the selective forces that operate to shape recombination rate and patterns are unclear. domestication offers a unique opportunity to study the interplay between recombination and selection. in domesticates, intense selection for particular traits is imposed on small populations over many generations, resulting in organisms that differ, sometimes dramatically, in morphology and physiology from their wild ancestor. although earlier studies suggested increased recombination rate in domesticates, a formal comparison of recombination rates between domestic mammals and their wild congeners was missing. in order to determine broad-scale recombination rate, we used immunolabeling detection of mlh1 foci as crossover markers in spermatocytes in three pairs of closely related wild and domestic species (dog and wolf, goat and ibex, and sheep and mouflon). in the three pairs, and contrary to previous suggestions, our data show that contemporary recombination rate is higher in the wild species. subsequently, we inferred recombination breakpoints in sequence data for 16 genomic regions in dogs and wolves, each containing a locus associated with a dog phenotype potentially under selection during domestication. no difference in the number and distribution of recombination breakpoints was found between dogs and wolves. we conclude that our data indicate that strong directional selection did not result in changes in recombination in domestic mammals, and that both upper and lower bounds for crossover rates may be tightly regulated. analysis of diverse eukaryotes has revealed that recombination events cluster in discrete genomic locations known as hotspots. in humans, a zinc-finger protein, prdm9, is believed to initiate recombination in >40% of hotspots by binding to a specific dna sequence motif. however, the prdm9 coding sequence is disrupted in the dog genome assembly, raising questions regarding the nature and control of recombination in dogs. by analyzing the sequences of prdm9 orthologs in a number of dog breeds and several carnivores, we show here that this gene was inactivated early in canid evolution. we next use patterns of linkage disequilibrium using more than 170,000 snp markers typed in almost 500 dogs to estimate the recombination rates in the dog genome using a coalescent-based approach. broad-scale recombination rates show good correspondence with an existing linkage-based map. significant variation in recombination rate is observed on the fine scale, and we are able to detect over 4000 recombination hotspots with high confidence. in contrast to human hotspots, 40% of canine hotspots are characterized by a distinct peak in gc content. a comparative genomic analysis indicates that these peaks are present also as weaker peaks in the panda, suggesting that the hotspots have been continually reinforced by accelerated and strongly gc biased nucleotide substitutions, consistent with the long-term action of biased gene conversion on the dog lineage. these results are consistent with the loss of prdm9 in canids, resulting in a greater evolutionary stability of recombination hotspots. the genetic determinants of recombination hotspots in the dog genome may thus reflect a fundamental process of relevance to diverse animal species.
within the mitotic spindle, specific interactions between microtubules, chromosomes and numerous accessory proteins allow the generation of spatially regulated forces that bring about accurate chromosome segregation. generation of this proper spatial regulation requires that individual proteins be targeted to specific substructures within the spindle. for example, the kinesin-related protein cenp-e is targeted specifically to the corona fibers of kinetochores (yao et al., 1997) where its action is required during alignment of chromosomes at the metaphase plate (schaar et al., 1997; wood et al., 1997). in contrast, the protein numa (nuclear mitotic antigen) is concentrated at spindle poles where its activity appears to be required for the focused organization of microtubules (gaglio et al., 1995). the vertebrate mitotic spindle pole is a microtubuledependent region surrounding the centrioles and centrosome at each of the two ends of the bipolar mitotic spindle. numa, γtubulin and katanin are proteins whose localization define the spindle pole. numa associates exclusively with the microtubule-dependent spindle pole during mitosis and does not associate with interphase centrosomes (price and pettijohn, 1986; dionne et al., 1999). in contrast, localization of γ-tubulin to the interphase or mitotic centrosome does not require intact microtubules (khodjakov and rieder, 1999; stearns et al., 1991; zheng et al., 1991). however, localization of additional γ-tubulin that surrounds the centrosomes only during mitosis does require microtubules (mcnally and thomas, 1998; khodjakov and rieder, 1999). like numa, the sea urchin protein, katanin, is concentrated in a microtubule-dependent structure surrounding the γ-tubulin at the poles of embryonic spindles (mcnally et al., 1996). antibodies recognizing mammalian homologs of katanin also recognize large microtubule-dependent structures surrounding γ-tubulin foci at spindle poles in several cell types and, in addition, recognize a smaller microtubule-independent focus at the centrosome in some cell types (mcnally and thomas, 1998). sea urchin katanin severs microtubules in an atp-dependent manner in vitro (mcnally and vale, 1993) and is thought to be important in releasing microtubules from their centrosomal attachment points in vivo. indeed, microinjection of antibodies recognizing a vertebrate katanin homolog into neurons results in the accumulation of microtubules attached to the centrosome (ahmad et al., 1999), indicating that katanin-mediated microtubule severing is responsible for the release of microtubules from the neuronal centrosome. the concentration of katanin in mitotic spindle poles (mcnally and thomas, 1998) and the specific activation of katanin’s activity in mphase xenopus extracts (vale, 1991; mcnally and thomas, 1998) suggest that katanin may also sever microtubules from their centrosomal attachments during mitosis in non-neuronal cells. katanin’s localization in spindle poles may increase the efficiency of this centrosomal release reaction and thus allow 1623 journal of cell science 113, 1623-1633 (2000) printed in great britain © the company of biologists limited 2000 jcs1028 microtubules are dynamic structures whose proper rearrangement during the cell cycle is essential for the positioning of membranes during interphase and for chromosome segregation during mitosis. the previous discovery of a cyclin b/cdc2-activated microtubule-severing activity in m-phase xenopus egg extracts suggested that a microtubule-severing protein might play an important role in cell cycle-dependent changes in microtubule dynamics and organization. however, the isolation of three different microtubule-severing proteins, p56, ef1alpha, and katanin, has only confused the issue because none of these proteins is directly activated by cyclin b/cdc2. here we use immunodepletion with antibodies specific for a vertebrate katanin homologue to demonstrate that katanin is responsible for the majority of m-phase severing activity in xenopus eggs. this result suggests that katanin is responsible for changes in microtubules occurring at mitosis. immunofluorescence analysis demonstrated that katanin is concentrated at a microtubule-dependent structure at mitotic spindle poles in xenopus a6 cells and in human fibroblasts, suggesting a specific role in microtubule disassembly at spindle poles. surprisingly, katanin was also found in adult mouse brain, indicating that katanin may have other functions distinct from its mitotic role.
objective: the literature suggests that colorectal cancer mortality in texas is distributed inhomogeneously among specific demographic subgroups and in certain geographic regions over an extended period. to understand the extent of the demographic and geographic disparities, the present study examined colorectal cancer mortality in 15 demographic groups in texas counties between 1990 and 2001. methods: the spatial scan statistic was used to assess the standardized mortality ratio, duration and age-adjusted rates of excess mortality, and their respective p-values for testing the null hypothesis of homogeneity of geographic and temporal distribution. results: the study confirmed the excess mortality in some texas counties found in the literature, identified 13 additional excess mortality regions, and found 4 health regions with persistent excess mortality involving several population subgroups. conclusion: health disparities of colorectal cancer mortality continue to exist in texas demographic subpopulations. health education and intervention programs should be directed to the at-risk subpopulations in the identified regions. both statistical ecology and environmental statistics have numerous challenges and opportunities in the waiting for the twenty-first century, calling for increasing numbers of nontraditional statistical approaches. both theoretical and applied ecology are using advancing data analytical and interpretational software and hardware to satisfy public policy and discovery research, variously incorporating geospatial information, site-specific data and remote sensing imagery. we discuss a declared need for geoinformatic surveillance for spatial critical area detection. we explore, for ecological and environmental use, an innovation of the circle-based spatial scan statistic popular in the health sciences.
this paper reports a novel deep architecture referred to as maxout network in network (min), which can enhance model discriminability and facilitate the process of information abstraction within the receptive field. the proposed network adopts the framework of the recently developed network in network structure, which slides a universal approximator, multilayer perceptron (mlp) with rectifier units, to exact features. instead of mlp, we employ maxout mlp to learn a variety of piecewise linear activation functions and to mediate the problem of vanishing gradients that can occur when using rectifier units. moreover, batch normalization is applied to reduce the saturation of maxout units by pre-conditioning the model and dropout is applied to prevent overfitting. finally, average pooling is used in all pooling layers to regularize maxout mlp in order to facilitate information abstraction in every receptive field while tolerating the change of object position. because average pooling preserves all features in the local patch, the proposed min model can enforce the suppression of irrelevant information during training. our experiments demonstrated the state-of-the-art classification performance when the min model was applied to mnist, cifar-10, and cifar-100 datasets and comparable performance for svhn dataset. we consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. we define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. we empirically verify that the model successfully accomplishes both of these tasks. we use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: mnist, cifar-10, cifar-100, and svhn.
integrating large-scale functional genomic data has significantly accelerated our understanding of gene functions. however, no algorithm has been developed to differentiate functions for isoforms of the same gene using high-throughput genomic data. this is because standard supervised learning requires ‘ground-truth’ functional annotations, which are lacking at the isoform level. to address this challenge, we developed a generic framework that interrogates public rna-seq data at the transcript level to differentiate functions for alternatively spliced isoforms. for a specific function, our algorithm identifies the ‘responsible’ isoform(s) of a gene and generates classifying models at the isoform level instead of at the gene level. through cross-validation, we demonstrated that our algorithm is effective in assigning functions to genes, especially the ones with multiple isoforms, and robust to gene expression levels and removal of homologous gene pairs. we identified genes in the mouse whose isoforms are predicted to have disparate functionalities and experimentally validated the ‘responsible’ isoforms using data from mammary tissue. with protein structure modeling and experimental evidence, we further validated the predicted isoform functional differences for the genes cdkn2a and anxa6. our generic framework is the first to predict and differentiate functions for alternatively spliced isoforms, instead of genes, using genomic data. it is extendable to any base machine learner and other species with alternatively spliced isoforms, and shifts the current gene-centered function prediction to isoform-level predictions. in pattern classification it is usually assumed that a training set of labeled patterns is available. multiple-instance learning (mil) generalizes this problem setting by making weaker assumptions about the labeling information. while each pattern is still believed to possess a true label, training labels are associated with sets or bags of patterns rather than individual patterns. more formally, given is a set of patterns x1, ...,xn grouped into bags x1, ..., xm, with xj = {xi : i ∈ ij} and ij ⊆ {1, ..., n}. with each bag xj is associated a label yj ∈ {−1, 1}. these labels are interpreted in the following way: if a bag has a negative label yj = −1, all patterns in that bag inherit the negative label. if on the other hand, yj = 1, then at least one pattern xi ∈ xj is a positive example of the underlying concept. the mil scenario has many interesting applications: one prominent application is the classification of molecules in the context of drug design (dietterich, lathrop, & lozanoperez 1997). here, each molecule is represented by a bag of possible conformations. another application is in image retrieval where images can be viewed as bags of local image patches (maron & ratan 1998) or image regions. algorithms for the mil problem were first presented in (dietterich, lathrop, & lozano-perez 1997; auer 1997; long & tan 1996). these methods (and analytical results) are based on hypothesis classes consisting of axisaligned rectangles. similarly, methods developed subsequently (e.g., (maron & lozano-perez 1998; zhang & goldman 2002)) have focused on specially tailored machine learning algorithms that do not compare favorably in the limiting case of bags of size 1 (the standard classification setting). a notable exception is (ramon & raedt 2000).
many structured prediction tasks in machine vision have a collection of acceptable answers, instead of one definitive ground truth answer. segmentation of images, for example, is subject to human labeling bias. similarly, there are multiple possible pixel values that could plausibly complete occluded image regions. state-of-the art supervised learning methods are typically optimized to make a single test-time prediction for each query, failing to find other modes in the output space. existing methods that allow for sampling often sacrifice speed or accuracy. we introduce a simple method for training a neural network, which enables diverse structured predictions to be made for each test-time query. for a single input, we learn to predict a range of possible answers. we compare favorably to methods that seek diversity through an ensemble of networks. such stochastic multiple choice learning faces mode collapse, where one or more ensemble members fail to receive any training signal. our best performing solution can be deployed for various tasks, and just involves small modifications to the existing single-mode architecture, loss function, and training regime. we demonstrate that our method results in quantitative improvements across three challenging tasks: 2d image completion, 3d volume estimation, and flow prediction. many practical perception systems exist within larger processes that include interactions with users or additional components capable of evaluating the quality of predicted solutions. in these contexts, it is beneficial to provide these oracle mechanisms with multiple highly likely hypotheses rather than a single prediction. in this work, we pose the task of producing multiple outputs as a learning problem over an ensemble of deep networks -- introducing a novel stochastic gradient descent based approach to minimize the loss with respect to an oracle. our method is simple to implement, agnostic to both architecture and loss function, and parameter-free. our approach achieves lower oracle error compared to existing methods on a wide range of tasks and deep architectures. we also show qualitatively that the diverse solutions produced often provide interpretable representations of task ambiguity.
isovaleric acidemia (iva, mim 248600) can be a severe and potentially life-threatening disease in affected neonates, but with a positive prognosis on treatment for some phenotypes. this study presents the first application of metabolomics to evaluate the metabolite profiles derived from urine samples of untreated and treated iva patients as well as of obligate heterozygotes. all iva patients carried the same homozygous c.367 g > a nucleotide change in exon 4 of the ivd gene but manifested phenotypic diversity. concurrent class analysis (conca) was used to compare all the metabolites from the original complete data set obtained from the three case and two control groups used in this investigation. this application of conca has not been reported previously, and is used here to compare four different modes of scaling of all metabolites. the variables important in discrimination from the conca thus enabled the recognition of different metabolic patterns encapsulated within the data sets that would not have been revealed by using only one mode of scaling. application of multivariate and univariate analyses disclosed 11 important metabolites that distinguished untreated iva from controls. these included well-established diagnostic biomarkers of iva, endogenous detoxification markers, and 3-hydroxycaproic acid, an indicator of ketosis, but not reported previously for this disease. nine metabolites were identified that reflected the effect of treatment of iva. they included detoxification products and indicators related to the high carbohydrate and low protein diet which formed the hallmark of the treatment. this investigation also provides the first comparative metabolite profile for heterozygotes of this inherited metabolic disorder. the detection of informative metabolites in even very low concentrations in all three experimental groups highlights the potential advantage of the holistic mode of analysis of inherited metabolic diseases in a metabolomics investigation. isovaleric acidemia (iva) is one of the most common organic acidemias found in south africa. since 1983, a significant number of iva cases have been identified in approximately 20,000 caucasian patients screened for metabolic defects. iva is caused by an autosomal recessive deficiency of isovaleryl-coa dehydrogenase (ivd) resulting in the accumulation of isovaleryl-coa and its metabolites. in total, 10 iva patients and three carriers were available for phenotypic and genotypic investigation in this study. all patients were found to be homozygous for a single c.367 g > a (p.g123r) mutation. the amino acid substitution of a glycine to arginine resulted in a markedly reduced steady-state level of the ivd protein, which explains the nearly complete lack of ivd enzyme activity as assessed in fibroblast homogenates. despite the genetic homogeneity of this south african iva group, the clinical presentation varied widely, ranging from severe mental handicap and multiple episodes of metabolic derangement to an asymptomatic state. the variation may be due to poor dietary intervention, delayed diagnosis or even epigenetic and polygenetic factors of unknown origin.
backgroundfew studies to date have explored the stated preferences of national decision makers for health technology adoption criteria, and none of these have compared stated decision-making behaviours against actual behaviours. assessment of the external validity of stated preference studies, such as discrete-choice experiments (dces), remains an under-researched area.objectivesthe primary aim was to explore the preferences of all wales medicines strategy group (awmsg) appraisal committee and appraisal sub-committee (the new medicines group) members (‘appraisal committees’) for specific new medicines adoption criteria. secondary aims were to explore the external validity of respondents’ stated preferences and the impact of question choice options upon preference structures in dces.methodsa dce was conducted to estimate appraisal committees members’ preferences for incremental cost effectiveness, quality-adjusted life-years (qalys) gained, annual number of patients expected to be treated, the impact of the disease on patients before treatment, and the assessment of uncertainty in the economic evidence submitted for new medicines compared with current uk nhs treatment. respondents evaluated 28 pairs of hypothetical new medicines, making a primary forced choice between each pair and a more flexible secondary choice, which permitted either, neither or both new medicines to be chosen. the performance of the resultant models was compared against previous awmsg decisions.resultsforty-one out of a total of 80 past and present members of awmsg appraisal committees completed the dce. the incremental cost effectiveness of new medicines, and the qaly gains they provide, significantly (p < 0.0001) influence recommendations. committee members were willing to accept higher incremental cost-effectiveness ratios and lower qaly gains for medicines that treat disease impacting primarily upon survival rather than quality of life, and where uncertainty in the cost-effectiveness estimates has been thoroughly explored. the number of patients to be treated by the new medicine did not exert a significant influence upon recommendations. the use of a flexible-choice question format revealed a different preference structure to the forced-choice format, but the performance of the two models was similar. aggregate decisions of the awmsg were well predicted by both models, but their sensitivity (64 %, 68 %) and specificity (55 %, 64 %) were limited.conclusionsa willingness to trade the cost effectiveness and qaly gains against other factors indicates that economic efficiency and qaly maximisation are not the only considerations of committee members when making recommendations on the use of medicines in wales. on average, appraisal committee members’ stated preferences appear consistent with their actual decision-making behaviours, providing support for the external validity of our dces. however, as health technology assessment involves complex decision-making processes, and each individual recommendation may be influenced to varying degrees by a multitude of different considerations, the ability of our models to predict individual medicine recommendations is more limited. the decisions made by the national institute for clinical excellence (nice) give rise to two questions: how is cost-effectiveness evidence used to make judgements about the 'value for money' of health technologies? and how are factors other than cost-effectiveness taken into account? the aim of this paper is to explore nice's cost-effectiveness threshold(s) and the tradeoffs between cost effectiveness and other factors apparent in its decisions. binary choice analysis is used to reveal the preferences of nice and to consider the consistency of its decisions. for each decision to accept or reject a technology, explanatory variables include: the cost per life year or per qaly gained; uncertainty regarding cost effectiveness; the net cost to the nhs; the burden of disease; the availability (or not) of alternative treatments; and specific factors indicated by nice. results support the broad notion of a threshold, where the probability of rejection increases as the cost per qaly increases. cost effectiveness, together with uncertainty and the burden of disease, explain nice decisions better than cost effectiveness alone. the results suggest a threshold somewhat higher than nices stated 'range of acceptable cost effectiveness' of pound 20,000-30,000 british pounds per qaly--although the exact meaning of a 'range' in this context remains unclear.
recently, the worldwide propagation of clonal ctx-m-15-producing escherichia coli isolates, namely st131 and o25b:h4, has been reported. like the majority of extra-intestinal pathogenic e. coli isolates, the pandemic clone st131 belongs to phylogenetic group b2, and has recently been shown to be highly virulent in a mouse model, even though it lacks several genes encoding key virulence factors (pap, cnf1 and hlya). using two animal models, caenorhabditis elegans and zebrafish embryos, we assessed the virulence of three e. coli st131 strains (2 ctx-m-15- producing urine and 1 non-esbl-producing faecal isolate), comparing them with five non-st131 b2 and a group a uropathogenic e. coli (upec). in c. elegans, the three st131 strains showed intermediate virulence between the non virulent group a isolate and the virulent non-st131 b2 strains. in zebrafish, the ctx-m-15-producing st131 upec isolates were also less virulent than the non-st131 b2 strains, suggesting that the production of ctx-m-15 is not correlated with enhanced virulence. amongst the non-st131 b2 group isolates, variation in pathogenic potential in zebrafish embryos was observed ranging from intermediate to highly virulent. interestingly, the st131 strains were equally persistent in surviving embryos as the non-st131-group b2 strains, suggesting similar mechanisms may account for development of persistent infection. optical maps of the genome of the st131 strains were compared with those of 24 reference e. coli strains. although small differences were seen within the st131 strains, the tree built on the optical maps showed that these strains belonged to a specific cluster (86% similarity) with only 45% similarity with the other group b2 strains and 25% with strains of group a and d. thus, the st131 clone has a genetic composition that differs from other group b2 strains, and appears to be less virulent than previously suspected. an ongoing outbreak of exceptionally virulent shiga toxin (stx)-producing escherichia coli o104:h4 centered in germany, has caused over 830 cases of hemolytic uremic syndrome (hus) and 46 deaths since may 2011. serotype o104:h4, which has not been detected in animals, has rarely been associated with hus in the past. to prospectively elucidate the unique characteristics of this strain in the early stages of this outbreak, we applied whole genome sequencing on the life technologies ion torrent pgm™ sequencer and optical mapping to characterize one outbreak isolate (lb226692) and a historic o104:h4 hus isolate from 2001 (01-09591). reference guided draft assemblies of both strains were completed with the newly introduced pgm™ within 62 hours. the hus-associated strains both carried genes typically found in two types of pathogenic e. coli, enteroaggregative e. coli (eaec) and enterohemorrhagic e. coli (ehec). phylogenetic analyses of 1,144 core e. coli genes indicate that the hus-causing o104:h4 strains and the previously published sequence of the eaec strain 55989 show a close relationship but are only distantly related to common ehec serotypes. though closely related, the outbreak strain differs from the 2001 strain in plasmid content and fimbrial genes. we propose a model in which eaec 55989 and ehec o104:h4 strains evolved from a common ehec o104:h4 progenitor, and suggest that by stepwise gain and loss of chromosomal and plasmid-encoded virulence factors, a highly pathogenic hybrid of eaec and ehec emerged as the current outbreak clone. in conclusion, rapid next-generation technologies facilitated prospective whole genome characterization in the early stages of an outbreak.
divergent transcription occurs at the majority of rna polymerase ii (rnapii) promoters in mouse embryonic stem cells (mescs), and this activity correlates with cpg islands. here we report the characterization of upstream antisense transcription in regions encoding transcription start site associated rnas (tssa-rnas) at four divergent cpg island promoters: isg20l1, tcea1, txn1, and sf3b1. we find that upstream antisense rnas (uarnas) have distinct capped 5′ termini and heterogeneous nonpolyadenylated 3′ ends. uarnas are short-lived with average half-lives of 18 minutes and are present at 1–4 copies per cell, approximately one rna per dna template. exosome depletion stabilizes uarnas. these uarnas are probably initiation products because their capped termini correlate with peaks of paused rnapii. the pausing factors nelf and dsif are associated with these antisense polymerases and their sense partners. knockdown of either nelf or dsif results in an increase in the levels of uarnas. consistent with p-tefb controlling release from pausing, treatment with its inhibitor, flavopiridol, decreases uarna and nascent mrna transcripts with similar kinetics. finally, isg20l1 induction reveals equivalent increases in transcriptional activity in sense and antisense directions. together these data show divergent polymerases are regulated after p-tefb recruitment with uarna levels controlled by the exosome. transcription initiation by rna polymerase ii (rnapii) is thought to occur unidirectionally from most genes. here, we present evidence of widespread divergent transcription at protein-encoding gene promoters. transcription start site–associated rnas (tssa-rnas) nonrandomly flank active promoters, with peaks of antisense and sense short rnas at 250 nucleotides upstream and 50 nucleotides downstream of tsss, respectively. northern analysis shows that tssa-rnas are subsets of an rna population 20 to 90 nucleotides in length. promoter-associated rnapii and h3k4-trimethylated histones, transcription initiation hallmarks, colocalize at sense and antisense tssa-rna positions; however, h3k79-dimethylated histones, characteristic of elongating rnapii, are only present downstream of tsss. these results suggest that divergent transcription over short distances is common for active promoters and may help promoter regions maintain a state poised for subsequent regulation.
backgroundtwo-component systems (tcs) play critical roles in sensing and responding to environmental cues. azospirillum is a plant growth-promoting rhizobacterium living in the rhizosphere of many important crops. despite numerous studies about its plant beneficial properties, little is known about how the bacterium senses and responds to its rhizospheric environment. the availability of complete genome sequenced from four azospirillum strains (a. brasilense sp245 and cbg 497, a. lipoferum 4b and azospirillum sp. b510) offers the opportunity to conduct a comprehensive comparative analysis of the tcs gene family.resultsazospirillum genomes harbour a very large number of genes encoding tcs, and are especially enriched in hybrid histidine kinases (hyhk) genes compared to other plant-associated bacteria of similar genome sizes. we gained further insight into hyhk structure and architecture, revealing an intriguing complexity of these systems. an unusual proportion of tcs genes were orphaned or in complex clusters, and a high proportion of predicted soluble hks compared to other plant-associated bacteria are reported. phylogenetic analyses of the transmitter and receiver domains of a. lipoferum 4b hyhk indicate that expansion of this family mainly arose through horizontal gene transfer but also through gene duplications all along the diversification of the azospirillum genus. by performing a genome-wide comparison of tcs, we unraveled important ‘genus-defining’ and ‘plant-specifying’ tcs.conclusionsthis study shed light on azospirillum tcs which may confer important regulatory flexibility. collectively, these findings highlight that azospirillum genomes have broad potential for adaptation to fluctuating environments. magnifying genomes (mage) is a microbial genome annotation system based on a relational database containing information on bacterial genomes, as well as a web interface to achieve genome annotation projects. our system allows one to initiate the annotation of a genome at the early stage of the finishing phase. mage's main features are (i) integration of annotation data from bacterial genomes enhanced by a gene coding re-annotation process using accurate gene models, (ii) integration of results obtained with a wide range of bioinformatics methods, among which exploration of gene context by searching for conserved synteny and reconstruction of metabolic pathways, (iii) an advanced web interface allowing multiple users to refine the automatic assignment of gene product functions. mage is also linked to numerous well-known biological databases and systems. our system has been thoroughly tested during the annotation of complete bacterial genomes (acinetobacter baylyi adp1, pseudoalteromonas haloplanktis, frankia alni) and is currently used in the context of several new microbial genome annotation projects. in addition, mage allows for annotation curation and exploration of already published genomes from various genera (e.g. yersinia, bacillus and neisseria). mage can be accessed at .
time-resolved fourier transform infrared (ftir) difference spectra of the halorhodopsin (hr) photocycle have been collected from 3 micros to 100 ms in saturating concentrations of kcl or kbr. kinetic analysis of these data revealed two decay processes, with time constants of tau(1) approximately 150 micros and tau(2) approximately 16 ms in the presence of either halide, with tau(2) describing the return to the starting (hr) state. comparison to previous low-temperature ftir spectra of hr intermediates confirms that characteristic hk and hl spectral features are both present before the tau(1) decay, in a state previously defined as hk(l) (dioumaev, a., and m. braiman. 1997. photochem. photobiol. 66:755-763). however, the relative sizes of these features depend on which halide is present. in br-, the hl features are clearly more dominant than in cl-. therefore, the state present before tau(1) is probably best described as an hk(l)/hl(1) equilibrium, instead of a single hk(l) state. different halides affect the relative amounts of hk(l) and hl(1) present, i.e., cl- produces a much more significant back-reaction from hl(1) to hk(l) than does br-. the halide dependence of this back-reaction could therefore explain the halide selectivity of the halorhodopsin anion pump. abstract— step‐scan fourier transform infrared spectroscopy with 50 ns time resolution was applied to the early stages of the photocycle of halorhodopsin (hr) for the temperature range 3‐42° c. kinetic data analysis with global fitting revealed two distinct kinetic processes associated with relaxations of the early red‐shifted photoproduct hk; these processes have time constants t1⋍ 280 ns and t2⋍ 360 μs at 20°c. spectral features demonstrate that the t1 process corresponds to a transition between two distinct bathointermediates, hke and hkl. the vibrational difference bands associated with both t1 and t2 transitions are spread throughout the whole 1800‐900 cm−1 range. however, the largest bands correspond to ethylenic c=c stretches, fingerprint c‐c stretches and hydrogen out‐of‐plane (hoop) wags of the retinal chromophore. the time evolution of these difference bands indicate that both the t1 and t2 decay processes involve principally a relaxation of the chromophore and its immediate environment. the decay of the intense hoop vibrations is nearly equally divided between the t1 and t2 processes, indicating a complex chromophore relaxation from a twisted nonrelaxed conformation in the primary (hke) bathointermediate, to a less‐twisted structure in hkl, and finally to a roughly planar structure in the hypsochromically shifted hl intermediate. this conclusion is also supported by the unexpectedly large positive entropy of activation observed for the t1 process. the two relaxations from hke to hl are largely analogous to corresponding relaxations (ke→ kl→ l) in the bacterior‐hodopsin photocycle, except that the second step is slowed down by over 200‐fold in hr.
background:peripheral blood-derived inflammation-based scores such as the neutrophil–lymphocyte ratio (nlr) and platelet–lymphocyte ratio (plr) have recently been proposed as prognostic markers in solid tumours. although evidence to support these markers as unfavourable prognostic factors is more compelling in gastrointestinal cancers, very little is known of their impact on breast cancer. we investigated the association between the nlr and plr, and overall survival after breast cancer.methods:data from the university of malaya medical centre breast cancer registry was used. of 2059 consecutive patients diagnosed from 2000 to 2008, we included 1435 patients with an available pre-treatment differential blood count (∼70%). patients were stratified into quintiles of the nlr/plr. multivariable cox regression was used to determine the independent prognostic significances of the nlr/plr.results:compared with the first quintile of the nlr, women in quintile 5 were younger, had bigger tumours, nodal involvement, distant metastases and higher tumour grades. higher nlr quintiles were significantly associated with poorer survival with a 5-year relative survival ratio (rsr) of 76.4% (95% ci: 69.6–82.1%) in quintile 1, 79.4% (95% ci: 74.4–83.7%) in quintile 2, 72.1% (95% ci: 66.3–77.3%) in quintile 3, 65.6% (95% ci: 59.8–70.8%) in quintile 4 and 51.1% (95% ci: 43.3–58.5%) in quintile 5. following adjustment for demography, tumour characteristics, treatment and the plr, the adjusted hazard ratio (hr) for quintile 5 vs quintile 1 was 1.50 (95% ci: 1.08–1.63); ptrend=0.004. results were unchanged when the nlr was analysed as a dichotomous variable using different cutoff points. although patients in plr quintile 5 had lower survival than in quintile 1 (5-year rsr: 53.2% (95% ci: 46.9–59.2%) vs 77.0% (95% ci: 70.9–82.2%)), this association was not significant after multivariable adjustment. however, a plr >185 was significantly associated with poorer survival; adjusted hr: 1.25 (95% ci: 1.04–1.52).conclusions:both the nlr and plr are independently associated with an increased risk of mortality in breast cancer. their added value in the prognostication of breast cancer in clinical practice warrants investigation. background: inflammation influences cancer development and progression. an elevated platelet to lymphocyte ratio (plr), a marker of inflammation, has been linked to poor prognosis in several malignancies. here, we quantify the prognostic impact of this biomarker. methods: a systematic review of databases was conducted to identify publications exploring the association of blood plr and overall survival (os) in solid tumors. data were pooled in a meta-analysis. pooled hrs for os by disease group and by plr cutoff groups were computed and weighted using generic inverse-variance and random-effect modeling. results: twenty studies comprising 12,754 patients were assessed. cutoffs for plr defining risk groups ranged from 150 to 300 and were dichotomous (12 studies; group 1) or split into three groups (<150/150–300/>300, 8 studies; group 2). higher plr was associated with significantly worse os in group 1 [hr = 1.87; 95% confidence interval (ci, 1.49–2.34); p < 0.001] and with a nonsignificant association in group 2 (hr per higher category = 1.21; 95%ci, 0.97–1.50; p = 0.10). the size of effect of plr on os was greater for metastatic disease (hr[group 1] = 2.0; 95% ci, 1.6–2.7; hr[group 2] = 1.6; 95% ci, 1.1–2.4) than for early-stage disease (hr[group 1] = 1.5; 95% ci, 1.0–2.2; hr[group 2] = 1.0; 95% ci, 0.8–1.3). a significant association was observed for colorectal, hepatocellular, gastroesophageal, ovarian, and pancreatic carcinoma in group 1 and for colorectal cancers in group 2. conclusion: a high plr is associated with worse os in various solid tumors. further research of its regulation and relevance in daily practice is warranted. impact: plr is a readily available and inexpensive biomarker with independent prognostic value in solid tumors. cancer epidemiol biomarkers prev; 23(7); 1204–12. ©2014 aacr.
an investigation was made to evaluate the role of anethum graveolens l. (dill) leaf extract in the regulation of corticosteroid‐induced type 2 diabetes mellitus in female rats. in dexamethasone‐treated animals (1 mg/kg for 22 days) an increase in serum concentration of insulin and glucose and in hepatic lipid peroxidation (lpo) was observed. however, there was a decrease in serum concentration of thyroid hormones and in the endogenous antioxidant enzymes, such as superoxide dismutase (sod), catalase (cat) and reduced glutathione (gsh) in liver. in animals treated with an equivalent amount of dexamethasone for a similar period (22 days) when received the leaf extract (100 mg/kg b.wt/d.) for last 15 days a decrease in the concentration of both serum glucose and insulin was observed, indicating the potential of the plant extract in the regulation of corticosteroid‐induced diabetes. dexamethasone‐induced alterations in the levels of thyroid hormones as well as in hepatic lpo, sod, cat and gsh were also reversed by the plant extract. copyright © 2008 john wiley & sons, ltd. scopoletin (7‐hydroxy‐6‐methoxy coumarin) was isolated from the leaves of aegle marmelos and evaluated for its potential to regulate hyperthyroidism, lipid peroxidation and hyperglycemia in levo‐thyroxine‐induced hyperthyroid rats. scopoletin (1.00 mg/kg, p.o.) administered daily for 7 days to levo‐thyroxine‐treated animals decreased the levels of serum thyroid hormones and glucose as well as hepatic glucose‐6‐phosphatase activity, demonstrating its potential to regulate hyperthyroidism and hyperglycemia. scopoletin also inhibited hepatic lipid peroxidation and increased the activity of antioxidants, superoxide dismutase and catalase. compared with the standard antithyroid drug, propylthiouracil, scopoletin exhibited a superior therapeutic activity, since unlike propylthiouracil, it also inhibited hepatic lipid peroxidation. these findings indicate that scopoletin has the potential to inhibit thyroid function and hyperglycemia without hepatotoxicity. copyright © 2006 john wiley & sons, ltd.
abstract. the purpose of the study was to characterise statistically the inherent fluctuations in breath-by-breath measurements of pulmonary gas exchange (oxygen uptake and carbon dioxide output, vo2 and vco2, respectively) and pulmonary ventilation (ve) in patients with chronic obstructive pulmonary disease (copd) and to compare them with those of healthy control subjects. thirty subjects with copd [mean (sd): 67 (6) years old; forced expiratory volume in 1 min, fev1 1.25( 0.18) l; 42 (6)% predicted fev1] and 12 healthy subjects [31 (3) years old; fev1 3.62 (0.54) l; 99 (8)% predicted fev1] performed exercise tests on a cycle ergometer at a constant work rate of moderate intensity. steady-state exercise values for vo2, vco2 and ve were 905 (96) ml·min–1, 847(90) ml·min–1 and 23 (3) l·min–1, respectively for the copd patients and 1239(89) ml·min–1, 1191(84) ml·min–1 and 37(3) l·min–1, respectively, for the healthy controls. the breath-by-breath fluctuations were well characterised by a gaussian density-probability function with breath-to-breath autocorrelations that were not significantly different from 0, up to four subsequent breaths. its magnitude varied among variables, but was independent of the signal amplitude for the same subject and variable. with ratios of amplitude of fluctuation:signal of around 10%, typical of the patients studied, the resolution of time constants and amplitude were ≅9 s and ≅100 ml·min–1, respectively for vo2 or vco2 with one repetition. excess co2 is generated when lactate is increased during exercise because its [h+] is buffered primarily by hco-3 (22 ml for each meq of lactic acid). we developed a method to detect the anaerobic threshold (at), using computerized regression analysis of the slopes of the co2 uptake (vco2) vs. o2 uptake (vo2) plot, which detects the beginning of the excess co2 output generated from the buffering of [h+], termed the v-slope method. from incremental exercise tests on 10 subjects, the point of excess co2 output (at) predicted closely the lactate and hco-3 thresholds. the mean gas exchange at was found to correspond to a small increment of lactate above the mathematically defined lactate threshold [0.50 +/- 0.34 (sd) meq/l] and not to differ significantly from the estimated hco-3 threshold. the mean vo2 at at computed by the v-slope analysis did not differ significantly from the mean value determined by a panel of six experienced reviewers using traditional visual methods, but the at could be more reliably determined by the v-slope method. the respiratory compensation point, detected separately by examining the minute ventilation vs. vco2 plot, was consistently higher than the at (2.51 +/- 0.42 vs. 1.83 +/- 0.30 l/min of vo2). this method for determining the at has significant advantages over others that depend on regular breathing pattern and respiratory chemosensitivity.
backgroundopen chromatin regions are correlated with active regulatory elements in development and are dysregulated in diseases. the baf (swi/snf) complex is essential for development, and has been demonstrated to remodel reconstituted chromatin in vitro and to control the accessibility of a few individual regions in vivo. however, it remains unclear where and how baf controls the open chromatin landscape to regulate developmental processes, such as human epidermal differentiation.resultsusing a novel “on-plate” atac-sequencing approach for profiling open chromatin landscapes with a low number of adherent cells, we demonstrate that the baf complex is essential for maintaining 11.6 % of open chromatin regions in epidermal differentiation. these baf-dependent open chromatin regions are highly cell-type-specific and are strongly enriched for binding sites for p63, a master epidermal transcription factor. the dna sequences of p63 binding sites intrinsically favor nucleosome formation and are inaccessible in other cell types without p63 to prevent ectopic activation. in epidermal cells, baf and p63 mutually recruit each other to maintain 14,853 open chromatin regions. we further demonstrate that baf and p63 cooperatively position nucleosomes away from p63 binding sites and recruit transcriptional machinery to control tissue differentiation.conclusionsbaf displays high specificity in controlling the open chromatin landscape during epidermal differentiation by cooperating with the master transcription factor p63 to maintain lineage-specific open chromatin regions. chromatin structure can affect the transcriptional activity of eukaryotic structural genes by blocking access of sequence-specific activator proteins (activators) to their promoter-binding sites1. for example, the dna-binding domain of the yeast gal4 protein interacts very poorly with nucleosome cores compared with naked dna2 (and see below), and binding of other activators is even more strongly inhibited2,3. the way in which activators bind to nucleosomal dna is therefore a critical aspect of transcriptional activation. genetic studies have suggested that the multi-component swi/snf complex of saccharomyces cerevisiae facilitates transcription by altering the structure of the chromatin4,5. here we identify and partially purify a human homologue of the yeast swi/snf complex (hswi/snf complex). we show that a partially purified hswi/snf complex mediates the atp-dependent disruption of a nucleosome, thereby enabling the activators, gal4–vp16 and gal4–ah, to bind within a nucleosome core. we conclude that the hswi/snf complex acts directly to reorganize chromatin structure so as to facilitate binding of transcription factors.
the sarcoplasmic/endoplasmic reticulum calcium atpase 1 (serca1) has two muscle specific splice isoforms; serca1a in fast-type adult and serca1b in neonatal and regenerating skeletal muscles. at the protein level the only difference between these two isoforms is that serca1a has c-terminal glycine while serca1b has an octapeptide tail instead. this makes the generation of a serca1a specific antibody not feasible. the switch between the two isoforms is a hallmark of differentiation so we describe here a method based on the signal ratios of the serca1b specific and pan serca1 antibodies to estimate the serca1b/serca1a dominance on immunoblot of human muscles. using this method we showed that unlike in mouse and rat, serca1b was only expressed in pre-matured infant leg and arm muscles; it was replaced by serca1a in more matured neonatal muscles and was completely absent in human foetal and neonatal diaphragms. interestingly, only serca1a and no serca1b were detected in muscles of 7–12 years old boys with duchenne, a degenerative-regenerative muscular dystrophy. however, in adult patients with myotonic dystrophy type 2 (dm2), the serca1b dominated over serca1a. thus the human serca1b has a different expression pattern from that of rodents and it is associated with dm2. the relative mrna levels corresponding to the different sarcoplasmic/endoplasmic-reticulum ca(2+)-atpase isoforms (serca1a, serca1b, serca2a, serca2b and serca3) were measured by reverse transcriptase-pcr in rat soleus muscles regenerating after notexin-induced necrosis. the succession of appearance of the different types of serca mrna species in regenerating muscle largely recapitulates those observed during normal ontogenesis. the mrna levels of the muscle-specific isoforms serca1a and serca2a became very low on the first and third days after injection of the snake venom. it was only on the fifth day of regeneration that the mrna of the neonatal variant of the fast-twitch skeletal serca1b isoform began to rise, well before the other serca transcripts. at 7 and 10 days, i.e. at a time when the new myofibres normally become reinnervated, the mrna level of serca1a and serca2a increased markedly, but the fast-twitch skeletal serca1a isoform was still the most prominent. on day 21, in the advanced stage of regeneration, a switch in the relative expression levels of serca1a and serca2a mrna was observed and the ratio of both isoforms became similar to that found in the normal soleus muscles. this was followed by a decline in the level of all serca mrna species, so that on day 28 the levels of the sarcoplasmic/endoplasmatic-reticulum ca(2+)-pump rnas was again lower but their ratio remained similar to that of the untreated control soleus.
abstract breast asymmetry is common in females, despite a similar driving force; dynamic activity may result in asymmetrical breast motion. this preliminary study investigated how breast categorisation (left/right or dominant/non-dominant) may affect breast support recommendations and its relationship with breast pain. ten females ran on a treadmill at 10 kph in three breast supports (no bra, everyday bra, sports bra). five reflective markers on the thorax and nipples were tracked using infrared cameras (200 hz) during five running gait cycles in each breast support. multiplanar displacements of both breasts were calculated relative to the thorax. although the maximum individual participant difference was 2.4 cm (mediolaterally) between the left and right breast, no left/right differences were found in any direction or support condition. notably, correlations between breast pain and anterioposterior breast displacement were stronger with the left breast (r = 0.614) and moderate with the right breast (r = 0.456). following participant categorisation according to the greatest magnitude of superioinferior breast displacement (dominant breast), results showed significant differences in displacement for all directions across different breast supports. when using breast kinematic data to examine relationships with breast pain or to recommend breast support requirements, data on both breasts should be collected. abstract although breast pain has been related to vertical breast displacement and velocity, the influence of breast support on multi-planar breast kinematics and breast comfort has yet to be ascertained. the aims of this study were to investigate multi-planar breast displacement, velocity, and acceleration with and without breast support during running and to establish the correlation with breast comfort. fifteen females ran at 2.8 m · s−1 in no bra, an everyday bra, and a sports bra. three-dimensional coordinates of breast and body markers were tracked during ten gait cycles and following each trial the participants rated their breast comfort. relative breast displacement was calculated and derived for velocity and acceleration. vertical breast displacement, velocity, and acceleration peaked at, before, and after mid-stance, respectively. the patterns of displacement and velocity trajectories were unaffected by increasing breast support, though the magnitudes were significantly reduced. the magnitude and trajectory of breast acceleration was unaffected by increasing breast support and showed no correlation with comfort. breast velocity displayed the strongest relationship to comfort (r = 0.61). considerable mediolateral and anteroposterior breast kinematics were identified, suggesting that future studies and bra design may benefit from three-dimensional analysis. in conclusion, improvements in breast support may be defined by reductions in breast velocity and displacement.
abstractongoing monitoring in the swiss alps has shown that rock ptarmigan (lagopus muta helvetica) has suffered a significant population decrease over the last decade and climate change has been proposed as a potential cause. in this study, we investigate the response of this high alpine grouse species to rapid climate change. we address a problem often neglected in macro-ecological studies on species distribution: scale-dependency of distribution models. the models are based on empirical field data and on environmental databases for large-scale models. the implementation of several statistical modelling approaches, external validation strategies and the implementation of a recent study on regional climate change in switzerland ensure robust predictions of future range shifts. our results demonstrate that, on the territory level, variables depicting vegetation, heterogeneity of local topography and habitat structure have greatest explanatory power. in contrast at the meso-scale and macro-scale (with grain sizes of 1 and 100 km2, respectively), bioclimatic and land cover-related variables play a prominent role. the models predict that, based on increasing temperatures during the breeding season, potential habitat will decrease by up to two-thirds until the year 2070. at the same time, a shift of potential habitat towards the mountain tops is predicted. the multi-scale approach highlights the true extent of potential habitat for this species with its patchy distribution in steep terrain. the small-scale analysis pinpoints the key habitat areas within the extensive areas of suitable habitat predicted by models on large grain sizes and in this way reveals sub-grid variability. our results can facilitate the adaptation of species conservation strategies to a quickly changing environment.zusammenfassunghabitat auf den gipfeln der berge: wie lange kann das alpenschneehuhn (lagopus muta helvetica) raschen klimawandel in den schweizer alpen überleben? ein mehrskaliger ansatz.  fortlaufendes monitoring hat gezeigt, dass innerhalb des letzten jahrzehnts die population des alpenschneehuhns (lagopus muta helvetica) in den schweizer alpen stark abgenommen hat. als mögliche ursache kommt der klimawandel in betracht. in dieser studie untersuchen wir die auswirkungen raschen klimawandels auf dieses hochalpine raufußhuhn. dabei setzten wir uns mit einem aspekt auseinander, der in vielen makroökologischen studien oft vernachlässigt wird: die skalenabhängigkeit von habitatmodellen. die modelle basieren auf empirischen felddaten und auf umweltdatenbanken für die großskaligen modelle. die anwendung mehrerer, statistischer modelle, externe validierung und die daten einer aktuellen studie zum klimawandel in der schweiz legen die grundlage für robuste vorhersagen der künftigen verbreitung des alpenschneehuhns. unsere ergebnisse zeigen, dass auf der revierskala variablen, die die vegetation, die lokale topographie und habitatstruktur beschreiben die größte vorhersagekraft haben. im gegensatz dazu spielen auf der mesoskala (korngröße 1 km2) und makroskala (korngröße 100 km2) bioklimatische und land cover variablen die herausragende rolle. die modelle sagen vorher, dass sich allein aufgrund einer erhöhten durchschnittstemperatur während der brutzeit das potenzielle habitat bis zum jahre 2070 um bis zu zwei drittel verringern wird. zudem findet eine verschiebung in richtung gebirgsgipfel statt. insbesondere für arten, die steiles terrain bewohnen und lückenhafte verbreitung aufweisen wie das alpenschneehuhn, verdeutlicht die analyse auf mehreren skalen das wirkliche ausmaß des potenziellen habitats. so zeigt die feinskalige analyse die bevorzugten gebiete innerhalb der großräumigen gebiete auf, welche die modelle auf den großen skalen vorhersagen und verdeutlicht auf diese weise die variabilität innerhalb der rasterzellen. unsere ergebnisse können einen beitrag zur anpassung der naturschutzstrategien zur arterhaltung in einer sich schnell verändernden umwelt leisten. with the rise of new powerful statistical techniques and gis tools, the development of predictive habitat distribution models has rapidly increased in ecology. such models are static and probabilistic in nature, since they statistically relate the geographical distribution of species or communities to their present environment. a wide array of models has been developed to cover aspects as diverse as biogeography, conservation biology, climate change research, and habitat or species management. in this paper, we present a review of predictive habitat distribution modeling. the variety of statistical techniques used is growing. ordinary multiple regression and its generalized form (glm) are very popular and are often used for modeling species distributions. other methods include neural networks, ordination and classification methods, bayesian models, locally weighted approaches (e.g. gam), environmental envelopes or even combinations of these models. the selection of an appropriate method should not depend solely on statistical considerations. some models are better suited to reflect theoretical findings on the shape and nature of the species’ response (or realized niche). conceptual considerations include e.g. the trade-off between optimizing accuracy versus optimizing generality. in the field of static distribution modeling, the latter is mostly related to selecting appropriate predictor variables and to designing an appropriate procedure for model selection. new methods, including threshold-independent measures (e.g. receiver operating characteristic (roc)-plots) and resampling techniques (e.g. bootstrap, cross-validation) have been introduced in ecology for testing the accuracy of predictive models. the choice of an evaluation measure should be driven primarily by the goals of the study. this may possibly lead to the attribution of different weights to the various types of prediction errors (e.g. omission, commission or confusion). testing the model in a wider range of situations (in space and time) will permit one to define the range of applications for which the model predictions are suitable. in turn, the qualification of the model depends primarily on the goals of the study that define the qualification criteria and on the usability of the model, rather than on statistics alone. © 2000 elsevier science b.v. all rights reserved.
introduction: the pattern of sleep plays an important role in protecting the adolescents’ health. the main objective of this research is to determine the relationship between sufficient sleep (≥ 8 hours of sleep per night on school days) and health-risk behaviours in portuguese adolescents. methods: 5,050 participants with an average age of 13.98 (dp ± 1.85), 52.3% of which were female. the instrument used was the health behaviour in school-aged children 2010 (hbsc) questionnaire. the associations were studied by applying χ² tests and the multivariate logistic regression models. results: a significant percentage of adolescents (39%) get less than 8 hours sleep on weekdays. sufficient sleep (≥ 8 h) is associated with younger age: adolescents between the ages of 13 and 15 (or=0.549, p<.05) and those aged 16 or older (or=0.291, p<.05) sleep less, as well as with less consumption of tobacco (or=0.728, p<.05) and alcohol (or=0.837, p<.05), a lower level of sadness (or=0.786, p<.05) and a lower tendency to use the computer for 3 hours or more a day (or=0.829, p<.05). conclusion: the adolescents’ pattern of sleep is an important feature in adolescents lifestyles being associated to a large range of health and health compromising behaviours. aim:  to investigate the sleep quality status and its associated factors (including psychological and physiological as well as social demographic factors) among chinese mainland adolescents.
